{
  "hash": "8097a4f7029456c7cf8c643734334503",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"第1讲：机器学习理论基础\"\nsubtitle: \"非时序任务的认知框架（i.i.d.）\"\n---\n\n\n\n\n\n\n# 课程定位与本周目标\n\n## 课程主线\n\n本课程围绕**泛化—正则化—评估**三位一体展开：\n\n- **泛化能力**：模型在未见数据上的表现，是机器学习的核心目标\n- **正则化**：控制模型复杂度，防止过拟合的关键手段\n- **评估规范**：科学衡量模型性能，确保研究结论可靠\n\n## 本周聚焦\n\n本周建立**i.i.d.（独立同分布）场景**下的\"最小认知框架\"，为后续金融应用打下理论基础。\n\n:::{.callout-important}\n**重要提示**：金融数据通常**不满足 i.i.d. 假设**（存在时序依赖、非平稳性等）。本周先理解基础框架，第2周将系统讲解金融时序评估规范。\n:::\n\n# 两类监督学习任务：回归 vs 分类\n\n## 统一的符号系统\n\n监督学习的基本设定：\n\n- **特征向量** $\\mathbf{x} \\in \\mathbb{R}^p$：描述观测对象的 $p$ 个属性\n- **标签** $y$：我们希望预测的目标变量\n  - 回归任务：$y \\in \\mathbb{R}$（连续值）\n  - 分类任务：$y \\in \\{1, 2, \\ldots, K\\}$（离散类别）\n- **训练集** $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$：用于学习模型的已知数据\n- **模型** $\\hat{f}(\\mathbf{x})$：从特征到预测的映射\n\n## 回归任务（Regression）\n\n### 目标\n\n预测一个**连续数值**，如股票收益率、信用评分、违约损失率等。\n\n### 常见损失函数\n\n1. **均方误差（MSE）**：\n$$\nL(\\hat{f}) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{f}(\\mathbf{x}_i))^2\n$$\n\n2. **平均绝对误差（MAE）**：\n$$\nL(\\hat{f}) = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{f}(\\mathbf{x}_i)|\n$$\n\n### 典型模型输出\n\n- 线性回归：$\\hat{y} = \\mathbf{x}^\\top \\boldsymbol{\\beta}$\n- 非线性回归：$\\hat{y} = f(\\mathbf{x})$（如神经网络、树模型等）\n\n## 分类任务（Classification）\n\n### 目标\n\n将观测对象归入**离散类别**，如预测涨跌方向、信用等级、欺诈与否等。\n\n### 常见损失函数\n\n**对数损失（Log-loss / Cross-entropy）**：\n\n对于二分类（$y \\in \\{0,1\\}$）：\n$$\nL(\\hat{f}) = -\\frac{1}{n}\\sum_{i=1}^n [y_i \\log(\\hat{p}_i) + (1-y_i)\\log(1-\\hat{p}_i)]\n$$\n\n其中 $\\hat{p}_i = P(y_i=1|\\mathbf{x}_i)$ 是模型预测的概率。\n\n### 典型模型输出\n\n- **概率输出**：$\\hat{p} = P(y=1|\\mathbf{x}) \\in [0,1]$\n  - Logistic回归：$\\hat{p} = \\frac{1}{1+\\exp(-\\mathbf{x}^\\top\\boldsymbol{\\beta})}$\n- **类别预测**：$\\hat{y} = \\mathbb{I}(\\hat{p} > \\text{threshold})$\n\n## 金融问题中的回归 vs 分类\n\n:::{.callout-note icon=false}\n### 📌 案例：预测股票未来收益\n\n**同一问题，两种表述**：\n\n**回归表述**：\n- 标签：$y = r_{t+1}$（下期实际收益率）\n- 预测：$\\hat{r}_{t+1} = f(\\mathbf{x}_t)$\n- 评估指标：$R^2$, RMSE, IC（信息系数）\n\n**分类表述**：\n- 标签：$y = \\mathbb{I}(r_{t+1} > 0)$（涨或跌）\n- 预测：$\\hat{p}_{t+1} = P(r_{t+1} > 0 | \\mathbf{x}_t)$\n- 评估指标：AUC, 精确率, 召回率\n\n**选择依据**：\n- 若关心收益大小的准确性 → 回归\n- 若关心方向判断与排序 → 分类\n- 若后续构建多空组合 → 两者皆可（收益预测或概率排序）\n:::\n\n# 偏差–方差分解与泛化误差\n\n## 为什么模型会过拟合？\n\n**核心问题**：训练集表现优异的模型，为何在新数据上表现很差？\n\n答案在于**泛化误差的分解**。\n\n## 偏差–方差分解（Bias-Variance Decomposition）\n\n对于回归任务，测试点 $\\mathbf{x}_0$ 处的期望预测误差可分解为：\n\n$$\n\\mathbb{E}[(y_0 - \\hat{f}(\\mathbf{x}_0))^2] = \\underbrace{[\\mathbb{E}(\\hat{f}(\\mathbf{x}_0)) - f(\\mathbf{x}_0)]^2}_{\\text{偏差}^2} + \\underbrace{\\mathbb{E}[(\\hat{f}(\\mathbf{x}_0) - \\mathbb{E}(\\hat{f}(\\mathbf{x}_0)))^2]}_{\\text{方差}} + \\underbrace{\\sigma^2}_{\\text{不可约误差}}\n$$\n\n### 三个成分的含义\n\n1. **偏差（Bias）**：\n   - 模型的系统性误差\n   - 反映模型的**拟合能力**\n   - 过于简单的模型 → 高偏差（欠拟合）\n\n2. **方差（Variance）**：\n   - 模型对训练数据的敏感度\n   - 反映模型的**稳定性**\n   - 过于复杂的模型 → 高方差（过拟合）\n\n3. **不可约误差（Irreducible Error）**：\n   - 数据本身的噪声 $\\sigma^2$\n   - 任何模型都无法消除\n\n## 过拟合的统计根源\n\n过拟合本质上是**高方差**问题：\n\n- 模型过于复杂，捕捉了训练数据中的噪声\n- 在训练集上表现优异（低偏差，甚至零偏差）\n- 在测试集上表现很差（高方差）\n\n:::{.callout-warning}\n### ⚠️ 金融数据中的过拟合陷阱\n\n金融数据的**低信噪比**特点使过拟合问题尤为严重：\n\n- 股票收益的可预测成分很小（$R^2$ 通常 < 5%）\n- 复杂模型容易将噪声误认为信号\n- 样本外表现往往远低于样本内\n:::\n\n## 学习曲线（Learning Curves）\n\n**训练误差 vs 测试误差**随样本量的变化：\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![学习曲线示意图](week1_files/figure-pdf/cell-2-output-1.pdf){}\n:::\n:::\n\n\n**关键观察**：\n\n- **欠拟合**：训练误差和测试误差都很高，且接近\n- **过拟合**：训练误差很低，但测试误差远高于训练误差\n- **良好拟合**：两者适度分离，随样本增加而收敛\n\n# 从 ERM 到 SRM：正则化与模型选择\n\n## 经验风险最小化（ERM）\n\n**标准监督学习**就是在训练集上最小化损失：\n\n$$\n\\hat{f} = \\arg\\min_{f \\in \\mathcal{F}} \\frac{1}{n}\\sum_{i=1}^n L(y_i, f(\\mathbf{x}_i))\n$$\n\n问题：当模型族 $\\mathcal{F}$ 太丰富时，容易过拟合。\n\n## 结构风险最小化（SRM）\n\n**核心思想**：在损失函数中加入模型复杂度惩罚：\n\n$$\n\\hat{f} = \\arg\\min_{f \\in \\mathcal{F}} \\left[\\frac{1}{n}\\sum_{i=1}^n L(y_i, f(\\mathbf{x}_i)) + \\lambda \\cdot \\text{Complexity}(f)\\right]\n$$\n\n其中 $\\lambda > 0$ 是**正则化参数**，控制复杂度惩罚的强度。\n\n## 线性模型中的正则化\n\n对于线性回归 $\\hat{y} = \\mathbf{x}^\\top \\boldsymbol{\\beta}$，常见正则化方法：\n\n### 1. 岭回归（Ridge Regression）\n\n$$\n\\hat{\\boldsymbol{\\beta}}^{\\text{ridge}} = \\arg\\min_{\\boldsymbol{\\beta}} \\left[\\sum_{i=1}^n (y_i - \\mathbf{x}_i^\\top\\boldsymbol{\\beta})^2 + \\lambda \\sum_{j=1}^p \\beta_j^2\\right]\n$$\n\n**特点**：\n\n- $L_2$ 惩罚：$\\|\\boldsymbol{\\beta}\\|_2^2$\n- 系数**收缩**但不会变为零\n- 适合特征间**多重共线性**严重的情况\n- 闭式解：$\\hat{\\boldsymbol{\\beta}}^{\\text{ridge}} = (\\mathbf{X}^\\top\\mathbf{X} + \\lambda \\mathbf{I})^{-1}\\mathbf{X}^\\top\\mathbf{y}$\n\n### 2. Lasso 回归\n\n$$\n\\hat{\\boldsymbol{\\beta}}^{\\text{lasso}} = \\arg\\min_{\\boldsymbol{\\beta}} \\left[\\sum_{i=1}^n (y_i - \\mathbf{x}_i^\\top\\boldsymbol{\\beta})^2 + \\lambda \\sum_{j=1}^p |\\beta_j|\\right]\n$$\n\n**特点**：\n\n- $L_1$ 惩罚：$\\|\\boldsymbol{\\beta}\\|_1$\n- 产生**稀疏解**：部分系数精确为零\n- 具有**变量选择**功能\n- 适合特征维度高、真正重要特征少的情况\n\n### 3. 弹性网（Elastic Net）\n\n$$\n\\hat{\\boldsymbol{\\beta}}^{\\text{enet}} = \\arg\\min_{\\boldsymbol{\\beta}} \\left[\\sum_{i=1}^n (y_i - \\mathbf{x}_i^\\top\\boldsymbol{\\beta})^2 + \\lambda_1 \\sum_{j=1}^p |\\beta_j| + \\lambda_2 \\sum_{j=1}^p \\beta_j^2\\right]\n$$\n\n**特点**：\n\n- 结合 $L_1$ 和 $L_2$ 惩罚\n- 在相关特征间**更稳定**\n- 兼具变量选择与群组效应\n\n:::{.callout-tip}\n### 💡 金融应用中的选择建议\n\n- **岭回归**：特征多重共线性严重（如多个估值指标）\n- **Lasso**：特征数量远大于样本（如大量技术指标）\n- **弹性网**：需要稳定的变量选择（如构建可解释的因子模型）\n:::\n\n## i.i.d. 假设下的数据划分\n\n### 训练-验证-测试三分法\n\n```\n原始数据\n    ↓\n┌─────────────────────────────────────┐\n│ 训练集 (60%)  │ 验证集 (20%) │ 测试集 (20%) │\n└─────────────────────────────────────┘\n     ↓               ↓              ↓\n  训练模型      选择超参数       最终评估\n```\n\n**职责分工**：\n\n1. **训练集**：拟合模型参数（如 $\\boldsymbol{\\beta}$）\n2. **验证集**：选择超参数（如 $\\lambda$）与模型比较\n3. **测试集**：仅用一次，报告最终泛化性能\n\n:::{.callout-caution}\n### ⚠️ 常见错误\n\n**重复使用测试集**会导致\"数据窥探\"（data snooping），使测试性能失去公正性！\n:::\n\n### K 折交叉验证（K-Fold Cross-Validation）\n\n当数据量有限时，更充分利用数据：\n\n```\n原始数据切分为 K 份（如 K=5）：\n┌────┬────┬────┬────┬────┐\n│ 1  │ 2  │ 3  │ 4  │ 5  │\n└────┴────┴────┴────┴────┘\n\nFold 1: [2,3,4,5] 训练, [1] 验证\nFold 2: [1,3,4,5] 训练, [2] 验证\nFold 3: [1,2,4,5] 训练, [3] 验证\nFold 4: [1,2,3,5] 训练, [4] 验证\nFold 5: [1,2,3,4] 训练, [5] 验证\n\n最终性能 = 5 次验证误差的平均\n```\n\n:::{.callout-important}\n### 🚨 金融数据的特殊性\n\n**K 折交叉验证仅适用于 i.i.d. 数据！**\n\n金融时序数据必须用**滚动窗口**或**扩展窗口**评估（详见第2周）。\n:::\n\n# 关键评估指标体系\n\n模型好坏必须用**与研究目标一致**的指标衡量。\n\n## 回归任务指标\n\n### 1. 均方误差（MSE）与均方根误差（RMSE）\n\n$$\n\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2, \\quad \\text{RMSE} = \\sqrt{\\text{MSE}}\n$$\n\n- RMSE 与 $y$ 同量纲，更易解释\n\n### 2. 平均绝对误差（MAE）\n\n$$\n\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i|\n$$\n\n- 对异常值更鲁棒\n\n### 3. 决定系数（$R^2$）\n\n$$\nR^2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}\n$$\n\n- 衡量模型解释的方差比例\n- 样本内 $R^2$ 总是 $\\leq 1$\n\n### 4. 样本外 $R^2$（Out-of-Sample $R^2$）\n\n$$\nR^2_{\\text{OOS}} = 1 - \\frac{\\sum_{i \\in \\text{test}} (y_i - \\hat{y}_i)^2}{\\sum_{i \\in \\text{test}} (y_i - \\bar{y}_{\\text{train}})^2}\n$$\n\n- **可能为负**（模型比历史均值还差）\n- 金融资产定价中的关键指标\n\n## 分类任务指标\n\n### 1. 对数损失（Log-loss）\n\n$$\n\\text{Log-loss} = -\\frac{1}{n}\\sum_{i=1}^n [y_i \\log(\\hat{p}_i) + (1-y_i)\\log(1-\\hat{p}_i)]\n$$\n\n- 衡量概率预测的质量\n- 对错误预测的惩罚更重\n\n### 2. AUC-ROC 曲线下面积\n\n**ROC 曲线**：不同阈值下的真正例率（TPR）vs 假正例率（FPR）\n\n$$\n\\text{TPR} = \\frac{\\text{TP}}{\\text{TP}+\\text{FN}}, \\quad \\text{FPR} = \\frac{\\text{FP}}{\\text{FP}+\\text{TN}}\n$$\n\n**AUC**（Area Under Curve）：\n\n- 范围 [0, 1]，越大越好\n- 0.5 表示随机猜测\n- **解释**：随机选一对（正例，负例），模型对正例打分更高的概率\n\n### 3. AUC-PR（Precision-Recall 曲线）\n\n**精确率与召回率**：\n\n$$\n\\text{Precision} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}}, \\quad \\text{Recall} = \\frac{\\text{TP}}{\\text{TP}+\\text{FN}}\n$$\n\n**适用场景**：类别极不平衡时（如信用违约、欺诈检测）\n\n### 4. F1 分数\n\n$$\nF_1 = 2 \\cdot \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n$$\n\n- 精确率与召回率的调和平均\n- 单一阈值下的综合指标\n\n### 5. 校准（Calibration）\n\n预测概率 $\\hat{p}$ 与实际频率是否一致？\n\n**校准图**：将样本按 $\\hat{p}$ 分桶，检查每桶内正例的真实比例。\n\n:::{.callout-tip}\n### 💡 指标选择的黄金法则\n\n**先明确研究目标，再选指标**：\n\n- 关心排序 → AUC-ROC\n- 关心不平衡分类 → AUC-PR, F1\n- 关心概率准确性 → Log-loss, 校准\n- 关心数值预测 → MSE, MAE, $R^2$\n:::\n\n## 类别不平衡的常见误区\n\n**案例**：预测信用违约，违约率 1%。\n\n❌ **错误做法**：\n\n```python\n# 模型预测所有人都不违约\naccuracy = 0.99  # 准确率 99%！\n```\n\n虽然准确率很高，但模型毫无用处！\n\n✅ **正确做法**：\n\n- 使用 AUC-PR、F1、召回率等指标\n- 考虑代价敏感学习\n- 调整决策阈值以平衡误报与漏报\n\n# 机器学习的最小证据链\n\n## 什么是\"最小证据链\"？\n\n**定义**：从原始数据到研究结论，**可审计、可复现、可信任**的完整证据路径。\n\n:::{.callout-note icon=false}\n### 📋 最小证据链检查清单\n\n1. ✅ **数据与标签定义**\n   - 数据来源、版本、时间范围\n   - 标签如何定义（含信息可得性说明）\n   - 缺失值、异常值如何处理\n\n2. ✅ **预处理规则**\n   - 标准化、归一化方式\n   - 特征工程步骤\n   - 缺失值填充策略\n\n3. ✅ **划分与评估策略**\n   - 训练-验证-测试如何划分\n   - i.i.d. 还是时序评估\n   - 超参数选择方法\n\n4. ✅ **基准模型**\n   - 简单基准（历史均值、线性模型等）\n   - 与既有文献的对比\n\n5. ✅ **样本外结果**\n   - 主要指标与置信区间\n   - 切片评估（按时间、行业等）\n   - 稳健性检验（换特征、换窗口等）\n\n6. ✅ **可复现性材料**\n   - 代码与随机种子\n   - 变量字典与流程图\n   - 环境配置说明\n:::\n\n## 为什么强调\"最小\"？\n\n- **可行性**：要求过高会降低研究效率\n- **聚焦核心**：抓住信息泄露、不可复现等关键风险点\n- **可审计**：评审者/读者能快速验证研究可信度\n\n:::{.callout-warning}\n### ⚠️ 常见缺失环节\n\n1. **信息可得性说明不清**：用了未来数据或不可交易的信息\n2. **预处理不透明**：标准化用了全局统计量（含测试集信息）\n3. **超参数选择不规范**：在测试集上调参\n4. **只报最好结果**：隐藏失败尝试，过度拟合\n5. **无代码或种子**：结果无法复现\n:::\n\n# 本周小结\n\n## 核心要点\n\n1. **监督学习框架**：回归 vs 分类，损失函数决定模型行为\n2. **过拟合根源**：偏差–方差权衡，复杂模型 + 噪声数据 → 高方差\n3. **正则化**：岭/Lasso/弹性网，控制复杂度，提升泛化能力\n4. **评估规范**：训练-验证-测试分工，指标与目标一致\n5. **最小证据链**：可审计、可复现的研究规范\n\n## 本周思考题\n\n### 问题 1\n\n将\"预测未来收益率\"分别表述为回归任务与分类任务时，标签应如何定义？两种表述分别应优先使用哪些评价指标？\n\n:::{.callout-note collapse=\"true\"}\n### 💡 参考答案\n\n**回归表述**：\n\n- 标签：$y = r_{t+h}$（未来 $h$ 期的实际收益率）\n- 优先指标：MSE、MAE、$R^2$、样本外 $R^2$、IC（信息系数）\n\n**分类表述**：\n\n- 标签：$y = \\mathbb{I}(r_{t+h} > \\text{threshold})$（如涨跌、超额收益正负）\n- 优先指标：AUC-ROC、Log-loss、Rank-IC（排序相关性）\n\n**选择依据**：若后续构建组合，**分类表述的排序能力**往往更重要。\n:::\n\n### 问题 2\n\n用偏差–方差分解解释：为什么更复杂的模型可能在训练集更好，但在样本外更差？\n\n:::{.callout-note collapse=\"true\"}\n### 💡 参考答案\n\n- **训练集**：复杂模型可降低偏差（更灵活拟合），训练误差↓\n- **测试集**：复杂模型方差高（对训练数据过敏感），捕捉噪声\n- **结果**：测试误差 = 偏差² + 方差 + 不可约误差，方差项主导↑\n\n**关键**：训练误差只反映偏差，不反映方差！\n:::\n\n### 问题 3\n\n请列出\"最小证据链\"中你认为最容易被忽视的两项，并说明忽视它们可能带来的误判。\n\n:::{.callout-note collapse=\"true\"}\n### 💡 参考答案示例\n\n1. **信息可得性说明**\n   - 忽视后果：使用未来数据（look-ahead bias），样本内指标虚高\n   - 实例：用当期年报数据预测当期收益（年报披露有滞后）\n\n2. **随机种子与环境配置**\n   - 忽视后果：结果无法复现，无法验证真实性\n   - 实例：不同机器/版本得到不同结果，研究可信度存疑\n:::\n\n---\n\n## 下周预告\n\n第2周将进入**金融场景的特殊性**：\n\n- 时序数据如何评估（滚动窗口、嵌套CV）\n- 回测卫生清单（存活偏误、信息泄露等）\n- 从预测到交易：组合构建与成本后评估\n\n请提前阅读：\n\n- Gu, Kelly & Xiu (2020) *Empirical asset pricing via machine learning*\n- Kelly & Xiu (2023), Chapters 3-5\n\n**预习提示**：在文中找出\"预测表现好但不可交易\"的证据或讨论点，带到课上！\n\n",
    "supporting": [
      "week1_files/figure-pdf"
    ],
    "filters": []
  }
}