{"title":"第3讲：文本分析理论 → 金融文本应用","markdown":{"yaml":{"title":"第3讲：文本分析理论 → 金融文本应用","subtitle":"从原始文本到可审计的量化变量"},"headingText":"本周目标与三条底线","containsRefs":false,"markdown":"\n\n\n### 课程主线回顾\n\n**泛化—正则化—评估**三位一体，在文本分析中的体现：\n\n- **泛化**：文本模型能否推广到新文档、新时期？\n- **正则化**：如何避免过拟合（特别是词典法的多重比较、LLM 的过度调优）？\n- **评估**：文本变量是否带来增量信息？\n\n### 三条底线\n\n:::{.callout-important}\n🎯 不可突破的红线\n\n1. **信息可得性**：不含前瞻信息（look-ahead bias）\n2. **过程可审计**：从原始文本到变量的每一步可追溯\n3. **结果可复现**：代码、模型版本、预处理规则完整记录\n:::\n\n这三条底线确保研究的**科学性**与**可信度**。\n\n## 文本表示方法演进\n\n### 文本分析的核心挑战\n\n**原始文本**是非结构化数据：\n\n```\n\"The company's revenue grew by 15% year-over-year, \ndriven by strong demand in emerging markets.\"\n```\n\n**目标**：转化为数值特征，用于预测/分类/聚类等任务。\n\n**挑战**：\n\n- 维度高（词汇量巨大）\n- 稀疏（单个文档只用少量词）\n- 顺序性（语序承载语义）\n- 歧义性（一词多义、多词一义）\n\n### 方法谱系：从简单到复杂\n\n#### 词袋模型（Bag-of-Words, BoW）\n\n**思想**：将文本表示为词频向量，忽略语序。\n\n**步骤**：\n\n1. **分词**（Tokenization）：\n   ```\n   \"revenue grew by 15%\" → [\"revenue\", \"grew\", \"by\", \"15%\"]\n   ```\n\n2. **构建词汇表**（Vocabulary）：\n   ```\n   V = {revenue, grew, company, market, ...}  # 假设 |V| = 10,000\n   ```\n\n3. **向量化**：\n   ```\n   文档 → [0, 2, 0, 1, ..., 0]  # 长度 = |V|\n          ↑     ↑  ↑\n       revenue出现0次\n          grew出现2次\n            ...\n   ```\n\n**变体：TF-IDF**（Term Frequency–Inverse Document Frequency）\n\n$$\n\\text{TF-IDF}(w, d) = \\underbrace{\\frac{\\text{count}(w, d)}{|d|}}_{\\text{词频}} \\times \\underbrace{\\log\\frac{N}{\\text{df}(w)}}_{\\text{逆文档频率}}\n$$\n\n- 降低常见词（如\"的\"、\"是\"）的权重\n- 提升区分性强的词的权重\n\n**优点**：\n\n- 简单、可解释\n- 计算高效\n- 适合作为基准\n\n**缺点**：\n\n- 忽略语序（\"not good\" vs \"good not\"）\n- 维度高、稀疏\n- 无法捕捉语义相似性（\"revenue\" vs \"sales\"）\n\n#### 词典法（Dictionary-based Methods）\n\n**思想**：用**预定义词表**匹配文本，计算情感/主题得分。\n\n**经典词典**：\n\n- **Loughran-McDonald (2011)**：金融情感词典\n  - Positive: {growth, profit, gain, ...}\n  - Negative: {loss, risk, decline, ...}\n- **Harvard IV-4**：心理学词典\n- **自定义词典**：针对特定任务\n\n**计算**：\n\n$$\n\\text{Sentiment Score} = \\frac{\\#\\text{Positive Words} - \\#\\text{Negative Words}}{\\#\\text{Total Words}}\n$$\n\n**金融应用案例**：\n\n```python\n# 年报文本情感分析\npositive_words = {'growth', 'profit', 'opportunity', ...}\nnegative_words = {'loss', 'risk', 'decline', 'uncertainty', ...}\n\ndef sentiment(text):\n    tokens = tokenize(text.lower())\n    pos = sum(1 for w in tokens if w in positive_words)\n    neg = sum(1 for w in tokens if w in negative_words)\n    return (pos - neg) / len(tokens)\n```\n\n**优点**：\n\n- 高度可解释（可追溯到具体词）\n- 稳定（不需训练）\n- 适合监管审计\n\n**缺点**：\n\n- 忽略上下文（\"not good\" 被误判为正面）\n- 词典覆盖不全\n- 行业/时期特异性（\"viral\" 在生物 vs 营销中含义不同）\n\n:::{.callout-tip}\n💡 何时用词典法？\n\n- **可解释性要求高**（如监管报告）\n- **领域词典成熟**（如金融、医疗）\n- **作为基准**（与 ML 方法对比）\n:::\n\n#### 主题模型（Topic Models）\n\n**思想**：无监督学习，发现文档的**潜在主题**。\n\n**经典算法：LDA（Latent Dirichlet Allocation）**\n\n**假设**：\n\n- 每个文档是多个主题的混合\n- 每个主题是词的概率分布\n\n**示例**（K=3 个主题）：\n\n```\n文档1: 70% 主题A（科技） + 20% 主题B（金融） + 10% 主题C（政策）\n文档2: 10% 主题A + 80% 主题B + 10% 主题C\n\n主题A: {AI: 0.05, algorithm: 0.04, data: 0.03, ...}\n主题B: {stock: 0.06, market: 0.05, trading: 0.04, ...}\n主题C: {government: 0.05, regulation: 0.04, policy: 0.03, ...}\n```\n\n**提取特征**：\n\n- 文档的主题分布向量：$\\boldsymbol{\\theta}_d = [\\theta_{d,1}, \\ldots, \\theta_{d,K}]$\n\n**金融应用**：\n\n- 年报主题分析（技术创新 vs 财务风险）\n- 新闻聚类（宏观 vs 行业 vs 个股）\n\n**优点**：\n\n- 降维（数万维 → K 维）\n- 可解释（主题词）\n- 无监督\n\n**缺点**：\n\n- 主题数量 K 需人工选择\n- 主题解释主观\n- 计算成本高\n\n#### 词嵌入（Word Embeddings）\n\n**思想**：将词映射到**低维连续向量空间**，语义相似的词距离近。\n\n**经典模型：Word2Vec (Mikolov et al., 2013)**\n\n**训练目标**（Skip-gram）：\n\n给定中心词，预测上下文词。\n\n**结果**：\n\n```\nrevenue: [0.2, -0.5, 0.8, ...]  # 300维向量\nsales:   [0.21, -0.48, 0.79, ...]  # 距离很近\nprofit:  [0.18, -0.52, 0.75, ...]\n```\n\n**著名性质**：\n\n$$\n\\text{vec}(\\text{king}) - \\text{vec}(\\text{man}) + \\text{vec}(\\text{woman}) \\approx \\text{vec}(\\text{queen})\n$$\n\n**文档表示**：\n\n- 简单平均：$\\mathbf{v}_{\\text{doc}} = \\frac{1}{|d|}\\sum_{w \\in d} \\mathbf{v}_w$\n- 加权平均（TF-IDF 权重）\n\n**优点**：\n\n- 捕捉语义相似性\n- 预训练模型可直接用（如 Google News Word2Vec）\n\n**缺点**：\n\n- 静态（\"bank\" 在不同上下文中向量相同）\n- 文档表示过于粗糙（简单平均丢失语序）\n\n#### Transformer 与 BERT\n\n**革命性突破**：**上下文化嵌入**（Contextualized Embeddings）\n\n**BERT（Bidirectional Encoder Representations from Transformers）**\n\n- Devlin et al. (2019)\n\n**核心思想**：\n\n- 同一个词在不同上下文中有**不同的向量**\n- 双向注意力机制（Transformer）\n\n**示例**：\n\n```\n句1: \"I went to the bank to deposit money.\"\n     → \"bank\" 向量偏向\"金融机构\"\n\n句2: \"I sat by the river bank.\"\n     → \"bank\" 向量偏向\"河岸\"\n```\n\n**预训练任务**：\n\n1. **Masked Language Modeling (MLM)**：\n   ```\n   输入: \"The company's [MASK] grew by 15%.\"\n   预测: revenue / profit / sales\n   ```\n\n2. **Next Sentence Prediction (NSP)**：\n   ```\n   句A: \"Revenue increased.\"\n   句B: \"Profit margins improved.\"\n   预测: B 是否是 A 的下一句？\n   ```\n\n**金融领域预训练模型**：\n\n- **FinBERT** (Araci, 2019)：在金融新闻/年报上微调\n- **DistilRoBERTa-financial-sentiment**：轻量级金融情感分类\n\n**使用流程**：\n\n```python\nfrom transformers import AutoTokenizer, AutoModel\n\n# 加载预训练模型\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModel.from_pretrained(\"ProsusAI/finbert\")\n\n# 文本编码\ntext = \"The company reported strong earnings growth.\"\ninputs = tokenizer(text, return_tensors=\"pt\")\noutputs = model(**inputs)\n\n# 提取 [CLS] token 的嵌入作为文档表示\ndoc_embedding = outputs.last_hidden_state[:, 0, :]  # (1, 768)\n```\n\n**优点**：\n\n- **最强语义表达**\n- 迁移学习：预训练 + 微调\n- 最新 SOTA 性能\n\n**缺点**：\n\n- **计算成本高**（需 GPU）\n- **不易复现**（模型更新频繁）\n- **可解释性差**（黑箱）\n- **版本控制难**（模型文件大）\n\n:::{.callout-warning}\n⚠️ 使用 BERT/LLM 的规范要求\n\n1. **锁定模型版本**：记录精确的模型名称与版本号\n   ```python\n   # 好：明确版本\n   model = AutoModel.from_pretrained(\"bert-base-uncased\", revision=\"abc123\")\n   \n   # 差：版本不确定\n   model = AutoModel.from_pretrained(\"bert-base-uncased\")\n   ```\n\n2. **固定随机种子**：微调时保证可复现\n   ```python\n   set_seed(42)\n   ```\n\n3. **记录计算环境**：\n   ```\n   transformers==4.36.0\n   torch==2.1.0\n   CUDA==11.8\n   ```\n\n4. **提供推理代码**：完整的预处理 + 模型推理流程\n:::\n\n### 方法选择决策树\n\n```\n是否需要高度可解释？\n├─ 是 → 词典法（如 LM 情感词典）\n└─ 否 → 有监督学习任务？\n        ├─ 是 → 有标注数据？\n        │       ├─ 是 → 数据量大（>10K）？\n        │       │       ├─ 是 → BERT 微调\n        │       │       └─ 否 → TF-IDF + 传统 ML\n        │       └─ 否 → 词典法或主题模型\n        └─ 否（无监督）→ 主题模型（LDA）或预训练嵌入\n```\n\n## 语料治理：从原始文档到可用观测值\n\n### 核心原则\n\n**语料治理**（Corpus Curation）确保：\n\n1. **版本锁定**：使用哪个版本的文档？\n2. **时间戳准确**：何时发布？何时市场可得？\n3. **实体对齐**：文档对应哪个公司/人物/事件？\n4. **去噪**：去除无关/重复/错误内容\n\n### 版本锁定\n\n#### 问题：事后修订\n\n**案例**：上市公司年报\n\n- **首次披露**：2024-04-30，原始版本\n- **修订版**：2024-06-15，更正财务数据\n\n**错误做法**：\n\n使用数据库中的\"最新版\"（可能是修订后的）\n\n**正确做法**：\n\n使用**首次披露版本**（as-filed version）\n\n**实施**：\n\n```python\n# 记录文档版本信息\ndf['document_id'] = \"10-K_AAPL_2023_v1\"  # 版本号\ndf['file_date'] = \"2024-04-30\"          # 首次提交日期\ndf['revision_date'] = None               # 若无修订\n```\n\n#### SEC EDGAR 数据示例\n\n```python\nimport requests\n\n# 获取首次提交版本\nurl = \"https://www.sec.gov/cgi-bin/viewer?action=view&cik=320193&accession_number=0000320193-24-000001&xbrl_type=v\"\nresponse = requests.get(url, headers={'User-Agent': 'your-email@example.com'})\n```\n\n### 时间戳与可得性规则\n\n#### 何时\"市场可得\"？\n\n| 文本类型 | 发布时间 | 市场反应窗口 |\n|---------|---------|-------------|\n| **年报/季报** | 收盘后或次日开盘前 | 次日开盘起 |\n| **新闻** | 实时 | 发布时刻起 |\n| **分析师报告** | 工作日盘前/盘后 | 发布时刻起 |\n| **社交媒体** | 实时 | 发布时刻起 |\n| **财报电话会** | 盘后固定时间 | 会议结束后 |\n\n**关键规则**：\n\n$$\n\\text{用于预测 } t \\text{ 日收益的文本} \\Rightarrow \\text{必须在 } t \\text{ 日开盘前发布}\n$$\n\n#### 对齐代码示例\n\n```python\n# 年报对齐\ndef align_report(df):\n    # 假设年报在披露日的次日才可交易\n    df['available_date'] = df['file_date'] + pd.Timedelta(days=1)\n    \n    # 对齐到交易日\n    df['available_date'] = df['available_date'].apply(\n        lambda d: next_trading_day(d)\n    )\n    \n    # 构造标签：用披露后首个交易日收益\n    df['target_return'] = df.groupby('ticker')['return'].shift(-1)\n    \n    return df\n```\n\n### 实体识别与对齐\n\n#### 挑战：一个实体，多种表述\n\n**案例**：苹果公司\n\n- 正式名称：\"Apple Inc.\"\n- 股票代码：\"AAPL\"\n- 常见别名：\"Apple\", \"苹果\", \"库比蒂诺公司\"\n\n#### 解决方案：实体链接（Entity Linking）\n\n**步骤**：\n\n1. **命名实体识别（NER）**：识别文本中的公司名\n   ```python\n   # 使用 spaCy\n   import spacy\n   nlp = spacy.load(\"en_core_web_sm\")\n   doc = nlp(\"Apple reported strong earnings.\")\n   entities = [(ent.text, ent.label_) for ent in doc.ents]\n   # [('Apple', 'ORG')]\n   ```\n\n2. **链接到标准 ID**：\n   ```python\n   entity_map = {\n       'Apple': 'AAPL',\n       'Apple Inc.': 'AAPL',\n       '苹果': 'AAPL',\n       ...\n   }\n   ticker = entity_map.get(entity_name, None)\n   ```\n\n3. **歧义消解**：\n   - \"Apple\" 可能是公司或水果\n   - 用上下文判断（如出现\"stock\", \"earnings\"）\n\n#### 金融专用工具\n\n- **FinBERT-NER**：金融实体识别\n- **OpenFIGI API**：金融工具标识符查询\n- **Wikidata/DBpedia**：知识图谱链接\n\n### 去重与噪声处理\n\n#### 常见噪声类型\n\n1. **模板文本**\n\n年报中的法律声明、标准段落：\n\n```\n\"Forward-looking statements involve risks and uncertainties...\"\n```\n\n**处理**：\n\n- 识别高频重复段落\n- 在情感分析前删除\n\n```python\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# 识别模板（在多个文档中高频出现的句子）\nsentences = extract_sentences(all_documents)\nvectorizer = TfidfVectorizer()\ntfidf = vectorizer.fit_transform(sentences)\n# 计算句子在文档间的相似度，删除重复率高的\n```\n\n2. **乱码与编码错误**\n\n```\n\"The companyâ€™s revenue...\"  # Unicode 错误\n```\n\n**处理**：\n\n```python\nimport ftfy\ntext_clean = ftfy.fix_text(text_raw)\n```\n\n3. **OCR/ASR 错误**\n\n扫描文档或语音转文字的错误：\n\n```\nOCR: \"The company's net income...\" → \"The c0mpany's net inc0me...\"\nASR: \"fiscal year\" → \"physical year\"\n```\n\n**处理**：\n\n- 使用高质量的原始文件（PDF 带文字层）\n- 检查关键词错误率\n- 后处理：拼写检查、上下文纠错\n\n#### 去重\n\n**文档级去重**：\n\n- 计算文档相似度（如余弦相似度）\n- 删除近似重复（如转载新闻）\n\n```python\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# 计算 TF-IDF 向量的相似度矩阵\nsimilarity = cosine_similarity(tfidf_matrix)\n\n# 删除相似度 > 0.95 的文档对\nduplicates = np.argwhere((similarity > 0.95) & (similarity < 1.0))\n```\n\n## 从原始文本到量化变量的可审计流程\n\n### 流程图\n\n```\n原始文档（PDF/HTML/TXT）\n    ↓\n① 版本确认 & 时间戳记录\n    ↓\n② 文本提取 & 编码修正\n    ↓\n③ 实体识别 & 对齐\n    ↓\n④ 预处理（分词、去停用词、去模板）\n    ↓\n⑤ 特征提取（词典/主题/嵌入）\n    ↓\n⑥ 变量构造（聚合、标准化）\n    ↓\n⑦ 质量检验 & 异常值处理\n    ↓\n可用于建模的变量\n```\n\n### 各步骤的可审计要求\n\n#### ① 版本确认 & 时间戳\n\n**记录**：\n\n```python\nmetadata = {\n    'document_id': 'unique_id',\n    'source': 'SEC EDGAR',\n    'url': 'https://...',\n    'file_date': '2024-04-30',\n    'download_date': '2024-05-01',\n    'version': 'v1'\n}\n```\n\n#### ② 文本提取\n\n**工具与参数**：\n\n```python\n# PDF 提取\nimport pdfplumber\nwith pdfplumber.open(pdf_path) as pdf:\n    text = '\\n'.join([page.extract_text() for page in pdf.pages])\n\n# 记录工具版本\nmetadata['extraction_tool'] = f'pdfplumber=={pdfplumber.__version__}'\n```\n\n#### ③ 实体识别 & 对齐\n\n**记录**：\n\n```python\nmetadata['ner_model'] = 'en_core_web_sm-3.7.0'\nmetadata['entity_map_version'] = 'v2024.1'\n```\n\n#### ④ 预处理\n\n**记录每一步**：\n\n```python\npreprocessing_steps = [\n    'lowercasing',\n    'remove_punctuation',\n    'remove_stopwords: nltk.corpus.stopwords (english)',\n    'stemming: PorterStemmer',\n]\n```\n\n#### ⑤ 特征提取\n\n**词典法**：\n\n```python\nsentiment_dict = {\n    'version': 'Loughran-McDonald 2020',\n    'positive_words': len(positive_words),\n    'negative_words': len(negative_words),\n}\n```\n\n**BERT**：\n\n```python\nmodel_info = {\n    'model_name': 'ProsusAI/finbert',\n    'model_revision': 'abc123',\n    'framework': 'transformers==4.36.0',\n    'device': 'cuda:0',\n}\n```\n\n#### ⑥ 变量构造\n\n**公式记录**：\n\n```python\n# 情感得分\nvariable_definition = \"\"\"\nsentiment = (n_positive - n_negative) / n_total\nwhere:\n  n_positive: count of words in LM positive dictionary\n  n_negative: count of words in LM negative dictionary\n  n_total: total word count (excluding stopwords)\n\"\"\"\n```\n\n#### ⑦ 质量检验\n\n**检查清单**：\n\n- 缺失值比例（若 > 20%，说明为何）\n- 异常值（极端情感得分）\n- 时间序列连续性（是否有长期缺失）\n- 横截面覆盖率（行业/市值分布）\n\n## 交付物：变量字典\n\n**示例**：\n\n| 变量名 | 定义 | 来源 | 更新频率 | 处理方法 | 缺失值 |\n|-------|-----|------|---------|---------|--------|\n| `sentiment_lm` | LM 情感得分 | 年报 MD&A 部分 | 年度 | LM 词典匹配 | 前向填充 |\n| `topic_tech` | 技术创新主题强度 | 年报全文 | 年度 | LDA (K=10) | 0填充 |\n| `uncertainty` | 不确定性词频 | 电话会文本 | 季度 | 自定义词典 | 删除 |\n\n## 文本变量评估与增量价值检验\n\n### 评估的三个层次\n\n#### 层次 1：描述性统计\n\n**基本检查**：\n\n- 均值、中位数、标准差\n- 时间趋势（是否异常跳跃？）\n- 横截面分布（是否过于集中？）\n\n**示例**：\n\n```python\n# 情感得分的时间序列\ndf.groupby('year')['sentiment'].mean().plot()\n\n# 横截面分布\ndf['sentiment'].hist(bins=50)\n```\n\n#### 层次 2：与已知因子的关系\n\n**问题**：文本变量是否只是已知因子的\"马甲\"？\n\n**检验**：\n\n1. **相关性分析**\n\n```python\nimport pandas as pd\n\n# 计算与 Fama-French 因子的相关性\ncorr = df[['sentiment', 'size', 'value', 'momentum']].corr()\nprint(corr['sentiment'])\n```\n\n2. **Horse Race 回归**\n\n$$\nr_{i,t+1} = \\alpha + \\beta_1 \\text{Sentiment}_{i,t} + \\beta_2 \\text{Size}_{i,t} + \\beta_3 \\text{Value}_{i,t} + \\varepsilon_{i,t+1}\n$$\n\n**关键问题**：\n\n- $\\beta_1$ 是否显著？\n- 加入文本变量后，模型 $R^2$ 提升多少？\n\n#### 层次 3：增量预测能力\n\n**设计**：\n\n1. **基准模型**（不含文本）\n\n```python\n# 用传统因子预测收益\nmodel_baseline = LinearRegression()\nmodel_baseline.fit(X_baseline, y)  # X_baseline = [size, value, momentum]\nr2_baseline = model_baseline.score(X_test, y_test)\n```\n\n2. **增强模型**（加入文本）\n\n```python\nX_augmented = np.hstack([X_baseline, X_text])  # 加入文本特征\nmodel_augmented = LinearRegression()\nmodel_augmented.fit(X_augmented, y)\nr2_augmented = model_augmented.score(X_test_augmented, y_test)\n```\n\n3. **比较**\n\n$$\n\\Delta R^2 = R^2_{\\text{augmented}} - R^2_{\\text{baseline}}\n$$\n\n**统计检验**：\n\n- Diebold-Mariano 检验（预测误差是否显著不同）\n- 嵌套模型 F 检验\n\n### 切片评估\n\n**不同时期**：\n\n- 牛市 vs 熊市\n- 危机期 vs 平稳期\n\n**不同资产**：\n\n- 大市值 vs 小市值\n- 成长股 vs 价值股\n- 不同行业\n\n**目的**：检验文本变量的普适性与稳健性。\n\n### 互补性 vs 冗余性\n\n**互补**（Complementary）：\n\n- 文本变量捕捉结构化变量未涵盖的信息\n- 例：年报语气（软信息）vs 财务指标（硬信息）\n\n**冗余**（Redundant）：\n\n- 文本变量只是重复已知信息\n- 例：新闻情感 ≈ 过去收益（动量效应）\n\n**证据链**：\n\n1. 相关性适度（0.3-0.7 为佳，过高则冗余）\n2. Horse race 中文本变量仍显著\n3. 分组分析：在结构化因子弱的子样本中，文本变量作用更强\n\n## RAG 与信息抽取的应用边界\n\n### Retrieval-Augmented Generation (RAG)\n\n**定义**：结合检索与生成，用外部知识库增强 LLM。\n\n**流程**：\n\n```\n用户查询\n    ↓\n检索相关文档（如向量数据库）\n    ↓\n拼接为 Prompt\n    ↓\nLLM 生成回答\n```\n\n#### 在金融中的应用\n\n**1. 投研辅助**\n\n```\n查询: \"分析苹果公司 2023 年的供应链风险\"\n  ↓\n检索: AAPL 2023 年报、相关新闻、分析师报告\n  ↓\nLLM: 生成综合分析报告\n```\n\n**2. 合规问答**\n\n```\n查询: \"公司是否违反了反洗钱法规？\"\n  ↓\n检索: 公司内部文档、监管政策\n  ↓\nLLM: 给出合规意见（需人工审核）\n```\n\n#### 边界与风险\n\n:::{.callout-warning}\n⚠️ 使用 RAG/LLM 的注意事项\n\n**不适合用于**：\n\n1. **高风险决策**（如自动批准贷款）\n   - LLM 输出不稳定，可能产生幻觉\n   \n2. **监管敏感场景**（如交易指令生成）\n   - 无法提供可审计的决策依据\n\n3. **实时交易**\n   - 延迟高，难以满足毫秒级要求\n\n**适合用于**：\n\n1. **辅助研究**（生成假设、文献综述）\n2. **内容生成**（研报初稿、客户报告）\n3. **知识管理**（内部文档检索）\n\n**核心原则**：**人机协作**，LLM 作为工具，人类保留最终决策权。\n:::\n\n### 信息抽取（Information Extraction）\n\n**任务**：从非结构化文本中提取结构化信息。\n\n**示例**：\n\n```\n原始文本:\n\"The company announced a $50 million share buyback program, \neffective January 1, 2024.\"\n\n提取结果:\n{\n  'event_type': 'share_buyback',\n  'amount': 50000000,\n  'currency': 'USD',\n  'effective_date': '2024-01-01',\n  'entity': 'The Company'\n}\n```\n\n#### 技术路径\n\n1. **规则 based**（正则表达式）\n   ```python\n   import re\n   pattern = r'\\$(\\d+(?:,\\d{3})*(?:\\.\\d+)?) (million|billion)'\n   match = re.search(pattern, text)\n   ```\n\n2. **机器学习**（NER + Relation Extraction）\n   ```python\n   # 使用 spaCy 的实体关系抽取\n   doc = nlp(text)\n   for ent in doc.ents:\n       if ent.label_ == 'MONEY':\n           amount = ent.text\n   ```\n\n3. **LLM-based**（Few-shot prompting）\n   ```python\n   prompt = f\"\"\"\n   Extract the following information from the text:\n   - Event type\n   - Amount\n   - Effective date\n   \n   Text: {text}\n   \n   Output as JSON.\n   \"\"\"\n   response = llm.generate(prompt)\n   ```\n\n#### 在风控中的应用\n\n**舆情监控**：\n\n- 自动抽取负面事件（诉讼、罚款、高管离职）\n- 实时预警\n\n**尽职调查**：\n\n- 批量处理合同、法律文书\n- 抽取关键条款（违约条件、担保方式等）\n\n## 本周小结\n\n### 核心要点\n\n1. **方法谱系**：词袋 → 词典 → 主题模型 → 词嵌入 → BERT，权衡可解释性与性能\n2. **语料治理**：版本锁定、时间对齐、实体链接、去噪，确保数据质量\n3. **可审计流程**：记录每一步（工具、参数、版本），交付变量字典\n4. **增量价值**：文本变量必须相对已知因子展示增量信息\n5. **应用边界**：RAG/LLM 适合辅助研究，不适合高风险自动决策\n\n### 本周思考题\n\n#### 问题 1\n\nBERT/LLM 构造文本变量相比词典法的优势与风险分别是什么？\n\n:::{.callout-note collapse=\"true\"}\n💡 参考答案\n\n**优势**：\n\n1. **更强语义理解**：捕捉上下文（\"not good\" 正确识别为负面）\n2. **泛化能力**：处理词典未覆盖的表述\n3. **端到端学习**：自动特征提取，减少人工工程\n\n**风险**：\n\n1. **可解释性差**：无法追溯到具体词/短语\n2. **不易复现**：模型版本更新频繁，结果可能变化\n3. **计算成本高**：需 GPU，推理慢\n4. **过拟合风险**：参数多，样本少时易过拟合\n5. **审计困难**：监管难以理解\"黑箱\"模型的决策依据\n:::\n\n#### 问题 2\n\n用新闻预测股价时，如何设计流程避免前瞻偏误？\n\n:::{.callout-note collapse=\"true\"}\n💡 参考答案\n\n**关键步骤**：\n\n1. **记录新闻时间戳**（精确到分钟）\n   ```python\n   df['news_timestamp'] = pd.to_datetime(df['published_time'])\n   ```\n\n2. **对齐到交易时间**\n   - 盘前新闻（9:30前）→ 用于预测当日收益\n   - 盘中/盘后新闻 → 用于预测次日收益\n\n3. **构造标签**\n   ```python\n   # 新闻在 t 日收盘前发布 → 预测 t+1 日收益\n   df['target_date'] = df['news_timestamp'].apply(\n       lambda ts: ts.date() + timedelta(days=1) if ts.hour >= 16 \n                  else ts.date()\n   )\n   df['target_return'] = df.merge(\n       returns, left_on=['ticker', 'target_date'], ...\n   )\n   ```\n\n4. **滚动窗口评估**（避免用未来新闻训练模型）\n\n5. **检验**：人工抽查对齐正确性\n:::\n\n#### 问题 3\n\n为什么必须检验新文本因子与已知因子（如 FF 因子）的相关性？\n\n:::{.callout-note collapse=\"true\"}\n💡 参考答案\n\n**原因**：\n\n1. **区分增量 vs 冗余**\n   - 若文本因子与规模、价值高度相关 → 可能只是\"旧瓶装新酒\"\n   - 真正有价值的是**独立于已知因子的信息**\n\n2. **避免过度宣称**\n   - 文献中大量\"新因子\"其实是已知因子的组合\n   - 需证明文本信息的独特性\n\n3. **理解经济含义**\n   - 相关性模式揭示文本变量捕捉了什么（情绪？风险？）\n   - 例：若情感与动量高度相关 → 可能只是市场反应的滞后\n\n**检验方法**：\n\n1. 计算相关系数（0.3-0.7 为健康范围）\n2. Horse race 回归（文本因子加入后仍显著）\n3. 分组分析（在已知因子弱的子样本中，文本因子作用更强）\n:::\n\n---\n\n### 下周预告\n\n第4周进入**多模态领域**：\n\n- 图像（卫星、票据、图表）、音频（电话会）、视频（路演）\n- 多模态融合策略与时序建模\n- 测量误差、算法偏差、伦理边界\n\n**预习阅读**：\n\n- Dell (2025) *Deep learning for economists*\n- Mayew & Venkatachalam (2012) *The power of voice*\n\n**预习任务**：带着\"多模态信号的增量信息如何证明？\"与\"伦理/隐私红线在哪里？\"两问阅读。\n","srcMarkdownNoYaml":"\n\n## 本周目标与三条底线\n\n### 课程主线回顾\n\n**泛化—正则化—评估**三位一体，在文本分析中的体现：\n\n- **泛化**：文本模型能否推广到新文档、新时期？\n- **正则化**：如何避免过拟合（特别是词典法的多重比较、LLM 的过度调优）？\n- **评估**：文本变量是否带来增量信息？\n\n### 三条底线\n\n:::{.callout-important}\n🎯 不可突破的红线\n\n1. **信息可得性**：不含前瞻信息（look-ahead bias）\n2. **过程可审计**：从原始文本到变量的每一步可追溯\n3. **结果可复现**：代码、模型版本、预处理规则完整记录\n:::\n\n这三条底线确保研究的**科学性**与**可信度**。\n\n## 文本表示方法演进\n\n### 文本分析的核心挑战\n\n**原始文本**是非结构化数据：\n\n```\n\"The company's revenue grew by 15% year-over-year, \ndriven by strong demand in emerging markets.\"\n```\n\n**目标**：转化为数值特征，用于预测/分类/聚类等任务。\n\n**挑战**：\n\n- 维度高（词汇量巨大）\n- 稀疏（单个文档只用少量词）\n- 顺序性（语序承载语义）\n- 歧义性（一词多义、多词一义）\n\n### 方法谱系：从简单到复杂\n\n#### 词袋模型（Bag-of-Words, BoW）\n\n**思想**：将文本表示为词频向量，忽略语序。\n\n**步骤**：\n\n1. **分词**（Tokenization）：\n   ```\n   \"revenue grew by 15%\" → [\"revenue\", \"grew\", \"by\", \"15%\"]\n   ```\n\n2. **构建词汇表**（Vocabulary）：\n   ```\n   V = {revenue, grew, company, market, ...}  # 假设 |V| = 10,000\n   ```\n\n3. **向量化**：\n   ```\n   文档 → [0, 2, 0, 1, ..., 0]  # 长度 = |V|\n          ↑     ↑  ↑\n       revenue出现0次\n          grew出现2次\n            ...\n   ```\n\n**变体：TF-IDF**（Term Frequency–Inverse Document Frequency）\n\n$$\n\\text{TF-IDF}(w, d) = \\underbrace{\\frac{\\text{count}(w, d)}{|d|}}_{\\text{词频}} \\times \\underbrace{\\log\\frac{N}{\\text{df}(w)}}_{\\text{逆文档频率}}\n$$\n\n- 降低常见词（如\"的\"、\"是\"）的权重\n- 提升区分性强的词的权重\n\n**优点**：\n\n- 简单、可解释\n- 计算高效\n- 适合作为基准\n\n**缺点**：\n\n- 忽略语序（\"not good\" vs \"good not\"）\n- 维度高、稀疏\n- 无法捕捉语义相似性（\"revenue\" vs \"sales\"）\n\n#### 词典法（Dictionary-based Methods）\n\n**思想**：用**预定义词表**匹配文本，计算情感/主题得分。\n\n**经典词典**：\n\n- **Loughran-McDonald (2011)**：金融情感词典\n  - Positive: {growth, profit, gain, ...}\n  - Negative: {loss, risk, decline, ...}\n- **Harvard IV-4**：心理学词典\n- **自定义词典**：针对特定任务\n\n**计算**：\n\n$$\n\\text{Sentiment Score} = \\frac{\\#\\text{Positive Words} - \\#\\text{Negative Words}}{\\#\\text{Total Words}}\n$$\n\n**金融应用案例**：\n\n```python\n# 年报文本情感分析\npositive_words = {'growth', 'profit', 'opportunity', ...}\nnegative_words = {'loss', 'risk', 'decline', 'uncertainty', ...}\n\ndef sentiment(text):\n    tokens = tokenize(text.lower())\n    pos = sum(1 for w in tokens if w in positive_words)\n    neg = sum(1 for w in tokens if w in negative_words)\n    return (pos - neg) / len(tokens)\n```\n\n**优点**：\n\n- 高度可解释（可追溯到具体词）\n- 稳定（不需训练）\n- 适合监管审计\n\n**缺点**：\n\n- 忽略上下文（\"not good\" 被误判为正面）\n- 词典覆盖不全\n- 行业/时期特异性（\"viral\" 在生物 vs 营销中含义不同）\n\n:::{.callout-tip}\n💡 何时用词典法？\n\n- **可解释性要求高**（如监管报告）\n- **领域词典成熟**（如金融、医疗）\n- **作为基准**（与 ML 方法对比）\n:::\n\n#### 主题模型（Topic Models）\n\n**思想**：无监督学习，发现文档的**潜在主题**。\n\n**经典算法：LDA（Latent Dirichlet Allocation）**\n\n**假设**：\n\n- 每个文档是多个主题的混合\n- 每个主题是词的概率分布\n\n**示例**（K=3 个主题）：\n\n```\n文档1: 70% 主题A（科技） + 20% 主题B（金融） + 10% 主题C（政策）\n文档2: 10% 主题A + 80% 主题B + 10% 主题C\n\n主题A: {AI: 0.05, algorithm: 0.04, data: 0.03, ...}\n主题B: {stock: 0.06, market: 0.05, trading: 0.04, ...}\n主题C: {government: 0.05, regulation: 0.04, policy: 0.03, ...}\n```\n\n**提取特征**：\n\n- 文档的主题分布向量：$\\boldsymbol{\\theta}_d = [\\theta_{d,1}, \\ldots, \\theta_{d,K}]$\n\n**金融应用**：\n\n- 年报主题分析（技术创新 vs 财务风险）\n- 新闻聚类（宏观 vs 行业 vs 个股）\n\n**优点**：\n\n- 降维（数万维 → K 维）\n- 可解释（主题词）\n- 无监督\n\n**缺点**：\n\n- 主题数量 K 需人工选择\n- 主题解释主观\n- 计算成本高\n\n#### 词嵌入（Word Embeddings）\n\n**思想**：将词映射到**低维连续向量空间**，语义相似的词距离近。\n\n**经典模型：Word2Vec (Mikolov et al., 2013)**\n\n**训练目标**（Skip-gram）：\n\n给定中心词，预测上下文词。\n\n**结果**：\n\n```\nrevenue: [0.2, -0.5, 0.8, ...]  # 300维向量\nsales:   [0.21, -0.48, 0.79, ...]  # 距离很近\nprofit:  [0.18, -0.52, 0.75, ...]\n```\n\n**著名性质**：\n\n$$\n\\text{vec}(\\text{king}) - \\text{vec}(\\text{man}) + \\text{vec}(\\text{woman}) \\approx \\text{vec}(\\text{queen})\n$$\n\n**文档表示**：\n\n- 简单平均：$\\mathbf{v}_{\\text{doc}} = \\frac{1}{|d|}\\sum_{w \\in d} \\mathbf{v}_w$\n- 加权平均（TF-IDF 权重）\n\n**优点**：\n\n- 捕捉语义相似性\n- 预训练模型可直接用（如 Google News Word2Vec）\n\n**缺点**：\n\n- 静态（\"bank\" 在不同上下文中向量相同）\n- 文档表示过于粗糙（简单平均丢失语序）\n\n#### Transformer 与 BERT\n\n**革命性突破**：**上下文化嵌入**（Contextualized Embeddings）\n\n**BERT（Bidirectional Encoder Representations from Transformers）**\n\n- Devlin et al. (2019)\n\n**核心思想**：\n\n- 同一个词在不同上下文中有**不同的向量**\n- 双向注意力机制（Transformer）\n\n**示例**：\n\n```\n句1: \"I went to the bank to deposit money.\"\n     → \"bank\" 向量偏向\"金融机构\"\n\n句2: \"I sat by the river bank.\"\n     → \"bank\" 向量偏向\"河岸\"\n```\n\n**预训练任务**：\n\n1. **Masked Language Modeling (MLM)**：\n   ```\n   输入: \"The company's [MASK] grew by 15%.\"\n   预测: revenue / profit / sales\n   ```\n\n2. **Next Sentence Prediction (NSP)**：\n   ```\n   句A: \"Revenue increased.\"\n   句B: \"Profit margins improved.\"\n   预测: B 是否是 A 的下一句？\n   ```\n\n**金融领域预训练模型**：\n\n- **FinBERT** (Araci, 2019)：在金融新闻/年报上微调\n- **DistilRoBERTa-financial-sentiment**：轻量级金融情感分类\n\n**使用流程**：\n\n```python\nfrom transformers import AutoTokenizer, AutoModel\n\n# 加载预训练模型\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModel.from_pretrained(\"ProsusAI/finbert\")\n\n# 文本编码\ntext = \"The company reported strong earnings growth.\"\ninputs = tokenizer(text, return_tensors=\"pt\")\noutputs = model(**inputs)\n\n# 提取 [CLS] token 的嵌入作为文档表示\ndoc_embedding = outputs.last_hidden_state[:, 0, :]  # (1, 768)\n```\n\n**优点**：\n\n- **最强语义表达**\n- 迁移学习：预训练 + 微调\n- 最新 SOTA 性能\n\n**缺点**：\n\n- **计算成本高**（需 GPU）\n- **不易复现**（模型更新频繁）\n- **可解释性差**（黑箱）\n- **版本控制难**（模型文件大）\n\n:::{.callout-warning}\n⚠️ 使用 BERT/LLM 的规范要求\n\n1. **锁定模型版本**：记录精确的模型名称与版本号\n   ```python\n   # 好：明确版本\n   model = AutoModel.from_pretrained(\"bert-base-uncased\", revision=\"abc123\")\n   \n   # 差：版本不确定\n   model = AutoModel.from_pretrained(\"bert-base-uncased\")\n   ```\n\n2. **固定随机种子**：微调时保证可复现\n   ```python\n   set_seed(42)\n   ```\n\n3. **记录计算环境**：\n   ```\n   transformers==4.36.0\n   torch==2.1.0\n   CUDA==11.8\n   ```\n\n4. **提供推理代码**：完整的预处理 + 模型推理流程\n:::\n\n### 方法选择决策树\n\n```\n是否需要高度可解释？\n├─ 是 → 词典法（如 LM 情感词典）\n└─ 否 → 有监督学习任务？\n        ├─ 是 → 有标注数据？\n        │       ├─ 是 → 数据量大（>10K）？\n        │       │       ├─ 是 → BERT 微调\n        │       │       └─ 否 → TF-IDF + 传统 ML\n        │       └─ 否 → 词典法或主题模型\n        └─ 否（无监督）→ 主题模型（LDA）或预训练嵌入\n```\n\n## 语料治理：从原始文档到可用观测值\n\n### 核心原则\n\n**语料治理**（Corpus Curation）确保：\n\n1. **版本锁定**：使用哪个版本的文档？\n2. **时间戳准确**：何时发布？何时市场可得？\n3. **实体对齐**：文档对应哪个公司/人物/事件？\n4. **去噪**：去除无关/重复/错误内容\n\n### 版本锁定\n\n#### 问题：事后修订\n\n**案例**：上市公司年报\n\n- **首次披露**：2024-04-30，原始版本\n- **修订版**：2024-06-15，更正财务数据\n\n**错误做法**：\n\n使用数据库中的\"最新版\"（可能是修订后的）\n\n**正确做法**：\n\n使用**首次披露版本**（as-filed version）\n\n**实施**：\n\n```python\n# 记录文档版本信息\ndf['document_id'] = \"10-K_AAPL_2023_v1\"  # 版本号\ndf['file_date'] = \"2024-04-30\"          # 首次提交日期\ndf['revision_date'] = None               # 若无修订\n```\n\n#### SEC EDGAR 数据示例\n\n```python\nimport requests\n\n# 获取首次提交版本\nurl = \"https://www.sec.gov/cgi-bin/viewer?action=view&cik=320193&accession_number=0000320193-24-000001&xbrl_type=v\"\nresponse = requests.get(url, headers={'User-Agent': 'your-email@example.com'})\n```\n\n### 时间戳与可得性规则\n\n#### 何时\"市场可得\"？\n\n| 文本类型 | 发布时间 | 市场反应窗口 |\n|---------|---------|-------------|\n| **年报/季报** | 收盘后或次日开盘前 | 次日开盘起 |\n| **新闻** | 实时 | 发布时刻起 |\n| **分析师报告** | 工作日盘前/盘后 | 发布时刻起 |\n| **社交媒体** | 实时 | 发布时刻起 |\n| **财报电话会** | 盘后固定时间 | 会议结束后 |\n\n**关键规则**：\n\n$$\n\\text{用于预测 } t \\text{ 日收益的文本} \\Rightarrow \\text{必须在 } t \\text{ 日开盘前发布}\n$$\n\n#### 对齐代码示例\n\n```python\n# 年报对齐\ndef align_report(df):\n    # 假设年报在披露日的次日才可交易\n    df['available_date'] = df['file_date'] + pd.Timedelta(days=1)\n    \n    # 对齐到交易日\n    df['available_date'] = df['available_date'].apply(\n        lambda d: next_trading_day(d)\n    )\n    \n    # 构造标签：用披露后首个交易日收益\n    df['target_return'] = df.groupby('ticker')['return'].shift(-1)\n    \n    return df\n```\n\n### 实体识别与对齐\n\n#### 挑战：一个实体，多种表述\n\n**案例**：苹果公司\n\n- 正式名称：\"Apple Inc.\"\n- 股票代码：\"AAPL\"\n- 常见别名：\"Apple\", \"苹果\", \"库比蒂诺公司\"\n\n#### 解决方案：实体链接（Entity Linking）\n\n**步骤**：\n\n1. **命名实体识别（NER）**：识别文本中的公司名\n   ```python\n   # 使用 spaCy\n   import spacy\n   nlp = spacy.load(\"en_core_web_sm\")\n   doc = nlp(\"Apple reported strong earnings.\")\n   entities = [(ent.text, ent.label_) for ent in doc.ents]\n   # [('Apple', 'ORG')]\n   ```\n\n2. **链接到标准 ID**：\n   ```python\n   entity_map = {\n       'Apple': 'AAPL',\n       'Apple Inc.': 'AAPL',\n       '苹果': 'AAPL',\n       ...\n   }\n   ticker = entity_map.get(entity_name, None)\n   ```\n\n3. **歧义消解**：\n   - \"Apple\" 可能是公司或水果\n   - 用上下文判断（如出现\"stock\", \"earnings\"）\n\n#### 金融专用工具\n\n- **FinBERT-NER**：金融实体识别\n- **OpenFIGI API**：金融工具标识符查询\n- **Wikidata/DBpedia**：知识图谱链接\n\n### 去重与噪声处理\n\n#### 常见噪声类型\n\n1. **模板文本**\n\n年报中的法律声明、标准段落：\n\n```\n\"Forward-looking statements involve risks and uncertainties...\"\n```\n\n**处理**：\n\n- 识别高频重复段落\n- 在情感分析前删除\n\n```python\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# 识别模板（在多个文档中高频出现的句子）\nsentences = extract_sentences(all_documents)\nvectorizer = TfidfVectorizer()\ntfidf = vectorizer.fit_transform(sentences)\n# 计算句子在文档间的相似度，删除重复率高的\n```\n\n2. **乱码与编码错误**\n\n```\n\"The companyâ€™s revenue...\"  # Unicode 错误\n```\n\n**处理**：\n\n```python\nimport ftfy\ntext_clean = ftfy.fix_text(text_raw)\n```\n\n3. **OCR/ASR 错误**\n\n扫描文档或语音转文字的错误：\n\n```\nOCR: \"The company's net income...\" → \"The c0mpany's net inc0me...\"\nASR: \"fiscal year\" → \"physical year\"\n```\n\n**处理**：\n\n- 使用高质量的原始文件（PDF 带文字层）\n- 检查关键词错误率\n- 后处理：拼写检查、上下文纠错\n\n#### 去重\n\n**文档级去重**：\n\n- 计算文档相似度（如余弦相似度）\n- 删除近似重复（如转载新闻）\n\n```python\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# 计算 TF-IDF 向量的相似度矩阵\nsimilarity = cosine_similarity(tfidf_matrix)\n\n# 删除相似度 > 0.95 的文档对\nduplicates = np.argwhere((similarity > 0.95) & (similarity < 1.0))\n```\n\n## 从原始文本到量化变量的可审计流程\n\n### 流程图\n\n```\n原始文档（PDF/HTML/TXT）\n    ↓\n① 版本确认 & 时间戳记录\n    ↓\n② 文本提取 & 编码修正\n    ↓\n③ 实体识别 & 对齐\n    ↓\n④ 预处理（分词、去停用词、去模板）\n    ↓\n⑤ 特征提取（词典/主题/嵌入）\n    ↓\n⑥ 变量构造（聚合、标准化）\n    ↓\n⑦ 质量检验 & 异常值处理\n    ↓\n可用于建模的变量\n```\n\n### 各步骤的可审计要求\n\n#### ① 版本确认 & 时间戳\n\n**记录**：\n\n```python\nmetadata = {\n    'document_id': 'unique_id',\n    'source': 'SEC EDGAR',\n    'url': 'https://...',\n    'file_date': '2024-04-30',\n    'download_date': '2024-05-01',\n    'version': 'v1'\n}\n```\n\n#### ② 文本提取\n\n**工具与参数**：\n\n```python\n# PDF 提取\nimport pdfplumber\nwith pdfplumber.open(pdf_path) as pdf:\n    text = '\\n'.join([page.extract_text() for page in pdf.pages])\n\n# 记录工具版本\nmetadata['extraction_tool'] = f'pdfplumber=={pdfplumber.__version__}'\n```\n\n#### ③ 实体识别 & 对齐\n\n**记录**：\n\n```python\nmetadata['ner_model'] = 'en_core_web_sm-3.7.0'\nmetadata['entity_map_version'] = 'v2024.1'\n```\n\n#### ④ 预处理\n\n**记录每一步**：\n\n```python\npreprocessing_steps = [\n    'lowercasing',\n    'remove_punctuation',\n    'remove_stopwords: nltk.corpus.stopwords (english)',\n    'stemming: PorterStemmer',\n]\n```\n\n#### ⑤ 特征提取\n\n**词典法**：\n\n```python\nsentiment_dict = {\n    'version': 'Loughran-McDonald 2020',\n    'positive_words': len(positive_words),\n    'negative_words': len(negative_words),\n}\n```\n\n**BERT**：\n\n```python\nmodel_info = {\n    'model_name': 'ProsusAI/finbert',\n    'model_revision': 'abc123',\n    'framework': 'transformers==4.36.0',\n    'device': 'cuda:0',\n}\n```\n\n#### ⑥ 变量构造\n\n**公式记录**：\n\n```python\n# 情感得分\nvariable_definition = \"\"\"\nsentiment = (n_positive - n_negative) / n_total\nwhere:\n  n_positive: count of words in LM positive dictionary\n  n_negative: count of words in LM negative dictionary\n  n_total: total word count (excluding stopwords)\n\"\"\"\n```\n\n#### ⑦ 质量检验\n\n**检查清单**：\n\n- 缺失值比例（若 > 20%，说明为何）\n- 异常值（极端情感得分）\n- 时间序列连续性（是否有长期缺失）\n- 横截面覆盖率（行业/市值分布）\n\n## 交付物：变量字典\n\n**示例**：\n\n| 变量名 | 定义 | 来源 | 更新频率 | 处理方法 | 缺失值 |\n|-------|-----|------|---------|---------|--------|\n| `sentiment_lm` | LM 情感得分 | 年报 MD&A 部分 | 年度 | LM 词典匹配 | 前向填充 |\n| `topic_tech` | 技术创新主题强度 | 年报全文 | 年度 | LDA (K=10) | 0填充 |\n| `uncertainty` | 不确定性词频 | 电话会文本 | 季度 | 自定义词典 | 删除 |\n\n## 文本变量评估与增量价值检验\n\n### 评估的三个层次\n\n#### 层次 1：描述性统计\n\n**基本检查**：\n\n- 均值、中位数、标准差\n- 时间趋势（是否异常跳跃？）\n- 横截面分布（是否过于集中？）\n\n**示例**：\n\n```python\n# 情感得分的时间序列\ndf.groupby('year')['sentiment'].mean().plot()\n\n# 横截面分布\ndf['sentiment'].hist(bins=50)\n```\n\n#### 层次 2：与已知因子的关系\n\n**问题**：文本变量是否只是已知因子的\"马甲\"？\n\n**检验**：\n\n1. **相关性分析**\n\n```python\nimport pandas as pd\n\n# 计算与 Fama-French 因子的相关性\ncorr = df[['sentiment', 'size', 'value', 'momentum']].corr()\nprint(corr['sentiment'])\n```\n\n2. **Horse Race 回归**\n\n$$\nr_{i,t+1} = \\alpha + \\beta_1 \\text{Sentiment}_{i,t} + \\beta_2 \\text{Size}_{i,t} + \\beta_3 \\text{Value}_{i,t} + \\varepsilon_{i,t+1}\n$$\n\n**关键问题**：\n\n- $\\beta_1$ 是否显著？\n- 加入文本变量后，模型 $R^2$ 提升多少？\n\n#### 层次 3：增量预测能力\n\n**设计**：\n\n1. **基准模型**（不含文本）\n\n```python\n# 用传统因子预测收益\nmodel_baseline = LinearRegression()\nmodel_baseline.fit(X_baseline, y)  # X_baseline = [size, value, momentum]\nr2_baseline = model_baseline.score(X_test, y_test)\n```\n\n2. **增强模型**（加入文本）\n\n```python\nX_augmented = np.hstack([X_baseline, X_text])  # 加入文本特征\nmodel_augmented = LinearRegression()\nmodel_augmented.fit(X_augmented, y)\nr2_augmented = model_augmented.score(X_test_augmented, y_test)\n```\n\n3. **比较**\n\n$$\n\\Delta R^2 = R^2_{\\text{augmented}} - R^2_{\\text{baseline}}\n$$\n\n**统计检验**：\n\n- Diebold-Mariano 检验（预测误差是否显著不同）\n- 嵌套模型 F 检验\n\n### 切片评估\n\n**不同时期**：\n\n- 牛市 vs 熊市\n- 危机期 vs 平稳期\n\n**不同资产**：\n\n- 大市值 vs 小市值\n- 成长股 vs 价值股\n- 不同行业\n\n**目的**：检验文本变量的普适性与稳健性。\n\n### 互补性 vs 冗余性\n\n**互补**（Complementary）：\n\n- 文本变量捕捉结构化变量未涵盖的信息\n- 例：年报语气（软信息）vs 财务指标（硬信息）\n\n**冗余**（Redundant）：\n\n- 文本变量只是重复已知信息\n- 例：新闻情感 ≈ 过去收益（动量效应）\n\n**证据链**：\n\n1. 相关性适度（0.3-0.7 为佳，过高则冗余）\n2. Horse race 中文本变量仍显著\n3. 分组分析：在结构化因子弱的子样本中，文本变量作用更强\n\n## RAG 与信息抽取的应用边界\n\n### Retrieval-Augmented Generation (RAG)\n\n**定义**：结合检索与生成，用外部知识库增强 LLM。\n\n**流程**：\n\n```\n用户查询\n    ↓\n检索相关文档（如向量数据库）\n    ↓\n拼接为 Prompt\n    ↓\nLLM 生成回答\n```\n\n#### 在金融中的应用\n\n**1. 投研辅助**\n\n```\n查询: \"分析苹果公司 2023 年的供应链风险\"\n  ↓\n检索: AAPL 2023 年报、相关新闻、分析师报告\n  ↓\nLLM: 生成综合分析报告\n```\n\n**2. 合规问答**\n\n```\n查询: \"公司是否违反了反洗钱法规？\"\n  ↓\n检索: 公司内部文档、监管政策\n  ↓\nLLM: 给出合规意见（需人工审核）\n```\n\n#### 边界与风险\n\n:::{.callout-warning}\n⚠️ 使用 RAG/LLM 的注意事项\n\n**不适合用于**：\n\n1. **高风险决策**（如自动批准贷款）\n   - LLM 输出不稳定，可能产生幻觉\n   \n2. **监管敏感场景**（如交易指令生成）\n   - 无法提供可审计的决策依据\n\n3. **实时交易**\n   - 延迟高，难以满足毫秒级要求\n\n**适合用于**：\n\n1. **辅助研究**（生成假设、文献综述）\n2. **内容生成**（研报初稿、客户报告）\n3. **知识管理**（内部文档检索）\n\n**核心原则**：**人机协作**，LLM 作为工具，人类保留最终决策权。\n:::\n\n### 信息抽取（Information Extraction）\n\n**任务**：从非结构化文本中提取结构化信息。\n\n**示例**：\n\n```\n原始文本:\n\"The company announced a $50 million share buyback program, \neffective January 1, 2024.\"\n\n提取结果:\n{\n  'event_type': 'share_buyback',\n  'amount': 50000000,\n  'currency': 'USD',\n  'effective_date': '2024-01-01',\n  'entity': 'The Company'\n}\n```\n\n#### 技术路径\n\n1. **规则 based**（正则表达式）\n   ```python\n   import re\n   pattern = r'\\$(\\d+(?:,\\d{3})*(?:\\.\\d+)?) (million|billion)'\n   match = re.search(pattern, text)\n   ```\n\n2. **机器学习**（NER + Relation Extraction）\n   ```python\n   # 使用 spaCy 的实体关系抽取\n   doc = nlp(text)\n   for ent in doc.ents:\n       if ent.label_ == 'MONEY':\n           amount = ent.text\n   ```\n\n3. **LLM-based**（Few-shot prompting）\n   ```python\n   prompt = f\"\"\"\n   Extract the following information from the text:\n   - Event type\n   - Amount\n   - Effective date\n   \n   Text: {text}\n   \n   Output as JSON.\n   \"\"\"\n   response = llm.generate(prompt)\n   ```\n\n#### 在风控中的应用\n\n**舆情监控**：\n\n- 自动抽取负面事件（诉讼、罚款、高管离职）\n- 实时预警\n\n**尽职调查**：\n\n- 批量处理合同、法律文书\n- 抽取关键条款（违约条件、担保方式等）\n\n## 本周小结\n\n### 核心要点\n\n1. **方法谱系**：词袋 → 词典 → 主题模型 → 词嵌入 → BERT，权衡可解释性与性能\n2. **语料治理**：版本锁定、时间对齐、实体链接、去噪，确保数据质量\n3. **可审计流程**：记录每一步（工具、参数、版本），交付变量字典\n4. **增量价值**：文本变量必须相对已知因子展示增量信息\n5. **应用边界**：RAG/LLM 适合辅助研究，不适合高风险自动决策\n\n### 本周思考题\n\n#### 问题 1\n\nBERT/LLM 构造文本变量相比词典法的优势与风险分别是什么？\n\n:::{.callout-note collapse=\"true\"}\n💡 参考答案\n\n**优势**：\n\n1. **更强语义理解**：捕捉上下文（\"not good\" 正确识别为负面）\n2. **泛化能力**：处理词典未覆盖的表述\n3. **端到端学习**：自动特征提取，减少人工工程\n\n**风险**：\n\n1. **可解释性差**：无法追溯到具体词/短语\n2. **不易复现**：模型版本更新频繁，结果可能变化\n3. **计算成本高**：需 GPU，推理慢\n4. **过拟合风险**：参数多，样本少时易过拟合\n5. **审计困难**：监管难以理解\"黑箱\"模型的决策依据\n:::\n\n#### 问题 2\n\n用新闻预测股价时，如何设计流程避免前瞻偏误？\n\n:::{.callout-note collapse=\"true\"}\n💡 参考答案\n\n**关键步骤**：\n\n1. **记录新闻时间戳**（精确到分钟）\n   ```python\n   df['news_timestamp'] = pd.to_datetime(df['published_time'])\n   ```\n\n2. **对齐到交易时间**\n   - 盘前新闻（9:30前）→ 用于预测当日收益\n   - 盘中/盘后新闻 → 用于预测次日收益\n\n3. **构造标签**\n   ```python\n   # 新闻在 t 日收盘前发布 → 预测 t+1 日收益\n   df['target_date'] = df['news_timestamp'].apply(\n       lambda ts: ts.date() + timedelta(days=1) if ts.hour >= 16 \n                  else ts.date()\n   )\n   df['target_return'] = df.merge(\n       returns, left_on=['ticker', 'target_date'], ...\n   )\n   ```\n\n4. **滚动窗口评估**（避免用未来新闻训练模型）\n\n5. **检验**：人工抽查对齐正确性\n:::\n\n#### 问题 3\n\n为什么必须检验新文本因子与已知因子（如 FF 因子）的相关性？\n\n:::{.callout-note collapse=\"true\"}\n💡 参考答案\n\n**原因**：\n\n1. **区分增量 vs 冗余**\n   - 若文本因子与规模、价值高度相关 → 可能只是\"旧瓶装新酒\"\n   - 真正有价值的是**独立于已知因子的信息**\n\n2. **避免过度宣称**\n   - 文献中大量\"新因子\"其实是已知因子的组合\n   - 需证明文本信息的独特性\n\n3. **理解经济含义**\n   - 相关性模式揭示文本变量捕捉了什么（情绪？风险？）\n   - 例：若情感与动量高度相关 → 可能只是市场反应的滞后\n\n**检验方法**：\n\n1. 计算相关系数（0.3-0.7 为健康范围）\n2. Horse race 回归（文本因子加入后仍显著）\n3. 分组分析（在已知因子弱的子样本中，文本因子作用更强）\n:::\n\n---\n\n### 下周预告\n\n第4周进入**多模态领域**：\n\n- 图像（卫星、票据、图表）、音频（电话会）、视频（路演）\n- 多模态融合策略与时序建模\n- 测量误差、算法偏差、伦理边界\n\n**预习阅读**：\n\n- Dell (2025) *Deep learning for economists*\n- Mayew & Venkatachalam (2012) *The power of voice*\n\n**预习任务**：带着\"多模态信号的增量信息如何证明？\"与\"伦理/隐私红线在哪里？\"两问阅读。\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":true,"html-math-method":"katex","output-file":"week3.html"},"language":{"toc-title-document":"目录","toc-title-website":"该页面内容","related-formats-title":"其他格式","related-notebooks-title":"笔记本","source-notebooks-prefix":"资源","other-links-title":"其他链接","code-links-title":"代码链接","launch-dev-container-title":"启动 Dev Container","launch-binder-title":"启动 Binder","article-notebook-label":"文章笔记本","notebook-preview-download":"下载笔记本","notebook-preview-download-src":"下载源代码","notebook-preview-back":"返回文章","manuscript-meca-bundle":"MECA 存档","section-title-abstract":"摘要","section-title-appendices":"附录","section-title-footnotes":"脚注","section-title-references":"参考文献","section-title-reuse":"二次使用","section-title-copyright":"版权","section-title-citation":"引用格式","appendix-attribution-cite-as":"请按如下格式引用：","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"查看许可协议","title-block-author-single":"作者","title-block-author-plural":"作者","title-block-affiliation-single":"单位","title-block-affiliation-plural":"单位","title-block-published":"发布于","title-block-modified":"修改于","title-block-keywords":"关键词","callout-tip-title":"提示","callout-note-title":"注记","callout-warning-title":"警告","callout-important-title":"重要","callout-caution-title":"注意","code-summary":"代码","code-tools-menu-caption":"代码","code-tools-show-all-code":"显示所有代码","code-tools-hide-all-code":"隐藏所有代码","code-tools-view-source":"查看源代码","code-tools-source-code":"源代码","tools-share":"Share","tools-download":"Download","code-line":"行","code-lines":"行","copy-button-tooltip":"复制到剪贴板","copy-button-tooltip-success":"已复制","repo-action-links-edit":"编辑该页面","repo-action-links-source":"查看代码","repo-action-links-issue":"反馈问题","back-to-top":"回到顶部","search-no-results-text":"没有结果","search-matching-documents-text":"匹配的文档","search-copy-link-title":"复制搜索链接","search-hide-matches-text":"隐藏其它匹配结果","search-more-match-text":"更多匹配结果","search-more-matches-text":"更多匹配结果","search-clear-button-title":"清除","search-text-placeholder":"","search-detached-cancel-button-title":"取消","search-submit-button-title":"提交","search-label":"搜索","toggle-section":"展开或折叠此栏","toggle-sidebar":"展开或折叠侧边栏导航","toggle-dark-mode":"切换深色模式","toggle-reader-mode":"切换阅读器模式","toggle-navigation":"展开或折叠导航栏","crossref-fig-title":"图","crossref-tbl-title":"表","crossref-lst-title":"列表","crossref-thm-title":"定理","crossref-lem-title":"引理","crossref-cor-title":"推论","crossref-prp-title":"命题","crossref-cnj-title":"猜想","crossref-def-title":"定义","crossref-exm-title":"例","crossref-exr-title":"习题","crossref-ch-prefix":"章节","crossref-apx-prefix":"附录","crossref-sec-prefix":"小节","crossref-eq-prefix":"式","crossref-lof-title":"图索引","crossref-lot-title":"表索引","crossref-lol-title":"列表索引","environment-proof-title":"证","environment-remark-title":"注记","environment-solution-title":"解","listing-page-order-by":"排序方式","listing-page-order-by-default":"默认","listing-page-order-by-date-asc":"日期升序","listing-page-order-by-date-desc":"日期降序","listing-page-order-by-number-desc":"降序","listing-page-order-by-number-asc":"升序","listing-page-field-date":"日期","listing-page-field-title":"标题","listing-page-field-description":"描述","listing-page-field-author":"作者","listing-page-field-filename":"文件名","listing-page-field-filemodified":"修改时间","listing-page-field-subtitle":"副标题","listing-page-field-readingtime":"阅读时间","listing-page-field-wordcount":"字数统计","listing-page-field-categories":"分类","listing-page-minutes-compact":"{0} 分钟","listing-page-category-all":"全部","listing-page-no-matches":"无匹配项","listing-page-words":"{0} 字","listing-page-filter":"筛选","draft":"草稿"},"metadata":{"lang":"zh","fig-responsive":true,"quarto-version":"1.6.32","theme":"cosmo","title":"第3讲：文本分析理论 → 金融文本应用","subtitle":"从原始文本到可审计的量化变量"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}