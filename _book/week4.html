<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-Hans" xml:lang="zh-Hans"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; 第4讲：多模态模型理论 → 金融信号抽取 – AI与金融研究：从理论到证据</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./proposal.html" rel="next">
<link href="./week3.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2486e1f0a3ee9ee1fc393803a1361cdb.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ed6da6eef3892af8a4b5ed59bfb951f5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交",
    "search-label": "搜索"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week4.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">第4讲：多模态模型理论 → 金融信号抽取</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="搜索" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI与金融研究：从理论到证据</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="搜索"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI与金融研究：从理论到证据</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">教学大纲</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">课程简介与预备知识</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">第1讲：机器学习理论基础</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">第2讲：资产定价中的机器学习应用</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">第3讲：文本分析理论 → 金融文本应用</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">第4讲：多模态模型理论 → 金融信号抽取</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./proposal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">小组研究项目指南</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目录</h2>
   
  <ul>
  <li><a href="#任务与数据把多模态研究表述为分类问题" id="toc-任务与数据把多模态研究表述为分类问题" class="nav-link active" data-scroll-target="#任务与数据把多模态研究表述为分类问题"><span class="header-section-number">7.1</span> 任务与数据：把多模态研究表述为分类问题</a>
  <ul class="collapse">
  <li><a href="#为什么是分类" id="toc-为什么是分类" class="nav-link" data-scroll-target="#为什么是分类"><span class="header-section-number">7.1.1</span> 为什么是”分类”？</a></li>
  <li><a href="#多模态数据版图" id="toc-多模态数据版图" class="nav-link" data-scroll-target="#多模态数据版图"><span class="header-section-number">7.1.2</span> 多模态数据版图</a></li>
  </ul></li>
  <li><a href="#视觉图像模态特征提取与变量构造" id="toc-视觉图像模态特征提取与变量构造" class="nav-link" data-scroll-target="#视觉图像模态特征提取与变量构造"><span class="header-section-number">7.2</span> 视觉（图像）模态：特征提取与变量构造</a>
  <ul class="collapse">
  <li><a href="#图像表示方法演进" id="toc-图像表示方法演进" class="nav-link" data-scroll-target="#图像表示方法演进"><span class="header-section-number">7.2.1</span> 图像表示方法演进</a></li>
  <li><a href="#金融应用案例" id="toc-金融应用案例" class="nav-link" data-scroll-target="#金融应用案例"><span class="header-section-number">7.2.2</span> 金融应用案例</a></li>
  <li><a href="#关键对齐与偏误" id="toc-关键对齐与偏误" class="nav-link" data-scroll-target="#关键对齐与偏误"><span class="header-section-number">7.2.3</span> 关键对齐与偏误</a></li>
  </ul></li>
  <li><a href="#音频模态特征提取与测量误差" id="toc-音频模态特征提取与测量误差" class="nav-link" data-scroll-target="#音频模态特征提取与测量误差"><span class="header-section-number">7.3</span> 音频模态：特征提取与测量误差</a>
  <ul class="collapse">
  <li><a href="#两条特征提取管线" id="toc-两条特征提取管线" class="nav-link" data-scroll-target="#两条特征提取管线"><span class="header-section-number">7.3.1</span> 两条特征提取管线</a></li>
  <li><a href="#金融应用案例-1" id="toc-金融应用案例-1" class="nav-link" data-scroll-target="#金融应用案例-1"><span class="header-section-number">7.3.2</span> 金融应用案例</a></li>
  <li><a href="#风险点与注意事项" id="toc-风险点与注意事项" class="nav-link" data-scroll-target="#风险点与注意事项"><span class="header-section-number">7.3.3</span> 风险点与注意事项</a></li>
  </ul></li>
  <li><a href="#视频模态时序聚合行为信号与合规边界" id="toc-视频模态时序聚合行为信号与合规边界" class="nav-link" data-scroll-target="#视频模态时序聚合行为信号与合规边界"><span class="header-section-number">7.4</span> 视频模态：时序聚合、行为信号与合规边界</a>
  <ul class="collapse">
  <li><a href="#视频-图像序列-音频" id="toc-视频-图像序列-音频" class="nav-link" data-scroll-target="#视频-图像序列-音频"><span class="header-section-number">7.4.1</span> 视频 = 图像序列 + 音频</a></li>
  <li><a href="#帧级视觉表征" id="toc-帧级视觉表征" class="nav-link" data-scroll-target="#帧级视觉表征"><span class="header-section-number">7.4.2</span> 帧级视觉表征</a></li>
  <li><a href="#行为线索非言语信号" id="toc-行为线索非言语信号" class="nav-link" data-scroll-target="#行为线索非言语信号"><span class="header-section-number">7.4.3</span> 行为线索：非言语信号</a></li>
  <li><a href="#时序建模示例lstm" id="toc-时序建模示例lstm" class="nav-link" data-scroll-target="#时序建模示例lstm"><span class="header-section-number">7.4.4</span> 时序建模示例：LSTM</a></li>
  <li><a href="#风险点与合规边界" id="toc-风险点与合规边界" class="nav-link" data-scroll-target="#风险点与合规边界"><span class="header-section-number">7.4.5</span> 风险点与合规边界</a></li>
  </ul></li>
  <li><a href="#融合与分类评估多模态增量信息检验" id="toc-融合与分类评估多模态增量信息检验" class="nav-link" data-scroll-target="#融合与分类评估多模态增量信息检验"><span class="header-section-number">7.5</span> 融合与分类评估：多模态增量信息检验</a>
  <ul class="collapse">
  <li><a href="#融合策略" id="toc-融合策略" class="nav-link" data-scroll-target="#融合策略"><span class="header-section-number">7.5.1</span> 融合策略</a></li>
  <li><a href="#缺失模态处理" id="toc-缺失模态处理" class="nav-link" data-scroll-target="#缺失模态处理"><span class="header-section-number">7.5.2</span> 缺失模态处理</a></li>
  <li><a href="#增量贡献评估" id="toc-增量贡献评估" class="nav-link" data-scroll-target="#增量贡献评估"><span class="header-section-number">7.5.3</span> 增量贡献评估</a></li>
  <li><a href="#切片评估与稳健性" id="toc-切片评估与稳健性" class="nav-link" data-scroll-target="#切片评估与稳健性"><span class="header-section-number">7.5.4</span> 切片评估与稳健性</a></li>
  </ul></li>
  <li><a href="#本周小结" id="toc-本周小结" class="nav-link" data-scroll-target="#本周小结"><span class="header-section-number">7.6</span> 本周小结</a>
  <ul class="collapse">
  <li><a href="#核心要点" id="toc-核心要点" class="nav-link" data-scroll-target="#核心要点"><span class="header-section-number">7.6.1</span> 核心要点</a></li>
  <li><a href="#本周思考题" id="toc-本周思考题" class="nav-link" data-scroll-target="#本周思考题"><span class="header-section-number">7.6.2</span> 本周思考题</a></li>
  <li><a href="#课程前半段回顾" id="toc-课程前半段回顾" class="nav-link" data-scroll-target="#课程前半段回顾"><span class="header-section-number">7.6.3</span> 课程前半段回顾</a></li>
  <li><a href="#后半段课程预告" id="toc-后半段课程预告" class="nav-link" data-scroll-target="#后半段课程预告"><span class="header-section-number">7.6.4</span> 后半段课程预告</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">第4讲：多模态模型理论 → 金融信号抽取</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> 代码</button></div></div>
<p class="subtitle lead">图像、音频、视频的特征提取与增量信息检验</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="任务与数据把多模态研究表述为分类问题" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="任务与数据把多模态研究表述为分类问题"><span class="header-section-number">7.1</span> 任务与数据：把多模态研究表述为分类问题</h2>
<section id="为什么是分类" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="为什么是分类"><span class="header-section-number">7.1.1</span> 为什么是”分类”？</h3>
<p>虽然多模态数据形式多样（图像、音频、视频），但在金融应用中，核心任务通常可表述为<strong>分类问题</strong>：</p>
<ul>
<li>预测<strong>涨/跌</strong>（二分类）</li>
<li>识别<strong>管理层情绪状态</strong>（多分类：乐观/中性/悲观）</li>
<li>判断<strong>欺诈/非欺诈</strong>（二分类）</li>
<li>预测<strong>信用等级</strong>（多分类）</li>
</ul>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
注记
</div>
</div>
<div class="callout-body-container callout-body">
<p>🎯 标签定义的三要素</p>
<ol type="1">
<li><strong>何时</strong>（When）：预测哪个时期的结果？</li>
<li><strong>对谁</strong>（Who）：个股/行业/市场？</li>
<li><strong>预测什么</strong>（What）：具体的类别定义？</li>
</ol>
<p><strong>示例</strong>：</p>
<ul>
<li><strong>何时</strong>：业绩电话会后第二个交易日</li>
<li><strong>对谁</strong>：该公司股票</li>
<li><strong>预测什么</strong>：收益率是否超过市场中位数（二分类）</li>
</ul>
<p>标签定义决定了：</p>
<ul>
<li>数据对齐方式（何时提取特征）</li>
<li>评估协议（时序 CV 的窗口设置）</li>
<li>样本选择（是否包含停牌股票）</li>
</ul>
</div>
</div>
</section>
<section id="多模态数据版图" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="多模态数据版图"><span class="header-section-number">7.1.2</span> 多模态数据版图</h3>
<section id="图像image" class="level4" data-number="7.1.2.1">
<h4 data-number="7.1.2.1" class="anchored" data-anchor-id="图像image"><span class="header-section-number">7.1.2.1</span> 图像（Image）</h4>
<table class="caption-top table">
<thead>
<tr class="header">
<th>数据源</th>
<th>金融应用</th>
<th>挑战</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>卫星图像</strong></td>
<td>预测零售客流、工厂活动、商品库存</td>
<td>空间对齐、云层遮挡</td>
</tr>
<tr class="even">
<td><strong>夜光数据</strong></td>
<td>区域经济活动强度</td>
<td>分辨率低、季节性</td>
</tr>
<tr class="odd">
<td><strong>票据/合同扫描件</strong></td>
<td>OCR 提取信息、欺诈检测</td>
<td>版式多样、噪声大</td>
</tr>
<tr class="even">
<td><strong>财报图表截图</strong></td>
<td>自动提取数据趋势</td>
<td>信息泄露风险（需确认发布时间）</td>
</tr>
<tr class="odd">
<td><strong>社交媒体图片</strong></td>
<td>品牌形象监测、产品识别</td>
<td>样本选择偏误</td>
</tr>
</tbody>
</table>
</section>
<section id="音频audio" class="level4" data-number="7.1.2.2">
<h4 data-number="7.1.2.2" class="anchored" data-anchor-id="音频audio"><span class="header-section-number">7.1.2.2</span> 音频（Audio）</h4>
<table class="caption-top table">
<thead>
<tr class="header">
<th>数据源</th>
<th>金融应用</th>
<th>挑战</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>财报电话会</strong></td>
<td>管理层情绪、不确定性识别</td>
<td>ASR 错误、说话人分离</td>
</tr>
<tr class="even">
<td><strong>客服录音</strong></td>
<td>客户满意度、投诉预警</td>
<td>隐私合规、信道噪声</td>
</tr>
<tr class="odd">
<td><strong>交易员通话</strong></td>
<td>合规监控、异常行为检测</td>
<td>实时性要求、术语识别</td>
</tr>
</tbody>
</table>
</section>
<section id="视频video" class="level4" data-number="7.1.2.3">
<h4 data-number="7.1.2.3" class="anchored" data-anchor-id="视频video"><span class="header-section-number">7.1.2.3</span> 视频（Video）</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 42%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>数据源</th>
<th>金融应用</th>
<th>挑战</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>管理层路演/发布会</strong></td>
<td>非言语线索（面部表情、手势）</td>
<td>角度/光照变化、遮挡</td>
</tr>
<tr class="even">
<td><strong>监控视频</strong></td>
<td>网点客流、ATM 异常</td>
<td>计算成本高、隐私问题</td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="视觉图像模态特征提取与变量构造" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="视觉图像模态特征提取与变量构造"><span class="header-section-number">7.2</span> 视觉（图像）模态：特征提取与变量构造</h2>
<section id="图像表示方法演进" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="图像表示方法演进"><span class="header-section-number">7.2.1</span> 图像表示方法演进</h3>
<section id="传统方法手工特征" class="level4" data-number="7.2.1.1">
<h4 data-number="7.2.1.1" class="anchored" data-anchor-id="传统方法手工特征"><span class="header-section-number">7.2.1.1</span> 传统方法：手工特征</h4>
<p><strong>低层特征</strong>：</p>
<ul>
<li>颜色直方图</li>
<li>纹理（Gabor 滤波器、LBP）</li>
<li>边缘检测（Canny、Sobel）</li>
</ul>
<p><strong>中层特征</strong>：</p>
<ul>
<li>SIFT（尺度不变特征变换）</li>
<li>HOG（方向梯度直方图）</li>
</ul>
<p><strong>问题</strong>：</p>
<ul>
<li>特征设计依赖专家知识</li>
<li>泛化能力有限</li>
</ul>
</section>
<section id="深度学习卷积神经网络cnn" class="level4" data-number="7.2.1.2">
<h4 data-number="7.2.1.2" class="anchored" data-anchor-id="深度学习卷积神经网络cnn"><span class="header-section-number">7.2.1.2</span> 深度学习：卷积神经网络（CNN）</h4>
<p><strong>经典架构演进</strong>：</p>
<pre><code>AlexNet (2012) → VGGNet (2014) → ResNet (2015) → EfficientNet (2019)</code></pre>
<p><strong>核心思想</strong>：</p>
<p>通过多层卷积+池化，自动学习从低层（边缘）到高层（物体）的特征层次。</p>
<p><strong>示例：ResNet-50</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> resnet50, ResNet50_Weights</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 加载预训练模型</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet50(weights<span class="op">=</span>ResNet50_Weights.IMAGENET1K_V1)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 提取特征（去掉最后的分类层）</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>feature_extractor <span class="op">=</span> torch.nn.Sequential(<span class="op">*</span><span class="bu">list</span>(model.children())[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 输入图像 → 2048维特征向量</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>image_tensor <span class="op">=</span> preprocess(image)  <span class="co"># (3, 224, 224)</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> feature_extractor(image_tensor.unsqueeze(<span class="dv">0</span>))  <span class="co"># (1, 2048, 1, 1)</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> features.squeeze()  <span class="co"># (2048,)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="最新视觉transformervit" class="level4" data-number="7.2.1.3">
<h4 data-number="7.2.1.3" class="anchored" data-anchor-id="最新视觉transformervit"><span class="header-section-number">7.2.1.3</span> 最新：视觉Transformer（ViT）</h4>
<p><strong>思想</strong>：</p>
<p>将图像切分为 patches，用 Transformer 处理（类似 NLP 中的词）。</p>
<p><strong>示例</strong>：</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> ViTModel, ViTImageProcessor</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> ViTImageProcessor.from_pretrained(<span class="st">'google/vit-base-patch16-224'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ViTModel.from_pretrained(<span class="st">'google/vit-base-patch16-224'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> processor(images<span class="op">=</span>image, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>image_embedding <span class="op">=</span> outputs.last_hidden_state[:, <span class="dv">0</span>, :]  <span class="co"># [CLS] token</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="自监督学习clip对比学习" class="level4" data-number="7.2.1.4">
<h4 data-number="7.2.1.4" class="anchored" data-anchor-id="自监督学习clip对比学习"><span class="header-section-number">7.2.1.4</span> 自监督学习：CLIP（对比学习）</h4>
<p><strong>核心思想</strong>（Radford et al., 2021）：</p>
<p>联合训练图像编码器与文本编码器，使匹配的图像-文本对在嵌入空间中接近。</p>
<p><strong>优势</strong>：</p>
<ul>
<li><strong>零样本迁移</strong>：无需标注数据即可分类</li>
<li><strong>跨模态检索</strong>：用文本查询图像，或反之</li>
</ul>
<p><strong>示例</strong>：</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> CLIPProcessor, CLIPModel</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CLIPModel.from_pretrained(<span class="st">"openai/clip-vit-base-patch32"</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> CLIPProcessor.from_pretrained(<span class="st">"openai/clip-vit-base-patch32"</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 图像 + 文本</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> load_image(<span class="st">"store.jpg"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [<span class="st">"a busy retail store"</span>, <span class="st">"an empty store"</span>]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> processor(text<span class="op">=</span>texts, images<span class="op">=</span>image, return_tensors<span class="op">=</span><span class="st">"pt"</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 计算图像-文本相似度</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>logits_per_image <span class="op">=</span> outputs.logits_per_image  <span class="co"># (1, 2)</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> logits_per_image.softmax(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># [0.8, 0.2] → "busy"</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="金融应用案例" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="金融应用案例"><span class="header-section-number">7.2.2</span> 金融应用案例</h3>
<section id="卫星图像预测经济活动" class="level4" data-number="7.2.2.1">
<h4 data-number="7.2.2.1" class="anchored" data-anchor-id="卫星图像预测经济活动"><span class="header-section-number">7.2.2.1</span> 卫星图像预测经济活动</h4>
<p><strong>任务</strong>：用停车场车辆数量预测零售商客流。</p>
<p><strong>流程</strong>：</p>
<pre><code>卫星图像（商场停车场）
    ↓
目标检测（YOLO/Faster R-CNN）→ 车辆数量
    ↓
时间序列聚合 → 周/月平均车辆数
    ↓
对齐到公司 → 预测销售额/股价</code></pre>
<p><strong>经典文献</strong>：</p>
<ul>
<li>Naik et al.&nbsp;(2019): <em>Measuring Economic Activity from Space</em></li>
</ul>
<p><strong>关键挑战</strong>：</p>
<ul>
<li><strong>空间对齐</strong>：停车场 → 具体门店 → 上市公司</li>
<li><strong>云层遮挡</strong>：缺失数据处理</li>
<li><strong>季节性</strong>：节假日/天气影响</li>
</ul>
</section>
<section id="财报图表自动提取" class="level4" data-number="7.2.2.2">
<h4 data-number="7.2.2.2" class="anchored" data-anchor-id="财报图表自动提取"><span class="header-section-number">7.2.2.2</span> 财报图表自动提取</h4>
<p><strong>任务</strong>：从年报 PDF 中提取趋势图，还原数据。</p>
<p><strong>流程</strong>：</p>
<pre><code>PDF → 图像提取 → 图表检测 → OCR 数字 → 数据重建</code></pre>
<p><strong>工具</strong>：</p>
<ul>
<li><strong>图表检测</strong>：Detectron2</li>
<li><strong>OCR</strong>：Tesseract, PaddleOCR</li>
<li><strong>数据提取</strong>：ChartOCR (专用工具)</li>
</ul>
<p><strong>风险</strong>：</p>
<ul>
<li><strong>信息泄露</strong>：必须确认图表在预测时点已发布</li>
<li><strong>测量误差</strong>：OCR 识别错误</li>
</ul>
</section>
<section id="社交媒体图片分析" class="level4" data-number="7.2.2.3">
<h4 data-number="7.2.2.3" class="anchored" data-anchor-id="社交媒体图片分析"><span class="header-section-number">7.2.2.3</span> 社交媒体图片分析</h4>
<p><strong>任务</strong>：品牌曝光度监测。</p>
<p><strong>流程</strong>：</p>
<pre><code>Instagram/Twitter 图片
    ↓
品牌 Logo 检测（YOLO 微调）
    ↓
聚合：每日品牌曝光次数
    ↓
预测：品牌价值、股价</code></pre>
<p><strong>挑战</strong>：</p>
<ul>
<li><strong>样本选择偏误</strong>：社交媒体用户不代表整体人群</li>
<li><strong>时间对齐</strong>：图片发布时间 vs 市场反应</li>
</ul>
</section>
</section>
<section id="关键对齐与偏误" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="关键对齐与偏误"><span class="header-section-number">7.2.3</span> 关键对齐与偏误</h3>
<section id="拍摄日-披露日" class="level4" data-number="7.2.3.1">
<h4 data-number="7.2.3.1" class="anchored" data-anchor-id="拍摄日-披露日"><span class="header-section-number">7.2.3.1</span> 拍摄日 ≠ 披露日</h4>
<p><strong>问题</strong>：</p>
<ul>
<li>卫星图像拍摄于 <span class="math inline">t</span> 日，但下载/处理后才在 <span class="math inline">t+k</span> 日可用</li>
<li>若用 <span class="math inline">t</span> 日图像预测 <span class="math inline">t</span> 日收益 → <strong>前瞻偏误</strong></li>
</ul>
<p><strong>解决</strong>：</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 记录图像拍摄时间与获取时间</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'image_date'</span>] <span class="op">=</span> <span class="st">'2024-01-15'</span>     <span class="co"># 卫星过境时间</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'available_date'</span>] <span class="op">=</span> <span class="st">'2024-01-18'</span> <span class="co"># 图像下载/处理完成时间</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 用 available_date 对齐到交易日</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'trade_date'</span>] <span class="op">=</span> df[<span class="st">'available_date'</span>].<span class="bu">apply</span>(next_trading_day)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="空间对齐" class="level4" data-number="7.2.3.2">
<h4 data-number="7.2.3.2" class="anchored" data-anchor-id="空间对齐"><span class="header-section-number">7.2.3.2</span> 空间对齐</h4>
<p><strong>问题</strong>：</p>
<ul>
<li>卫星图像覆盖区域 → 多个门店 → 多个公司</li>
</ul>
<p><strong>解决</strong>：</p>
<ul>
<li>使用<strong>地理信息系统（GIS）</strong>精确匹配</li>
<li>记录匹配规则与误差范围</li>
</ul>
</section>
<section id="域漂移domain-shift" class="level4" data-number="7.2.3.3">
<h4 data-number="7.2.3.3" class="anchored" data-anchor-id="域漂移domain-shift"><span class="header-section-number">7.2.3.3</span> 域漂移（Domain Shift）</h4>
<p><strong>问题</strong>：</p>
<ul>
<li>模型在 ImageNet 上预训练（自然图像）</li>
<li>应用于金融图像（卫星、票据）时性能下降</li>
</ul>
<p><strong>解决</strong>：</p>
<ul>
<li><strong>微调</strong>（Fine-tuning）：在目标域上继续训练</li>
<li><strong>领域自适应</strong>：减少源域与目标域的分布差异</li>
</ul>
</section>
<section id="质量控制" class="level4" data-number="7.2.3.4">
<h4 data-number="7.2.3.4" class="anchored" data-anchor-id="质量控制"><span class="header-section-number">7.2.3.4</span> 质量控制</h4>
<p><strong>常见问题</strong>：</p>
<ul>
<li>云层遮挡（卫星图像）</li>
<li>夜间图像过暗</li>
<li>压缩失真</li>
</ul>
<p><strong>解决</strong>：</p>
<ul>
<li>图像质量评分（模糊度、亮度检测）</li>
<li>剔除低质量样本</li>
</ul>
</section>
</section>
</section>
<section id="音频模态特征提取与测量误差" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="音频模态特征提取与测量误差"><span class="header-section-number">7.3</span> 音频模态：特征提取与测量误差</h2>
<section id="两条特征提取管线" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="两条特征提取管线"><span class="header-section-number">7.3.1</span> 两条特征提取管线</h3>
<section id="管线-1asr-文本接第3周流程" class="level4" data-number="7.3.1.1">
<h4 data-number="7.3.1.1" class="anchored" data-anchor-id="管线-1asr-文本接第3周流程"><span class="header-section-number">7.3.1.1</span> 管线 1：ASR → 文本（接第3周流程）</h4>
<p><strong>Automatic Speech Recognition（自动语音识别）</strong></p>
<p><strong>流程</strong>：</p>
<pre><code>音频文件（.wav/.mp3）
    ↓
ASR 模型（Whisper/Google Cloud Speech）
    ↓
文本转录
    ↓
应用第3周的文本分析方法</code></pre>
<p><strong>工具</strong>：</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> whisper</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># OpenAI Whisper（开源，高精度）</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> whisper.load_model(<span class="st">"base"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.transcribe(<span class="st">"earnings_call.mp3"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> result[<span class="st">"text"</span>]</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>优点</strong>：</p>
<ul>
<li>可用成熟的 NLP 方法</li>
<li>可解释性强</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li><strong>ASR 错误</strong>：识别不准（特别是专业术语、口音）</li>
<li><strong>丢失韵律信息</strong>：语调、停顿、语速</li>
</ul>
</section>
<section id="管线-2直接提取声学韵律特征" class="level4" data-number="7.3.1.2">
<h4 data-number="7.3.1.2" class="anchored" data-anchor-id="管线-2直接提取声学韵律特征"><span class="header-section-number">7.3.1.2</span> 管线 2：直接提取声学/韵律特征</h4>
<p><strong>不转文本，直接从音频提取特征</strong>：</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>特征类别</th>
<th>具体特征</th>
<th>金融含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>韵律（Prosody）</strong></td>
<td>音高（pitch）、语速（speaking rate）、停顿（pause）</td>
<td>情绪、紧张度</td>
</tr>
<tr class="even">
<td><strong>音质（Voice quality）</strong></td>
<td>颤音（jitter）、浊音（shimmer）</td>
<td>压力、不确定性</td>
</tr>
<tr class="odd">
<td><strong>能量</strong></td>
<td>音量、能量分布</td>
<td>强调、信心</td>
</tr>
<tr class="even">
<td><strong>低层特征</strong></td>
<td>MFCC（梅尔频率倒谱系数）</td>
<td>通用音频表示</td>
</tr>
<tr class="odd">
<td><strong>深度嵌入</strong></td>
<td>Wav2Vec 2.0, HuBERT</td>
<td>端到端学习</td>
</tr>
</tbody>
</table>
</section>
<section id="提取示例韵律特征" class="level4" data-number="7.3.1.3">
<h4 data-number="7.3.1.3" class="anchored" data-anchor-id="提取示例韵律特征"><span class="header-section-number">7.3.1.3</span> 提取示例：韵律特征</h4>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> librosa</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 加载音频</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(<span class="st">"audio.wav"</span>, sr<span class="op">=</span><span class="dv">16000</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 音高（基频）</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>pitches, magnitudes <span class="op">=</span> librosa.piptrack(y<span class="op">=</span>y, sr<span class="op">=</span>sr)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>pitch_mean <span class="op">=</span> np.mean(pitches[pitches <span class="op">&gt;</span> <span class="dv">0</span>])</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. 语速（通过零交叉率粗略估计）</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>zcr <span class="op">=</span> librosa.feature.zero_crossing_rate(y)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>speaking_rate <span class="op">=</span> np.mean(zcr)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. 停顿（检测静音段）</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>intervals <span class="op">=</span> librosa.effects.split(y, top_db<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>pause_count <span class="op">=</span> <span class="bu">len</span>(intervals) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> {</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pitch_mean'</span>: pitch_mean,</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">'speaking_rate'</span>: speaking_rate,</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pause_count'</span>: pause_count,</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="提取示例深度嵌入wav2vec-2.0" class="level4" data-number="7.3.1.4">
<h4 data-number="7.3.1.4" class="anchored" data-anchor-id="提取示例深度嵌入wav2vec-2.0"><span class="header-section-number">7.3.1.4</span> 提取示例：深度嵌入（Wav2Vec 2.0）</h4>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> Wav2Vec2Processor, Wav2Vec2Model</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> Wav2Vec2Processor.from_pretrained(<span class="st">"facebook/wav2vec2-base"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Wav2Vec2Model.from_pretrained(<span class="st">"facebook/wav2vec2-base"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 音频 → 特征向量</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>input_values <span class="op">=</span> processor(y, sampling_rate<span class="op">=</span>sr, return_tensors<span class="op">=</span><span class="st">"pt"</span>).input_values</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    hidden_states <span class="op">=</span> model(input_values).last_hidden_state</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 时间平均池化 → 固定长度向量</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>audio_embedding <span class="op">=</span> hidden_states.mean(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># (1, 768)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="金融应用案例-1" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="金融应用案例-1"><span class="header-section-number">7.3.2</span> 金融应用案例</h3>
<section id="财报电话会情绪识别" class="level4" data-number="7.3.2.1">
<h4 data-number="7.3.2.1" class="anchored" data-anchor-id="财报电话会情绪识别"><span class="header-section-number">7.3.2.1</span> 财报电话会情绪识别</h4>
<p><strong>任务</strong>：识别管理层的不确定性/紧张度。</p>
<p><strong>特征</strong>：</p>
<ul>
<li><strong>文本</strong>：词典法（不确定性词汇）</li>
<li><strong>韵律</strong>：音高方差、语速、停顿频率</li>
<li><strong>结合</strong>：多模态融合</li>
</ul>
<p><strong>经典文献</strong>：</p>
<ul>
<li>Mayew &amp; Venkatachalam (2012): <em>The Power of Voice</em></li>
<li>Larcker &amp; Zakolyukina (2012): <em>Detecting Deceptive Discussions</em></li>
</ul>
<p><strong>发现</strong>：</p>
<ul>
<li>音高升高、停顿增多 → 不确定性高</li>
<li>对未来股价有预测力（独立于文本）</li>
</ul>
</section>
<section id="客服录音质量监控" class="level4" data-number="7.3.2.2">
<h4 data-number="7.3.2.2" class="anchored" data-anchor-id="客服录音质量监控"><span class="header-section-number">7.3.2.2</span> 客服录音质量监控</h4>
<p><strong>任务</strong>：识别客户不满情绪，预警投诉。</p>
<p><strong>特征</strong>：</p>
<ul>
<li>客户语速、音量（急躁、愤怒）</li>
<li>客服响应时间</li>
</ul>
</section>
<section id="交易员通话合规监控" class="level4" data-number="7.3.2.3">
<h4 data-number="7.3.2.3" class="anchored" data-anchor-id="交易员通话合规监控"><span class="header-section-number">7.3.2.3</span> 交易员通话合规监控</h4>
<p><strong>任务</strong>：检测异常行为（如内幕交易暗示）。</p>
<p><strong>挑战</strong>：</p>
<ul>
<li>实时性要求高</li>
<li>术语丰富（需领域 ASR）</li>
<li>隐私合规</li>
</ul>
</section>
</section>
<section id="风险点与注意事项" class="level3" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="风险点与注意事项"><span class="header-section-number">7.3.3</span> 风险点与注意事项</h3>
<section id="asr-错误与信道噪声" class="level4" data-number="7.3.3.1">
<h4 data-number="7.3.3.1" class="anchored" data-anchor-id="asr-错误与信道噪声"><span class="header-section-number">7.3.3.1</span> ASR 错误与信道噪声</h4>
<p><strong>ASR 词错误率（WER）</strong>：</p>
<p><span class="math display">
\text{WER} = \frac{\text{插入} + \text{删除} + \text{替换}}{\text{总词数}}
</span></p>
<p><strong>影响因素</strong>：</p>
<ul>
<li>口音、语速</li>
<li>背景噪声（现场会议）</li>
<li>专业术语（如公司/产品名）</li>
</ul>
<p><strong>缓解</strong>：</p>
<ul>
<li>使用<strong>领域微调</strong>的 ASR（如金融专用模型）</li>
<li><strong>说话人分离</strong>：区分 CEO vs CFO vs 分析师</li>
<li><strong>置信度过滤</strong>：删除低置信度识别</li>
</ul>
</section>
<section id="说话人分离与身份对齐" class="level4" data-number="7.3.3.2">
<h4 data-number="7.3.3.2" class="anchored" data-anchor-id="说话人分离与身份对齐"><span class="header-section-number">7.3.3.2</span> 说话人分离与身份对齐</h4>
<p><strong>问题</strong>：</p>
<p>电话会中多人发言，需区分谁说了什么。</p>
<p><strong>技术</strong>：</p>
<ul>
<li><p><strong>说话人分段（Diarization）</strong>：标记每段音频的说话人</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyannote.audio <span class="im">import</span> Pipeline</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline.from_pretrained(<span class="st">"pyannote/speaker-diarization"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>diarization <span class="op">=</span> pipeline(<span class="st">"audio.wav"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> turn, _, speaker <span class="kw">in</span> diarization.itertracks(yield_label<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>speaker<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>turn<span class="sc">.</span>start<span class="sc">}</span><span class="ss">s - </span><span class="sc">{</span>turn<span class="sc">.</span>end<span class="sc">}</span><span class="ss">s"</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>说话人识别</strong>：匹配到具体人物（CEO/CFO）</p></li>
</ul>
<p><strong>挑战</strong>：</p>
<ul>
<li>音频质量差时错误率高</li>
<li>身份标注需人工验证</li>
</ul>
</section>
<section id="可得性选择偏误" class="level4" data-number="7.3.3.3">
<h4 data-number="7.3.3.3" class="anchored" data-anchor-id="可得性选择偏误"><span class="header-section-number">7.3.3.3</span> 可得性选择偏误</h4>
<p><strong>问题</strong>：</p>
<p>并非所有公司都公开电话会录音。</p>
<ul>
<li>大公司、透明度高的公司更可能公开</li>
<li>小公司、有负面消息的公司可能不公开</li>
</ul>
<p><strong>后果</strong>：</p>
<ul>
<li>样本代表性差</li>
<li>模型推广到全市场时失效</li>
</ul>
<p><strong>缓解</strong>：</p>
<ul>
<li>报告样本特征（市值、行业分布）</li>
<li>倾向评分加权（Propensity Score Weighting）</li>
</ul>
</section>
</section>
</section>
<section id="视频模态时序聚合行为信号与合规边界" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="视频模态时序聚合行为信号与合规边界"><span class="header-section-number">7.4</span> 视频模态：时序聚合、行为信号与合规边界</h2>
<section id="视频-图像序列-音频" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="视频-图像序列-音频"><span class="header-section-number">7.4.1</span> 视频 = 图像序列 + 音频</h3>
<p><strong>视频特征</strong>：</p>
<ul>
<li><strong>视觉通道</strong>：帧级图像特征</li>
<li><strong>音频通道</strong>：语音/背景音特征</li>
<li><strong>时序建模</strong>：捕捉动态变化</li>
</ul>
</section>
<section id="帧级视觉表征" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="帧级视觉表征"><span class="header-section-number">7.4.2</span> 帧级视觉表征</h3>
<section id="提取单帧特征" class="level4" data-number="7.4.2.1">
<h4 data-number="7.4.2.1" class="anchored" data-anchor-id="提取单帧特征"><span class="header-section-number">7.4.2.1</span> 提取单帧特征</h4>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 读取视频</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>cap <span class="op">=</span> cv2.VideoCapture(<span class="st">"video.mp4"</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>frames <span class="op">=</span> []</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> cap.isOpened():</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ret:</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    frames.append(frame)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>cap.release()</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 对每帧提取 CNN 特征</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> resnet50</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet50(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>feature_extractor <span class="op">=</span> torch.nn.Sequential(<span class="op">*</span><span class="bu">list</span>(model.children())[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>frame_features <span class="op">=</span> []</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> frame <span class="kw">in</span> frames[::<span class="dv">30</span>]:  <span class="co"># 每秒1帧（假设30fps）</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    tensor <span class="op">=</span> preprocess(frame)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    feature <span class="op">=</span> feature_extractor(tensor.unsqueeze(<span class="dv">0</span>)).squeeze()</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    frame_features.append(feature.numpy())</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 得到 (T, 2048) 的特征矩阵，T = 帧数</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="时间聚合" class="level4" data-number="7.4.2.2">
<h4 data-number="7.4.2.2" class="anchored" data-anchor-id="时间聚合"><span class="header-section-number">7.4.2.2</span> 时间聚合</h4>
<p><strong>简单方法</strong>：</p>
<ul>
<li><strong>平均池化</strong>：<span class="math inline">\mathbf{v}_{\text{video}} = \frac{1}{T}\sum_{t=1}^T \mathbf{v}_t</span></li>
<li><strong>最大池化</strong>：<span class="math inline">\mathbf{v}_{\text{video}} = \max_{t=1}^T \mathbf{v}_t</span></li>
</ul>
<p><strong>高级方法</strong>：</p>
<ul>
<li><strong>时序卷积网络（TCN）</strong></li>
<li><strong>LSTM/GRU</strong>：捕捉长期依赖</li>
<li><strong>Transformer</strong>：自注意力机制</li>
</ul>
</section>
</section>
<section id="行为线索非言语信号" class="level3" data-number="7.4.3">
<h3 data-number="7.4.3" class="anchored" data-anchor-id="行为线索非言语信号"><span class="header-section-number">7.4.3</span> 行为线索：非言语信号</h3>
<section id="面部动作编码facial-action-units-aus" class="level4" data-number="7.4.3.1">
<h4 data-number="7.4.3.1" class="anchored" data-anchor-id="面部动作编码facial-action-units-aus"><span class="header-section-number">7.4.3.1</span> 面部动作编码（Facial Action Units, AUs）</h4>
<p><strong>定义</strong>：</p>
<p>Paul Ekman 提出的面部肌肉运动编码系统，共 46 个 AU。</p>
<p><strong>示例</strong>：</p>
<ul>
<li>AU1: 内眉上扬（惊讶）</li>
<li>AU4: 皱眉（沉思、担忧）</li>
<li>AU12: 嘴角上扬（微笑）</li>
</ul>
<p><strong>提取工具</strong>：</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># OpenFace（开源）</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> subprocess</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>subprocess.run([</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"FeatureExtraction"</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"-f"</span>, <span class="st">"video.mp4"</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"-out_dir"</span>, <span class="st">"output/"</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 输出 CSV 文件，包含每帧的 AU 强度</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>aus <span class="op">=</span> pd.read_csv(<span class="st">"output/video.csv"</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(aus[[<span class="st">'AU01_r'</span>, <span class="st">'AU04_r'</span>, <span class="st">'AU12_r'</span>]].head())</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>金融应用</strong>：</p>
<ul>
<li>CEO 在路演中的微表情（紧张、自信）</li>
<li>与股价/融资成功率的关系</li>
</ul>
</section>
<section id="头部姿态head-pose" class="level4" data-number="7.4.3.2">
<h4 data-number="7.4.3.2" class="anchored" data-anchor-id="头部姿态head-pose"><span class="header-section-number">7.4.3.2</span> 头部姿态（Head Pose）</h4>
<p><strong>特征</strong>：</p>
<ul>
<li>Yaw（左右转）</li>
<li>Pitch（上下点头）</li>
<li>Roll（左右倾斜）</li>
</ul>
<p><strong>含义</strong>：</p>
<ul>
<li>频繁回避目光 → 不诚实？</li>
<li>频繁点头 → 认同/强调</li>
</ul>
</section>
<section id="注视gaze" class="level4" data-number="7.4.3.3">
<h4 data-number="7.4.3.3" class="anchored" data-anchor-id="注视gaze"><span class="header-section-number">7.4.3.3</span> 注视（Gaze）</h4>
<p><strong>特征</strong>：</p>
<ul>
<li>眼睛注视方向</li>
<li>眼神接触时长</li>
</ul>
<p><strong>金融应用</strong>：</p>
<ul>
<li>管理层回答问题时的眼神变化</li>
</ul>
</section>
</section>
<section id="时序建模示例lstm" class="level3" data-number="7.4.4">
<h3 data-number="7.4.4" class="anchored" data-anchor-id="时序建模示例lstm"><span class="header-section-number">7.4.4</span> 时序建模示例：LSTM</h3>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> VideoClassifier(nn.Module):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">2048</span>, hidden_dim<span class="op">=</span><span class="dv">512</span>, num_classes<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(input_dim, hidden_dim, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_dim, num_classes)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x: (batch, seq_len, input_dim)</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        _, (h_n, _) <span class="op">=</span> <span class="va">self</span>.lstm(x)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># h_n: (1, batch, hidden_dim)</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc(h_n.squeeze(<span class="dv">0</span>))</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> VideoClassifier()</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters())</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> video_features, labels <span class="kw">in</span> dataloader:</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(video_features)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="风险点与合规边界" class="level3" data-number="7.4.5">
<h3 data-number="7.4.5" class="anchored" data-anchor-id="风险点与合规边界"><span class="header-section-number">7.4.5</span> 风险点与合规边界</h3>
<section id="测量误差来源" class="level4" data-number="7.4.5.1">
<h4 data-number="7.4.5.1" class="anchored" data-anchor-id="测量误差来源"><span class="header-section-number">7.4.5.1</span> 测量误差来源</h4>
<p><strong>角度/光照/压缩</strong>：</p>
<ul>
<li>侧脸检测 AU 不准</li>
<li>逆光导致面部不清晰</li>
<li>视频压缩丢失细节</li>
</ul>
<p><strong>遮挡</strong>：</p>
<ul>
<li>手遮住脸</li>
<li>面具/口罩</li>
</ul>
<p><strong>缓解</strong>：</p>
<ul>
<li>质量评分：剔除低质量帧</li>
<li>数据增强：训练时模拟各种条件</li>
</ul>
</section>
<section id="算法偏差" class="level4" data-number="7.4.5.2">
<h4 data-number="7.4.5.2" class="anchored" data-anchor-id="算法偏差"><span class="header-section-number">7.4.5.2</span> 算法偏差</h4>
<p><strong>问题</strong>：</p>
<p>面部识别算法在不同人种/性别上的准确率不同。</p>
<ul>
<li>对白人、男性的识别率更高</li>
<li>对深色皮肤、女性的识别率较低</li>
</ul>
<p><strong>后果</strong>：</p>
<ul>
<li>模型对不同群体的预测存在系统性偏差</li>
<li>伦理与公平性问题</li>
</ul>
<p><strong>缓解</strong>：</p>
<ul>
<li>使用<strong>公平性优化</strong>的模型</li>
<li>报告不同群体的性能差异</li>
<li>在敏感场景中避免使用</li>
</ul>
</section>
<section id="涉及生物特征的合规边界" class="level4" data-number="7.4.5.3">
<h4 data-number="7.4.5.3" class="anchored" data-anchor-id="涉及生物特征的合规边界"><span class="header-section-number">7.4.5.3</span> 涉及生物特征的合规边界</h4>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
注意
</div>
</div>
<div class="callout-body-container callout-body">
<p>⚠️ 法律与伦理红线</p>
<p><strong>生物特征数据</strong>（面部、声纹、虹膜等）受严格监管：</p>
<p><strong>法规</strong>：</p>
<ul>
<li><strong>欧盟 GDPR</strong>：需明确同意，用途受限</li>
<li><strong>中国《个人信息保护法》</strong>：敏感个人信息，需单独同意</li>
<li><strong>美国各州法律</strong>：如加州 CCPA、伊利诺伊州 BIPA</li>
</ul>
<p><strong>禁止场景</strong>：</p>
<ul>
<li>未经同意的秘密收集</li>
<li>用于歧视性决策（如贷款审批基于面相）</li>
<li>大规模公共监控</li>
</ul>
<p><strong>合规建议</strong>：</p>
<ol type="1">
<li><strong>明确告知</strong>：数据收集目的、用途</li>
<li><strong>获取同意</strong>：可撤回的明确授权</li>
<li><strong>最小化原则</strong>：只收集必要数据</li>
<li><strong>去标识化</strong>：尽可能匿名化</li>
<li><strong>人工监督</strong>：敏感决策需人类审核</li>
</ol>
</div>
</div>
</section>
</section>
</section>
<section id="融合与分类评估多模态增量信息检验" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="融合与分类评估多模态增量信息检验"><span class="header-section-number">7.5</span> 融合与分类评估：多模态增量信息检验</h2>
<section id="融合策略" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="融合策略"><span class="header-section-number">7.5.1</span> 融合策略</h3>
<section id="早融合early-fusion" class="level4" data-number="7.5.1.1">
<h4 data-number="7.5.1.1" class="anchored" data-anchor-id="早融合early-fusion"><span class="header-section-number">7.5.1.1</span> 早融合（Early Fusion）</h4>
<p><strong>在特征层面拼接</strong>：</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 图像特征 (2048维) + 音频特征 (768维) + 文本特征 (768维)</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>multimodal_feature <span class="op">=</span> np.concatenate([</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    image_embedding,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    audio_embedding,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    text_embedding</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>])  <span class="co"># (3584维)</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 输入到分类器</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>classifier.fit(multimodal_feature, label)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>优点</strong>：简单</p>
<p><strong>缺点</strong>：</p>
<ul>
<li>不同模态维度差异大，可能主导性不均</li>
<li>缺失模态时难以处理</li>
</ul>
</section>
<section id="中期融合mid-fusion" class="level4" data-number="7.5.1.2">
<h4 data-number="7.5.1.2" class="anchored" data-anchor-id="中期融合mid-fusion"><span class="header-section-number">7.5.1.2</span> 中期融合（Mid Fusion）</h4>
<p><strong>各模态先单独编码，再融合</strong>：</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MidFusionModel(nn.Module):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_encoder <span class="op">=</span> nn.Linear(<span class="dv">2048</span>, <span class="dv">512</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.audio_encoder <span class="op">=</span> nn.Linear(<span class="dv">768</span>, <span class="dv">512</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_encoder <span class="op">=</span> nn.Linear(<span class="dv">768</span>, <span class="dv">512</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fusion <span class="op">=</span> nn.Linear(<span class="dv">512</span><span class="op">*</span><span class="dv">3</span>, <span class="dv">256</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Linear(<span class="dv">256</span>, <span class="dv">2</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, image, audio, text):</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>        img_emb <span class="op">=</span> <span class="va">self</span>.image_encoder(image)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        aud_emb <span class="op">=</span> <span class="va">self</span>.audio_encoder(audio)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        txt_emb <span class="op">=</span> <span class="va">self</span>.text_encoder(text)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>        fused <span class="op">=</span> torch.cat([img_emb, aud_emb, txt_emb], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        fused <span class="op">=</span> F.relu(<span class="va">self</span>.fusion(fused))</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.classifier(fused)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>优点</strong>：各模态地位平等</p>
</section>
<section id="后融合late-fusion" class="level4" data-number="7.5.1.3">
<h4 data-number="7.5.1.3" class="anchored" data-anchor-id="后融合late-fusion"><span class="header-section-number">7.5.1.3</span> 后融合（Late Fusion）</h4>
<p><strong>各模态单独预测，再集成</strong>：</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练三个独立分类器</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>image_pred <span class="op">=</span> image_classifier.predict_proba(image_features)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>audio_pred <span class="op">=</span> audio_classifier.predict_proba(audio_features)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>text_pred <span class="op">=</span> text_classifier.predict_proba(text_features)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 加权平均</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>final_pred <span class="op">=</span> <span class="fl">0.4</span> <span class="op">*</span> image_pred <span class="op">+</span> <span class="fl">0.3</span> <span class="op">*</span> audio_pred <span class="op">+</span> <span class="fl">0.3</span> <span class="op">*</span> text_pred</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>优点</strong>：</p>
<ul>
<li>可解释性强（知道各模态贡献）</li>
<li>容易处理缺失模态</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>未利用模态间交互</li>
</ul>
</section>
<section id="注意力融合attention-based" class="level4" data-number="7.5.1.4">
<h4 data-number="7.5.1.4" class="anchored" data-anchor-id="注意力融合attention-based"><span class="header-section-number">7.5.1.4</span> 注意力融合（Attention-based）</h4>
<p><strong>自动学习各模态的权重</strong>：</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionFusion(nn.Module):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">512</span>):</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention <span class="op">=</span> nn.Linear(input_dim, <span class="dv">1</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, modalities):</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># modalities: list of (batch, input_dim)</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        stacked <span class="op">=</span> torch.stack(modalities, dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># (batch, n_modalities, input_dim)</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 计算注意力权重</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        attn_scores <span class="op">=</span> <span class="va">self</span>.attention(stacked).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (batch, n_modalities)</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        attn_weights <span class="op">=</span> F.softmax(attn_scores, dim<span class="op">=</span><span class="dv">1</span>).unsqueeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (batch, n_modalities, 1)</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 加权和</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        fused <span class="op">=</span> (stacked <span class="op">*</span> attn_weights).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># (batch, input_dim)</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> fused</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>优点</strong>：自适应融合</p>
</section>
</section>
<section id="缺失模态处理" class="level3" data-number="7.5.2">
<h3 data-number="7.5.2" class="anchored" data-anchor-id="缺失模态处理"><span class="header-section-number">7.5.2</span> 缺失模态处理</h3>
<p><strong>现实问题</strong>：</p>
<ul>
<li>部分公司没有电话会录音（音频缺失）</li>
<li>部分时期卫星图像有云遮挡（图像缺失）</li>
</ul>
<p><strong>策略</strong>：</p>
<ol type="1">
<li><strong>删除缺失样本</strong>（简单但损失数据）</li>
<li><strong>用零向量填充</strong></li>
<li><strong>训练单模态 + 多模态模型</strong>，缺失时用单模态</li>
</ol>
</section>
<section id="增量贡献评估" class="level3" data-number="7.5.3">
<h3 data-number="7.5.3" class="anchored" data-anchor-id="增量贡献评估"><span class="header-section-number">7.5.3</span> 增量贡献评估</h3>
<section id="实验设计" class="level4" data-number="7.5.3.1">
<h4 data-number="7.5.3.1" class="anchored" data-anchor-id="实验设计"><span class="header-section-number">7.5.3.1</span> 实验设计</h4>
<p><strong>基准模型</strong>：仅用结构化变量（财务指标）</p>
<p><strong>增强模型</strong>：+ 文本变量</p>
<p><strong>多模态模型</strong>：+ 文本 + 图像/音频</p>
<p><strong>比较</strong>：</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>模型</th>
<th>AUC</th>
<th>F1</th>
<th>相对提升</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>基准（结构化）</td>
<td>0.75</td>
<td>0.68</td>
<td>-</td>
</tr>
<tr class="even">
<td>+ 文本</td>
<td>0.78</td>
<td>0.71</td>
<td>+4% AUC</td>
</tr>
<tr class="odd">
<td>+ 文本 + 音频</td>
<td>0.80</td>
<td>0.73</td>
<td>+6.7% AUC</td>
</tr>
</tbody>
</table>
<p><strong>统计检验</strong>：</p>
<ul>
<li><strong>DeLong 检验</strong>：比较 AUC 是否显著不同</li>
<li><strong>配对 t 检验</strong>：比较预测误差</li>
</ul>
</section>
<section id="互补性检验" class="level4" data-number="7.5.3.2">
<h4 data-number="7.5.3.2" class="anchored" data-anchor-id="互补性检验"><span class="header-section-number">7.5.3.2</span> 互补性检验</h4>
<p><strong>问题</strong>：多模态信号是否只是重复文本信息？</p>
<p><strong>检验</strong>：</p>
<ol type="1">
<li><p><strong>相关性分析</strong></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> df[[<span class="st">'text_sentiment'</span>, <span class="st">'audio_uncertainty'</span>, <span class="st">'image_activity'</span>]].corr()</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>相关系数 &lt; 0.6 为健康</li>
</ul></li>
<li><p><strong>分组分析</strong></p>
<ul>
<li>在文本信号弱的样本中，音频/图像是否作用更强？</li>
</ul></li>
<li><p><strong>消融实验（Ablation Study）</strong></p>
<ul>
<li>逐步移除各模态，观察性能下降</li>
</ul></li>
</ol>
</section>
<section id="误差分析" class="level4" data-number="7.5.3.3">
<h4 data-number="7.5.3.3" class="anchored" data-anchor-id="误差分析"><span class="header-section-number">7.5.3.3</span> 误差分析</h4>
<p><strong>案例分析</strong>：</p>
<ul>
<li>哪些样本预测错误？</li>
<li>是否某类样本（如小市值）更难预测？</li>
<li>多模态在哪些情况下帮助最大？</li>
</ul>
</section>
</section>
<section id="切片评估与稳健性" class="level3" data-number="7.5.4">
<h3 data-number="7.5.4" class="anchored" data-anchor-id="切片评估与稳健性"><span class="header-section-number">7.5.4</span> 切片评估与稳健性</h3>
<p><strong>时间切片</strong>：</p>
<ul>
<li>训练期 vs 测试期性能差异</li>
<li>不同市场状态（牛市/熊市）</li>
</ul>
<p><strong>横截面切片</strong>：</p>
<ul>
<li>不同行业（科技 vs 制造）</li>
<li>不同规模（大市值 vs 小市值）</li>
</ul>
<p><strong>目的</strong>：确保模型泛化能力。</p>
</section>
</section>
<section id="本周小结" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="本周小结"><span class="header-section-number">7.6</span> 本周小结</h2>
<section id="核心要点" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="核心要点"><span class="header-section-number">7.6.1</span> 核心要点</h3>
<ol type="1">
<li><strong>多模态任务设计</strong>：明确标签定义（何时、对谁、预测什么）</li>
<li><strong>图像特征</strong>：CNN/ViT/CLIP，注意空间对齐、质量控制、域漂移</li>
<li><strong>音频特征</strong>：ASR → 文本 vs 声学/韵律特征，注意 ASR 错误、说话人分离</li>
<li><strong>视频特征</strong>：帧级 + 时序建模，行为线索（AU/姿态/注视），注意测量误差</li>
<li><strong>融合策略</strong>：早/中/后融合、注意力机制，处理缺失模态</li>
<li><strong>增量检验</strong>：相对文本/结构化变量的增量贡献，互补性证据</li>
<li><strong>伦理边界</strong>：生物特征合规、算法偏差、隐私保护</li>
</ol>
</section>
<section id="本周思考题" class="level3" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="本周思考题"><span class="header-section-number">7.6.2</span> 本周思考题</h3>
<section id="问题-1" class="level4" data-number="7.6.2.1">
<h4 data-number="7.6.2.1" class="anchored" data-anchor-id="问题-1"><span class="header-section-number">7.6.2.1</span> 问题 1</h4>
<p>以”业绩电话会音频”构造一个分类任务（如识别管理层不确定性状态）时，标签通常如何定义？哪些环节最容易引入样本选择偏误？</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
注记
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>💡 参考答案</p>
<p><strong>标签定义</strong>：</p>
<ol type="1">
<li><strong>基于未来股价</strong>：
<ul>
<li><span class="math inline">y = \mathbb{I}(r_{t+1 \to t+k} &lt; \text{市场中位数})</span></li>
<li>不确定性高 → 未来表现差</li>
</ul></li>
<li><strong>基于财务意外</strong>：
<ul>
<li><span class="math inline">y = \mathbb{I}(|\text{实际EPS} - \text{预期EPS}| &gt; \text{阈值})</span></li>
<li>不确定性高 → 预测误差大</li>
</ul></li>
<li><strong>基于文本词典</strong>（辅助标注）：
<ul>
<li>统计不确定性词汇（“uncertain”, “might”, “could”）</li>
<li>人工验证部分样本</li>
</ul></li>
</ol>
<p><strong>样本选择偏误来源</strong>：</p>
<ol type="1">
<li><strong>可得性偏误</strong>
<ul>
<li>大公司、透明度高的公司更可能公开录音</li>
<li>小公司、有负面消息的可能隐藏</li>
</ul></li>
<li><strong>存活偏误</strong>
<ul>
<li>退市公司的电话会数据缺失</li>
</ul></li>
<li><strong>时期选择</strong>
<ul>
<li>危机期间电话会取消率更高</li>
</ul></li>
</ol>
<p><strong>缓解</strong>：</p>
<ul>
<li>报告样本特征分布</li>
<li>倾向评分加权</li>
<li>稳健性检验（仅用持续有数据的公司）</li>
</ul>
</div>
</div>
</div>
</section>
<section id="问题-2" class="level4" data-number="7.6.2.2">
<h4 data-number="7.6.2.2" class="anchored" data-anchor-id="问题-2"><span class="header-section-number">7.6.2.2</span> 问题 2</h4>
<p>如何严谨地证明多模态信号对文本/结构化变量具有增量信息？请给出一个你认为必要的互补性检验设计。</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
注记
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>💡 参考答案</p>
<p><strong>完整检验流程</strong>：</p>
<p><strong>1. 基准对比</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>模型</th>
<th>特征</th>
<th>AUC</th>
<th><span class="math inline">\Delta</span> AUC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>M1</td>
<td>结构化（财务指标）</td>
<td>0.72</td>
<td>-</td>
</tr>
<tr class="even">
<td>M2</td>
<td>M1 + 文本</td>
<td>0.76</td>
<td>+0.04</td>
</tr>
<tr class="odd">
<td>M3</td>
<td>M2 + 音频</td>
<td>0.79</td>
<td>+0.03</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>条件</strong>：<span class="math inline">\Delta</span> AUC 统计显著（DeLong 检验 <span class="math inline">p &lt; 0.05</span>）</li>
</ul>
<p><strong>2. 相关性分析</strong></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> df[[<span class="st">'structured'</span>, <span class="st">'text'</span>, <span class="st">'audio'</span>]].corr()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> corr_matrix.loc[<span class="st">'audio'</span>, <span class="st">'text'</span>] <span class="op">&lt;</span> <span class="fl">0.6</span>  <span class="co"># 避免高度冗余</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>3. 条件独立性检验</strong></p>
<p>在控制文本后，音频是否仍有预测力？</p>
<p><span class="math display">
\text{Logit}(y) = \beta_0 + \beta_1 \text{Text} + \beta_2 \text{Audio} + \varepsilon
</span></p>
<ul>
<li>检验：<span class="math inline">\beta_2</span> 是否显著？</li>
</ul>
<p><strong>4. 分组异质性</strong></p>
<p>在文本信号弱的子样本中，音频贡献更大：</p>
<pre><code>分组：文本情感 = 中性（信息量少）
  → 音频 AUC 提升更显著</code></pre>
<p><strong>5. 消融实验</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>移除模态</th>
<th>AUC 下降</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>去除音频</td>
<td>-0.03</td>
<td>音频有独特贡献</td>
</tr>
<tr class="even">
<td>去除文本</td>
<td>-0.04</td>
<td>文本仍重要</td>
</tr>
<tr class="odd">
<td>去除结构化</td>
<td>-0.05</td>
<td>基础变量最重要</td>
</tr>
</tbody>
</table>
<p><strong>结论模板</strong>：</p>
<p>“音频特征在控制文本与结构化变量后，仍能带来统计显著的 AUC 提升（+0.03, p=0.01）。相关性分析显示音频与文本相关系数为 0.45，表明二者捕捉了部分重叠但非完全冗余的信息。在文本情感中性的子样本中，音频的增量贡献更大（AUC +0.05），证实了互补性。”</p>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="课程前半段回顾" class="level3" data-number="7.6.3">
<h3 data-number="7.6.3" class="anchored" data-anchor-id="课程前半段回顾"><span class="header-section-number">7.6.3</span> 课程前半段回顾</h3>
<p>前四周我们建立了<strong>AI 赋能金融研究的完整框架</strong>：</p>
<ul>
<li><strong>第1周</strong>：机器学习基础（i.i.d. 场景）</li>
<li><strong>第2周</strong>：金融时序评估与回测规范</li>
<li><strong>第3周</strong>：文本分析的可审计流程</li>
<li><strong>第4周</strong>：多模态信号的增量检验</li>
</ul>
<p><strong>共同主线</strong>：</p>
<ol type="1">
<li><strong>泛化能力</strong>：样本外表现是唯一标准</li>
<li><strong>可审计性</strong>：从原始数据到变量的每一步可追溯</li>
<li><strong>增量价值</strong>：新方法必须相对已知方法展示增量信息</li>
</ol>
</section>
<section id="后半段课程预告" class="level3" data-number="7.6.4">
<h3 data-number="7.6.4" class="anchored" data-anchor-id="后半段课程预告"><span class="header-section-number">7.6.4</span> 后半段课程预告</h3>
<p><strong>第5-8周</strong>：学生研究计划汇报与研讨</p>
<ul>
<li>每组展示研究问题、数据、方法、评估协议</li>
<li>课堂讨论与反馈</li>
<li>强化<strong>最小证据链</strong>意识</li>
</ul>
<p><strong>第5周前</strong>将有<strong>课前测验</strong>，覆盖第1-4周核心概念，请提前复习！</p>
<hr>
<p><strong>祝学习顺利！期待看到你们的精彩研究！</strong></p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "已复制");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "已复制");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week3.html" class="pagination-link" aria-label="第3讲：文本分析理论 → 金融文本应用">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">第3讲：文本分析理论 → 金融文本应用</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./proposal.html" class="pagination-link" aria-label="小组研究项目指南">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">小组研究项目指南</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">源代码</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb24" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "第4讲：多模态模型理论 → 金融信号抽取"</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "图像、音频、视频的特征提取与增量信息检验"</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="fu">## 任务与数据：把多模态研究表述为分类问题</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="fu">### 为什么是"分类"？</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>虽然多模态数据形式多样（图像、音频、视频），但在金融应用中，核心任务通常可表述为**分类问题**：</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>预测**涨/跌**（二分类）</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>识别**管理层情绪状态**（多分类：乐观/中性/悲观）</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>判断**欺诈/非欺诈**（二分类）</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>预测**信用等级**（多分类）</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>:::{.callout-note icon=false}</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>🎯 标签定义的三要素</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**何时**（When）：预测哪个时期的结果？</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**对谁**（Who）：个股/行业/市场？</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**预测什么**（What）：具体的类别定义？</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>**示例**：</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**何时**：业绩电话会后第二个交易日</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**对谁**：该公司股票</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**预测什么**：收益率是否超过市场中位数（二分类）</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>标签定义决定了：</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>数据对齐方式（何时提取特征）</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>评估协议（时序 CV 的窗口设置）</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>样本选择（是否包含停牌股票）</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a><span class="fu">### 多模态数据版图</span></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 图像（Image）</span></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>| 数据源 | 金融应用 | 挑战 |</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>|-------|---------|-----|</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>| **卫星图像** | 预测零售客流、工厂活动、商品库存 | 空间对齐、云层遮挡 |</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>| **夜光数据** | 区域经济活动强度 | 分辨率低、季节性 |</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>| **票据/合同扫描件** | OCR 提取信息、欺诈检测 | 版式多样、噪声大 |</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>| **财报图表截图** | 自动提取数据趋势 | 信息泄露风险（需确认发布时间）|</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>| **社交媒体图片** | 品牌形象监测、产品识别 | 样本选择偏误 |</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 音频（Audio）</span></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>| 数据源 | 金融应用 | 挑战 |</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>|-------|---------|-----|</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>| **财报电话会** | 管理层情绪、不确定性识别 | ASR 错误、说话人分离 |</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>| **客服录音** | 客户满意度、投诉预警 | 隐私合规、信道噪声 |</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>| **交易员通话** | 合规监控、异常行为检测 | 实时性要求、术语识别 |</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 视频（Video）</span></span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>| 数据源 | 金融应用 | 挑战 |</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>|-------|---------|-----|</span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>| **管理层路演/发布会** | 非言语线索（面部表情、手势）| 角度/光照变化、遮挡 |</span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>| **监控视频** | 网点客流、ATM 异常 | 计算成本高、隐私问题 |</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## 视觉（图像）模态：特征提取与变量构造</span></span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a><span class="fu">### 图像表示方法演进</span></span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 传统方法：手工特征</span></span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>**低层特征**：</span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>颜色直方图</span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>纹理（Gabor 滤波器、LBP）</span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>边缘检测（Canny、Sobel）</span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a>**中层特征**：</span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>SIFT（尺度不变特征变换）</span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>HOG（方向梯度直方图）</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-81"><a href="#cb24-81" aria-hidden="true" tabindex="-1"></a>**问题**：</span>
<span id="cb24-82"><a href="#cb24-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-83"><a href="#cb24-83" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>特征设计依赖专家知识</span>
<span id="cb24-84"><a href="#cb24-84" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>泛化能力有限</span>
<span id="cb24-85"><a href="#cb24-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-86"><a href="#cb24-86" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 深度学习：卷积神经网络（CNN）</span></span>
<span id="cb24-87"><a href="#cb24-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-88"><a href="#cb24-88" aria-hidden="true" tabindex="-1"></a>**经典架构演进**：</span>
<span id="cb24-89"><a href="#cb24-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-90"><a href="#cb24-90" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-91"><a href="#cb24-91" aria-hidden="true" tabindex="-1"></a><span class="in">AlexNet (2012) → VGGNet (2014) → ResNet (2015) → EfficientNet (2019)</span></span>
<span id="cb24-92"><a href="#cb24-92" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-93"><a href="#cb24-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-94"><a href="#cb24-94" aria-hidden="true" tabindex="-1"></a>**核心思想**：</span>
<span id="cb24-95"><a href="#cb24-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-96"><a href="#cb24-96" aria-hidden="true" tabindex="-1"></a>通过多层卷积+池化，自动学习从低层（边缘）到高层（物体）的特征层次。</span>
<span id="cb24-97"><a href="#cb24-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-98"><a href="#cb24-98" aria-hidden="true" tabindex="-1"></a>**示例：ResNet-50**</span>
<span id="cb24-99"><a href="#cb24-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-100"><a href="#cb24-100" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-101"><a href="#cb24-101" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> resnet50, ResNet50_Weights</span>
<span id="cb24-102"><a href="#cb24-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-103"><a href="#cb24-103" aria-hidden="true" tabindex="-1"></a><span class="co"># 加载预训练模型</span></span>
<span id="cb24-104"><a href="#cb24-104" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet50(weights<span class="op">=</span>ResNet50_Weights.IMAGENET1K_V1)</span>
<span id="cb24-105"><a href="#cb24-105" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb24-106"><a href="#cb24-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-107"><a href="#cb24-107" aria-hidden="true" tabindex="-1"></a><span class="co"># 提取特征（去掉最后的分类层）</span></span>
<span id="cb24-108"><a href="#cb24-108" aria-hidden="true" tabindex="-1"></a>feature_extractor <span class="op">=</span> torch.nn.Sequential(<span class="op">*</span><span class="bu">list</span>(model.children())[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb24-109"><a href="#cb24-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-110"><a href="#cb24-110" aria-hidden="true" tabindex="-1"></a><span class="co"># 输入图像 → 2048维特征向量</span></span>
<span id="cb24-111"><a href="#cb24-111" aria-hidden="true" tabindex="-1"></a>image_tensor <span class="op">=</span> preprocess(image)  <span class="co"># (3, 224, 224)</span></span>
<span id="cb24-112"><a href="#cb24-112" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> feature_extractor(image_tensor.unsqueeze(<span class="dv">0</span>))  <span class="co"># (1, 2048, 1, 1)</span></span>
<span id="cb24-113"><a href="#cb24-113" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> features.squeeze()  <span class="co"># (2048,)</span></span>
<span id="cb24-114"><a href="#cb24-114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-115"><a href="#cb24-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-116"><a href="#cb24-116" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 最新：视觉Transformer（ViT）</span></span>
<span id="cb24-117"><a href="#cb24-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-118"><a href="#cb24-118" aria-hidden="true" tabindex="-1"></a>**思想**：</span>
<span id="cb24-119"><a href="#cb24-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-120"><a href="#cb24-120" aria-hidden="true" tabindex="-1"></a>将图像切分为 patches，用 Transformer 处理（类似 NLP 中的词）。</span>
<span id="cb24-121"><a href="#cb24-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-122"><a href="#cb24-122" aria-hidden="true" tabindex="-1"></a>**示例**：</span>
<span id="cb24-123"><a href="#cb24-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-124"><a href="#cb24-124" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-125"><a href="#cb24-125" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> ViTModel, ViTImageProcessor</span>
<span id="cb24-126"><a href="#cb24-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-127"><a href="#cb24-127" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> ViTImageProcessor.from_pretrained(<span class="st">'google/vit-base-patch16-224'</span>)</span>
<span id="cb24-128"><a href="#cb24-128" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ViTModel.from_pretrained(<span class="st">'google/vit-base-patch16-224'</span>)</span>
<span id="cb24-129"><a href="#cb24-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-130"><a href="#cb24-130" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> processor(images<span class="op">=</span>image, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb24-131"><a href="#cb24-131" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb24-132"><a href="#cb24-132" aria-hidden="true" tabindex="-1"></a>image_embedding <span class="op">=</span> outputs.last_hidden_state[:, <span class="dv">0</span>, :]  <span class="co"># [CLS] token</span></span>
<span id="cb24-133"><a href="#cb24-133" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-134"><a href="#cb24-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-135"><a href="#cb24-135" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 自监督学习：CLIP（对比学习）</span></span>
<span id="cb24-136"><a href="#cb24-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-137"><a href="#cb24-137" aria-hidden="true" tabindex="-1"></a>**核心思想**（Radford et al., 2021）：</span>
<span id="cb24-138"><a href="#cb24-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-139"><a href="#cb24-139" aria-hidden="true" tabindex="-1"></a>联合训练图像编码器与文本编码器，使匹配的图像-文本对在嵌入空间中接近。</span>
<span id="cb24-140"><a href="#cb24-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-141"><a href="#cb24-141" aria-hidden="true" tabindex="-1"></a>**优势**：</span>
<span id="cb24-142"><a href="#cb24-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-143"><a href="#cb24-143" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**零样本迁移**：无需标注数据即可分类</span>
<span id="cb24-144"><a href="#cb24-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**跨模态检索**：用文本查询图像，或反之</span>
<span id="cb24-145"><a href="#cb24-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-146"><a href="#cb24-146" aria-hidden="true" tabindex="-1"></a>**示例**：</span>
<span id="cb24-147"><a href="#cb24-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-148"><a href="#cb24-148" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-149"><a href="#cb24-149" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> CLIPProcessor, CLIPModel</span>
<span id="cb24-150"><a href="#cb24-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-151"><a href="#cb24-151" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CLIPModel.from_pretrained(<span class="st">"openai/clip-vit-base-patch32"</span>)</span>
<span id="cb24-152"><a href="#cb24-152" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> CLIPProcessor.from_pretrained(<span class="st">"openai/clip-vit-base-patch32"</span>)</span>
<span id="cb24-153"><a href="#cb24-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-154"><a href="#cb24-154" aria-hidden="true" tabindex="-1"></a><span class="co"># 图像 + 文本</span></span>
<span id="cb24-155"><a href="#cb24-155" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> load_image(<span class="st">"store.jpg"</span>)</span>
<span id="cb24-156"><a href="#cb24-156" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [<span class="st">"a busy retail store"</span>, <span class="st">"an empty store"</span>]</span>
<span id="cb24-157"><a href="#cb24-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-158"><a href="#cb24-158" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> processor(text<span class="op">=</span>texts, images<span class="op">=</span>image, return_tensors<span class="op">=</span><span class="st">"pt"</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-159"><a href="#cb24-159" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb24-160"><a href="#cb24-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-161"><a href="#cb24-161" aria-hidden="true" tabindex="-1"></a><span class="co"># 计算图像-文本相似度</span></span>
<span id="cb24-162"><a href="#cb24-162" aria-hidden="true" tabindex="-1"></a>logits_per_image <span class="op">=</span> outputs.logits_per_image  <span class="co"># (1, 2)</span></span>
<span id="cb24-163"><a href="#cb24-163" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> logits_per_image.softmax(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># [0.8, 0.2] → "busy"</span></span>
<span id="cb24-164"><a href="#cb24-164" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-165"><a href="#cb24-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-166"><a href="#cb24-166" aria-hidden="true" tabindex="-1"></a><span class="fu">### 金融应用案例</span></span>
<span id="cb24-167"><a href="#cb24-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-168"><a href="#cb24-168" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 卫星图像预测经济活动</span></span>
<span id="cb24-169"><a href="#cb24-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-170"><a href="#cb24-170" aria-hidden="true" tabindex="-1"></a>**任务**：用停车场车辆数量预测零售商客流。</span>
<span id="cb24-171"><a href="#cb24-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-172"><a href="#cb24-172" aria-hidden="true" tabindex="-1"></a>**流程**：</span>
<span id="cb24-173"><a href="#cb24-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-174"><a href="#cb24-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-175"><a href="#cb24-175" aria-hidden="true" tabindex="-1"></a><span class="in">卫星图像（商场停车场）</span></span>
<span id="cb24-176"><a href="#cb24-176" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-177"><a href="#cb24-177" aria-hidden="true" tabindex="-1"></a><span class="in">目标检测（YOLO/Faster R-CNN）→ 车辆数量</span></span>
<span id="cb24-178"><a href="#cb24-178" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-179"><a href="#cb24-179" aria-hidden="true" tabindex="-1"></a><span class="in">时间序列聚合 → 周/月平均车辆数</span></span>
<span id="cb24-180"><a href="#cb24-180" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-181"><a href="#cb24-181" aria-hidden="true" tabindex="-1"></a><span class="in">对齐到公司 → 预测销售额/股价</span></span>
<span id="cb24-182"><a href="#cb24-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-183"><a href="#cb24-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-184"><a href="#cb24-184" aria-hidden="true" tabindex="-1"></a>**经典文献**：</span>
<span id="cb24-185"><a href="#cb24-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-186"><a href="#cb24-186" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Naik et al. (2019): *Measuring Economic Activity from Space*</span>
<span id="cb24-187"><a href="#cb24-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-188"><a href="#cb24-188" aria-hidden="true" tabindex="-1"></a>**关键挑战**：</span>
<span id="cb24-189"><a href="#cb24-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-190"><a href="#cb24-190" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**空间对齐**：停车场 → 具体门店 → 上市公司</span>
<span id="cb24-191"><a href="#cb24-191" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**云层遮挡**：缺失数据处理</span>
<span id="cb24-192"><a href="#cb24-192" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**季节性**：节假日/天气影响</span>
<span id="cb24-193"><a href="#cb24-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-194"><a href="#cb24-194" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 财报图表自动提取</span></span>
<span id="cb24-195"><a href="#cb24-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-196"><a href="#cb24-196" aria-hidden="true" tabindex="-1"></a>**任务**：从年报 PDF 中提取趋势图，还原数据。</span>
<span id="cb24-197"><a href="#cb24-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-198"><a href="#cb24-198" aria-hidden="true" tabindex="-1"></a>**流程**：</span>
<span id="cb24-199"><a href="#cb24-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-200"><a href="#cb24-200" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-201"><a href="#cb24-201" aria-hidden="true" tabindex="-1"></a><span class="in">PDF → 图像提取 → 图表检测 → OCR 数字 → 数据重建</span></span>
<span id="cb24-202"><a href="#cb24-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-203"><a href="#cb24-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-204"><a href="#cb24-204" aria-hidden="true" tabindex="-1"></a>**工具**：</span>
<span id="cb24-205"><a href="#cb24-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-206"><a href="#cb24-206" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**图表检测**：Detectron2</span>
<span id="cb24-207"><a href="#cb24-207" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**OCR**：Tesseract, PaddleOCR</span>
<span id="cb24-208"><a href="#cb24-208" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**数据提取**：ChartOCR (专用工具)</span>
<span id="cb24-209"><a href="#cb24-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-210"><a href="#cb24-210" aria-hidden="true" tabindex="-1"></a>**风险**：</span>
<span id="cb24-211"><a href="#cb24-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-212"><a href="#cb24-212" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**信息泄露**：必须确认图表在预测时点已发布</span>
<span id="cb24-213"><a href="#cb24-213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**测量误差**：OCR 识别错误</span>
<span id="cb24-214"><a href="#cb24-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-215"><a href="#cb24-215" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 社交媒体图片分析</span></span>
<span id="cb24-216"><a href="#cb24-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-217"><a href="#cb24-217" aria-hidden="true" tabindex="-1"></a>**任务**：品牌曝光度监测。</span>
<span id="cb24-218"><a href="#cb24-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-219"><a href="#cb24-219" aria-hidden="true" tabindex="-1"></a>**流程**：</span>
<span id="cb24-220"><a href="#cb24-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-221"><a href="#cb24-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-222"><a href="#cb24-222" aria-hidden="true" tabindex="-1"></a><span class="in">Instagram/Twitter 图片</span></span>
<span id="cb24-223"><a href="#cb24-223" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-224"><a href="#cb24-224" aria-hidden="true" tabindex="-1"></a><span class="in">品牌 Logo 检测（YOLO 微调）</span></span>
<span id="cb24-225"><a href="#cb24-225" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-226"><a href="#cb24-226" aria-hidden="true" tabindex="-1"></a><span class="in">聚合：每日品牌曝光次数</span></span>
<span id="cb24-227"><a href="#cb24-227" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-228"><a href="#cb24-228" aria-hidden="true" tabindex="-1"></a><span class="in">预测：品牌价值、股价</span></span>
<span id="cb24-229"><a href="#cb24-229" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-230"><a href="#cb24-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-231"><a href="#cb24-231" aria-hidden="true" tabindex="-1"></a>**挑战**：</span>
<span id="cb24-232"><a href="#cb24-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-233"><a href="#cb24-233" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**样本选择偏误**：社交媒体用户不代表整体人群</span>
<span id="cb24-234"><a href="#cb24-234" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**时间对齐**：图片发布时间 vs 市场反应</span>
<span id="cb24-235"><a href="#cb24-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-236"><a href="#cb24-236" aria-hidden="true" tabindex="-1"></a><span class="fu">### 关键对齐与偏误</span></span>
<span id="cb24-237"><a href="#cb24-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-238"><a href="#cb24-238" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 拍摄日 ≠ 披露日</span></span>
<span id="cb24-239"><a href="#cb24-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-240"><a href="#cb24-240" aria-hidden="true" tabindex="-1"></a>**问题**：</span>
<span id="cb24-241"><a href="#cb24-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-242"><a href="#cb24-242" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>卫星图像拍摄于 $t$ 日，但下载/处理后才在 $t+k$ 日可用</span>
<span id="cb24-243"><a href="#cb24-243" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>若用 $t$ 日图像预测 $t$ 日收益 → **前瞻偏误**</span>
<span id="cb24-244"><a href="#cb24-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-245"><a href="#cb24-245" aria-hidden="true" tabindex="-1"></a>**解决**：</span>
<span id="cb24-246"><a href="#cb24-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-247"><a href="#cb24-247" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-248"><a href="#cb24-248" aria-hidden="true" tabindex="-1"></a><span class="co"># 记录图像拍摄时间与获取时间</span></span>
<span id="cb24-249"><a href="#cb24-249" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'image_date'</span>] <span class="op">=</span> <span class="st">'2024-01-15'</span>     <span class="co"># 卫星过境时间</span></span>
<span id="cb24-250"><a href="#cb24-250" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'available_date'</span>] <span class="op">=</span> <span class="st">'2024-01-18'</span> <span class="co"># 图像下载/处理完成时间</span></span>
<span id="cb24-251"><a href="#cb24-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-252"><a href="#cb24-252" aria-hidden="true" tabindex="-1"></a><span class="co"># 用 available_date 对齐到交易日</span></span>
<span id="cb24-253"><a href="#cb24-253" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'trade_date'</span>] <span class="op">=</span> df[<span class="st">'available_date'</span>].<span class="bu">apply</span>(next_trading_day)</span>
<span id="cb24-254"><a href="#cb24-254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-255"><a href="#cb24-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-256"><a href="#cb24-256" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 空间对齐</span></span>
<span id="cb24-257"><a href="#cb24-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-258"><a href="#cb24-258" aria-hidden="true" tabindex="-1"></a>**问题**：</span>
<span id="cb24-259"><a href="#cb24-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-260"><a href="#cb24-260" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>卫星图像覆盖区域 → 多个门店 → 多个公司</span>
<span id="cb24-261"><a href="#cb24-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-262"><a href="#cb24-262" aria-hidden="true" tabindex="-1"></a>**解决**：</span>
<span id="cb24-263"><a href="#cb24-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-264"><a href="#cb24-264" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>使用**地理信息系统（GIS）**精确匹配</span>
<span id="cb24-265"><a href="#cb24-265" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>记录匹配规则与误差范围</span>
<span id="cb24-266"><a href="#cb24-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-267"><a href="#cb24-267" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 域漂移（Domain Shift）</span></span>
<span id="cb24-268"><a href="#cb24-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-269"><a href="#cb24-269" aria-hidden="true" tabindex="-1"></a>**问题**：</span>
<span id="cb24-270"><a href="#cb24-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-271"><a href="#cb24-271" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>模型在 ImageNet 上预训练（自然图像）</span>
<span id="cb24-272"><a href="#cb24-272" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>应用于金融图像（卫星、票据）时性能下降</span>
<span id="cb24-273"><a href="#cb24-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-274"><a href="#cb24-274" aria-hidden="true" tabindex="-1"></a>**解决**：</span>
<span id="cb24-275"><a href="#cb24-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-276"><a href="#cb24-276" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**微调**（Fine-tuning）：在目标域上继续训练</span>
<span id="cb24-277"><a href="#cb24-277" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**领域自适应**：减少源域与目标域的分布差异</span>
<span id="cb24-278"><a href="#cb24-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-279"><a href="#cb24-279" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 质量控制</span></span>
<span id="cb24-280"><a href="#cb24-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-281"><a href="#cb24-281" aria-hidden="true" tabindex="-1"></a>**常见问题**：</span>
<span id="cb24-282"><a href="#cb24-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-283"><a href="#cb24-283" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>云层遮挡（卫星图像）</span>
<span id="cb24-284"><a href="#cb24-284" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>夜间图像过暗</span>
<span id="cb24-285"><a href="#cb24-285" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>压缩失真</span>
<span id="cb24-286"><a href="#cb24-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-287"><a href="#cb24-287" aria-hidden="true" tabindex="-1"></a>**解决**：</span>
<span id="cb24-288"><a href="#cb24-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-289"><a href="#cb24-289" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>图像质量评分（模糊度、亮度检测）</span>
<span id="cb24-290"><a href="#cb24-290" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>剔除低质量样本</span>
<span id="cb24-291"><a href="#cb24-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-292"><a href="#cb24-292" aria-hidden="true" tabindex="-1"></a><span class="fu">## 音频模态：特征提取与测量误差</span></span>
<span id="cb24-293"><a href="#cb24-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-294"><a href="#cb24-294" aria-hidden="true" tabindex="-1"></a><span class="fu">### 两条特征提取管线</span></span>
<span id="cb24-295"><a href="#cb24-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-296"><a href="#cb24-296" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 管线 1：ASR → 文本（接第3周流程）</span></span>
<span id="cb24-297"><a href="#cb24-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-298"><a href="#cb24-298" aria-hidden="true" tabindex="-1"></a>**Automatic Speech Recognition（自动语音识别）**</span>
<span id="cb24-299"><a href="#cb24-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-300"><a href="#cb24-300" aria-hidden="true" tabindex="-1"></a>**流程**：</span>
<span id="cb24-301"><a href="#cb24-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-302"><a href="#cb24-302" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-303"><a href="#cb24-303" aria-hidden="true" tabindex="-1"></a><span class="in">音频文件（.wav/.mp3）</span></span>
<span id="cb24-304"><a href="#cb24-304" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-305"><a href="#cb24-305" aria-hidden="true" tabindex="-1"></a><span class="in">ASR 模型（Whisper/Google Cloud Speech）</span></span>
<span id="cb24-306"><a href="#cb24-306" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-307"><a href="#cb24-307" aria-hidden="true" tabindex="-1"></a><span class="in">文本转录</span></span>
<span id="cb24-308"><a href="#cb24-308" aria-hidden="true" tabindex="-1"></a><span class="in">    ↓</span></span>
<span id="cb24-309"><a href="#cb24-309" aria-hidden="true" tabindex="-1"></a><span class="in">应用第3周的文本分析方法</span></span>
<span id="cb24-310"><a href="#cb24-310" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-311"><a href="#cb24-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-312"><a href="#cb24-312" aria-hidden="true" tabindex="-1"></a>**工具**：</span>
<span id="cb24-313"><a href="#cb24-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-314"><a href="#cb24-314" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-315"><a href="#cb24-315" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> whisper</span>
<span id="cb24-316"><a href="#cb24-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-317"><a href="#cb24-317" aria-hidden="true" tabindex="-1"></a><span class="co"># OpenAI Whisper（开源，高精度）</span></span>
<span id="cb24-318"><a href="#cb24-318" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> whisper.load_model(<span class="st">"base"</span>)</span>
<span id="cb24-319"><a href="#cb24-319" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.transcribe(<span class="st">"earnings_call.mp3"</span>)</span>
<span id="cb24-320"><a href="#cb24-320" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> result[<span class="st">"text"</span>]</span>
<span id="cb24-321"><a href="#cb24-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-322"><a href="#cb24-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-323"><a href="#cb24-323" aria-hidden="true" tabindex="-1"></a>**优点**：</span>
<span id="cb24-324"><a href="#cb24-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-325"><a href="#cb24-325" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>可用成熟的 NLP 方法</span>
<span id="cb24-326"><a href="#cb24-326" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>可解释性强</span>
<span id="cb24-327"><a href="#cb24-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-328"><a href="#cb24-328" aria-hidden="true" tabindex="-1"></a>**缺点**：</span>
<span id="cb24-329"><a href="#cb24-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-330"><a href="#cb24-330" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**ASR 错误**：识别不准（特别是专业术语、口音）</span>
<span id="cb24-331"><a href="#cb24-331" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**丢失韵律信息**：语调、停顿、语速</span>
<span id="cb24-332"><a href="#cb24-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-333"><a href="#cb24-333" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 管线 2：直接提取声学/韵律特征</span></span>
<span id="cb24-334"><a href="#cb24-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-335"><a href="#cb24-335" aria-hidden="true" tabindex="-1"></a>**不转文本，直接从音频提取特征**：</span>
<span id="cb24-336"><a href="#cb24-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-337"><a href="#cb24-337" aria-hidden="true" tabindex="-1"></a>| 特征类别 | 具体特征 | 金融含义 |</span>
<span id="cb24-338"><a href="#cb24-338" aria-hidden="true" tabindex="-1"></a>|---------|---------|---------|</span>
<span id="cb24-339"><a href="#cb24-339" aria-hidden="true" tabindex="-1"></a>| **韵律（Prosody）** | 音高（pitch）、语速（speaking rate）、停顿（pause） | 情绪、紧张度 |</span>
<span id="cb24-340"><a href="#cb24-340" aria-hidden="true" tabindex="-1"></a>| **音质（Voice quality）** | 颤音（jitter）、浊音（shimmer） | 压力、不确定性 |</span>
<span id="cb24-341"><a href="#cb24-341" aria-hidden="true" tabindex="-1"></a>| **能量** | 音量、能量分布 | 强调、信心 |</span>
<span id="cb24-342"><a href="#cb24-342" aria-hidden="true" tabindex="-1"></a>| **低层特征** | MFCC（梅尔频率倒谱系数） | 通用音频表示 |</span>
<span id="cb24-343"><a href="#cb24-343" aria-hidden="true" tabindex="-1"></a>| **深度嵌入** | Wav2Vec 2.0, HuBERT | 端到端学习 |</span>
<span id="cb24-344"><a href="#cb24-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-345"><a href="#cb24-345" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 提取示例：韵律特征</span></span>
<span id="cb24-346"><a href="#cb24-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-347"><a href="#cb24-347" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-348"><a href="#cb24-348" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> librosa</span>
<span id="cb24-349"><a href="#cb24-349" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-350"><a href="#cb24-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-351"><a href="#cb24-351" aria-hidden="true" tabindex="-1"></a><span class="co"># 加载音频</span></span>
<span id="cb24-352"><a href="#cb24-352" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(<span class="st">"audio.wav"</span>, sr<span class="op">=</span><span class="dv">16000</span>)</span>
<span id="cb24-353"><a href="#cb24-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-354"><a href="#cb24-354" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 音高（基频）</span></span>
<span id="cb24-355"><a href="#cb24-355" aria-hidden="true" tabindex="-1"></a>pitches, magnitudes <span class="op">=</span> librosa.piptrack(y<span class="op">=</span>y, sr<span class="op">=</span>sr)</span>
<span id="cb24-356"><a href="#cb24-356" aria-hidden="true" tabindex="-1"></a>pitch_mean <span class="op">=</span> np.mean(pitches[pitches <span class="op">&gt;</span> <span class="dv">0</span>])</span>
<span id="cb24-357"><a href="#cb24-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-358"><a href="#cb24-358" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. 语速（通过零交叉率粗略估计）</span></span>
<span id="cb24-359"><a href="#cb24-359" aria-hidden="true" tabindex="-1"></a>zcr <span class="op">=</span> librosa.feature.zero_crossing_rate(y)</span>
<span id="cb24-360"><a href="#cb24-360" aria-hidden="true" tabindex="-1"></a>speaking_rate <span class="op">=</span> np.mean(zcr)</span>
<span id="cb24-361"><a href="#cb24-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-362"><a href="#cb24-362" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. 停顿（检测静音段）</span></span>
<span id="cb24-363"><a href="#cb24-363" aria-hidden="true" tabindex="-1"></a>intervals <span class="op">=</span> librosa.effects.split(y, top_db<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb24-364"><a href="#cb24-364" aria-hidden="true" tabindex="-1"></a>pause_count <span class="op">=</span> <span class="bu">len</span>(intervals) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb24-365"><a href="#cb24-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-366"><a href="#cb24-366" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> {</span>
<span id="cb24-367"><a href="#cb24-367" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pitch_mean'</span>: pitch_mean,</span>
<span id="cb24-368"><a href="#cb24-368" aria-hidden="true" tabindex="-1"></a>    <span class="st">'speaking_rate'</span>: speaking_rate,</span>
<span id="cb24-369"><a href="#cb24-369" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pause_count'</span>: pause_count,</span>
<span id="cb24-370"><a href="#cb24-370" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-371"><a href="#cb24-371" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-372"><a href="#cb24-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-373"><a href="#cb24-373" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 提取示例：深度嵌入（Wav2Vec 2.0）</span></span>
<span id="cb24-374"><a href="#cb24-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-375"><a href="#cb24-375" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-376"><a href="#cb24-376" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> Wav2Vec2Processor, Wav2Vec2Model</span>
<span id="cb24-377"><a href="#cb24-377" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-378"><a href="#cb24-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-379"><a href="#cb24-379" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> Wav2Vec2Processor.from_pretrained(<span class="st">"facebook/wav2vec2-base"</span>)</span>
<span id="cb24-380"><a href="#cb24-380" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Wav2Vec2Model.from_pretrained(<span class="st">"facebook/wav2vec2-base"</span>)</span>
<span id="cb24-381"><a href="#cb24-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-382"><a href="#cb24-382" aria-hidden="true" tabindex="-1"></a><span class="co"># 音频 → 特征向量</span></span>
<span id="cb24-383"><a href="#cb24-383" aria-hidden="true" tabindex="-1"></a>input_values <span class="op">=</span> processor(y, sampling_rate<span class="op">=</span>sr, return_tensors<span class="op">=</span><span class="st">"pt"</span>).input_values</span>
<span id="cb24-384"><a href="#cb24-384" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-385"><a href="#cb24-385" aria-hidden="true" tabindex="-1"></a>    hidden_states <span class="op">=</span> model(input_values).last_hidden_state</span>
<span id="cb24-386"><a href="#cb24-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-387"><a href="#cb24-387" aria-hidden="true" tabindex="-1"></a><span class="co"># 时间平均池化 → 固定长度向量</span></span>
<span id="cb24-388"><a href="#cb24-388" aria-hidden="true" tabindex="-1"></a>audio_embedding <span class="op">=</span> hidden_states.mean(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># (1, 768)</span></span>
<span id="cb24-389"><a href="#cb24-389" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-390"><a href="#cb24-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-391"><a href="#cb24-391" aria-hidden="true" tabindex="-1"></a><span class="fu">### 金融应用案例</span></span>
<span id="cb24-392"><a href="#cb24-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-393"><a href="#cb24-393" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 财报电话会情绪识别</span></span>
<span id="cb24-394"><a href="#cb24-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-395"><a href="#cb24-395" aria-hidden="true" tabindex="-1"></a>**任务**：识别管理层的不确定性/紧张度。</span>
<span id="cb24-396"><a href="#cb24-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-397"><a href="#cb24-397" aria-hidden="true" tabindex="-1"></a>**特征**：</span>
<span id="cb24-398"><a href="#cb24-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-399"><a href="#cb24-399" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**文本**：词典法（不确定性词汇）</span>
<span id="cb24-400"><a href="#cb24-400" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**韵律**：音高方差、语速、停顿频率</span>
<span id="cb24-401"><a href="#cb24-401" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**结合**：多模态融合</span>
<span id="cb24-402"><a href="#cb24-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-403"><a href="#cb24-403" aria-hidden="true" tabindex="-1"></a>**经典文献**：</span>
<span id="cb24-404"><a href="#cb24-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-405"><a href="#cb24-405" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Mayew &amp; Venkatachalam (2012): *The Power of Voice*</span>
<span id="cb24-406"><a href="#cb24-406" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Larcker &amp; Zakolyukina (2012): *Detecting Deceptive Discussions*</span>
<span id="cb24-407"><a href="#cb24-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-408"><a href="#cb24-408" aria-hidden="true" tabindex="-1"></a>**发现**：</span>
<span id="cb24-409"><a href="#cb24-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-410"><a href="#cb24-410" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>音高升高、停顿增多 → 不确定性高</span>
<span id="cb24-411"><a href="#cb24-411" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>对未来股价有预测力（独立于文本）</span>
<span id="cb24-412"><a href="#cb24-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-413"><a href="#cb24-413" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 客服录音质量监控</span></span>
<span id="cb24-414"><a href="#cb24-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-415"><a href="#cb24-415" aria-hidden="true" tabindex="-1"></a>**任务**：识别客户不满情绪，预警投诉。</span>
<span id="cb24-416"><a href="#cb24-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-417"><a href="#cb24-417" aria-hidden="true" tabindex="-1"></a>**特征**：</span>
<span id="cb24-418"><a href="#cb24-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-419"><a href="#cb24-419" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>客户语速、音量（急躁、愤怒）</span>
<span id="cb24-420"><a href="#cb24-420" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>客服响应时间</span>
<span id="cb24-421"><a href="#cb24-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-422"><a href="#cb24-422" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 交易员通话合规监控</span></span>
<span id="cb24-423"><a href="#cb24-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-424"><a href="#cb24-424" aria-hidden="true" tabindex="-1"></a>**任务**：检测异常行为（如内幕交易暗示）。</span>
<span id="cb24-425"><a href="#cb24-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-426"><a href="#cb24-426" aria-hidden="true" tabindex="-1"></a>**挑战**：</span>
<span id="cb24-427"><a href="#cb24-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-428"><a href="#cb24-428" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>实时性要求高</span>
<span id="cb24-429"><a href="#cb24-429" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>术语丰富（需领域 ASR）</span>
<span id="cb24-430"><a href="#cb24-430" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>隐私合规</span>
<span id="cb24-431"><a href="#cb24-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-432"><a href="#cb24-432" aria-hidden="true" tabindex="-1"></a><span class="fu">### 风险点与注意事项</span></span>
<span id="cb24-433"><a href="#cb24-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-434"><a href="#cb24-434" aria-hidden="true" tabindex="-1"></a><span class="fu">#### ASR 错误与信道噪声</span></span>
<span id="cb24-435"><a href="#cb24-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-436"><a href="#cb24-436" aria-hidden="true" tabindex="-1"></a>**ASR 词错误率（WER）**：</span>
<span id="cb24-437"><a href="#cb24-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-438"><a href="#cb24-438" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb24-439"><a href="#cb24-439" aria-hidden="true" tabindex="-1"></a>\text{WER} = \frac{\text{插入} + \text{删除} + \text{替换}}{\text{总词数}}</span>
<span id="cb24-440"><a href="#cb24-440" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb24-441"><a href="#cb24-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-442"><a href="#cb24-442" aria-hidden="true" tabindex="-1"></a>**影响因素**：</span>
<span id="cb24-443"><a href="#cb24-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-444"><a href="#cb24-444" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>口音、语速</span>
<span id="cb24-445"><a href="#cb24-445" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>背景噪声（现场会议）</span>
<span id="cb24-446"><a href="#cb24-446" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>专业术语（如公司/产品名）</span>
<span id="cb24-447"><a href="#cb24-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-448"><a href="#cb24-448" aria-hidden="true" tabindex="-1"></a>**缓解**：</span>
<span id="cb24-449"><a href="#cb24-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-450"><a href="#cb24-450" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>使用**领域微调**的 ASR（如金融专用模型）</span>
<span id="cb24-451"><a href="#cb24-451" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**说话人分离**：区分 CEO vs CFO vs 分析师</span>
<span id="cb24-452"><a href="#cb24-452" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**置信度过滤**：删除低置信度识别</span>
<span id="cb24-453"><a href="#cb24-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-454"><a href="#cb24-454" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 说话人分离与身份对齐</span></span>
<span id="cb24-455"><a href="#cb24-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-456"><a href="#cb24-456" aria-hidden="true" tabindex="-1"></a>**问题**：</span>
<span id="cb24-457"><a href="#cb24-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-458"><a href="#cb24-458" aria-hidden="true" tabindex="-1"></a>电话会中多人发言，需区分谁说了什么。</span>
<span id="cb24-459"><a href="#cb24-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-460"><a href="#cb24-460" aria-hidden="true" tabindex="-1"></a>**技术**：</span>
<span id="cb24-461"><a href="#cb24-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-462"><a href="#cb24-462" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**说话人分段（Diarization）**：标记每段音频的说话人</span>
<span id="cb24-463"><a href="#cb24-463" aria-hidden="true" tabindex="-1"></a>  <span class="in">```python</span></span>
<span id="cb24-464"><a href="#cb24-464" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> pyannote.audio <span class="im">import</span> Pipeline</span>
<span id="cb24-465"><a href="#cb24-465" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-466"><a href="#cb24-466" aria-hidden="true" tabindex="-1"></a>  pipeline <span class="op">=</span> Pipeline.from_pretrained(<span class="st">"pyannote/speaker-diarization"</span>)</span>
<span id="cb24-467"><a href="#cb24-467" aria-hidden="true" tabindex="-1"></a>  diarization <span class="op">=</span> pipeline(<span class="st">"audio.wav"</span>)</span>
<span id="cb24-468"><a href="#cb24-468" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-469"><a href="#cb24-469" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> turn, _, speaker <span class="kw">in</span> diarization.itertracks(yield_label<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb24-470"><a href="#cb24-470" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>speaker<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>turn<span class="sc">.</span>start<span class="sc">}</span><span class="ss">s - </span><span class="sc">{</span>turn<span class="sc">.</span>end<span class="sc">}</span><span class="ss">s"</span>)</span>
<span id="cb24-471"><a href="#cb24-471" aria-hidden="true" tabindex="-1"></a>  <span class="in">```</span></span>
<span id="cb24-472"><a href="#cb24-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-473"><a href="#cb24-473" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**说话人识别**：匹配到具体人物（CEO/CFO）</span>
<span id="cb24-474"><a href="#cb24-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-475"><a href="#cb24-475" aria-hidden="true" tabindex="-1"></a>**挑战**：</span>
<span id="cb24-476"><a href="#cb24-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-477"><a href="#cb24-477" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>音频质量差时错误率高</span>
<span id="cb24-478"><a href="#cb24-478" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>身份标注需人工验证</span>
<span id="cb24-479"><a href="#cb24-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-480"><a href="#cb24-480" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 可得性选择偏误</span></span>
<span id="cb24-481"><a href="#cb24-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-482"><a href="#cb24-482" aria-hidden="true" tabindex="-1"></a>**问题**：</span>
<span id="cb24-483"><a href="#cb24-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-484"><a href="#cb24-484" aria-hidden="true" tabindex="-1"></a>并非所有公司都公开电话会录音。</span>
<span id="cb24-485"><a href="#cb24-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-486"><a href="#cb24-486" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>大公司、透明度高的公司更可能公开</span>
<span id="cb24-487"><a href="#cb24-487" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>小公司、有负面消息的公司可能不公开</span>
<span id="cb24-488"><a href="#cb24-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-489"><a href="#cb24-489" aria-hidden="true" tabindex="-1"></a>**后果**：</span>
<span id="cb24-490"><a href="#cb24-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-491"><a href="#cb24-491" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>样本代表性差</span>
<span id="cb24-492"><a href="#cb24-492" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>模型推广到全市场时失效</span>
<span id="cb24-493"><a href="#cb24-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-494"><a href="#cb24-494" aria-hidden="true" tabindex="-1"></a>**缓解**：</span>
<span id="cb24-495"><a href="#cb24-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-496"><a href="#cb24-496" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>报告样本特征（市值、行业分布）</span>
<span id="cb24-497"><a href="#cb24-497" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>倾向评分加权（Propensity Score Weighting）</span>
<span id="cb24-498"><a href="#cb24-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-499"><a href="#cb24-499" aria-hidden="true" tabindex="-1"></a><span class="fu">## 视频模态：时序聚合、行为信号与合规边界</span></span>
<span id="cb24-500"><a href="#cb24-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-501"><a href="#cb24-501" aria-hidden="true" tabindex="-1"></a><span class="fu">### 视频 = 图像序列 + 音频</span></span>
<span id="cb24-502"><a href="#cb24-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-503"><a href="#cb24-503" aria-hidden="true" tabindex="-1"></a>**视频特征**：</span>
<span id="cb24-504"><a href="#cb24-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-505"><a href="#cb24-505" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**视觉通道**：帧级图像特征</span>
<span id="cb24-506"><a href="#cb24-506" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**音频通道**：语音/背景音特征</span>
<span id="cb24-507"><a href="#cb24-507" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**时序建模**：捕捉动态变化</span>
<span id="cb24-508"><a href="#cb24-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-509"><a href="#cb24-509" aria-hidden="true" tabindex="-1"></a><span class="fu">### 帧级视觉表征</span></span>
<span id="cb24-510"><a href="#cb24-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-511"><a href="#cb24-511" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 提取单帧特征</span></span>
<span id="cb24-512"><a href="#cb24-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-513"><a href="#cb24-513" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-514"><a href="#cb24-514" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb24-515"><a href="#cb24-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-516"><a href="#cb24-516" aria-hidden="true" tabindex="-1"></a><span class="co"># 读取视频</span></span>
<span id="cb24-517"><a href="#cb24-517" aria-hidden="true" tabindex="-1"></a>cap <span class="op">=</span> cv2.VideoCapture(<span class="st">"video.mp4"</span>)</span>
<span id="cb24-518"><a href="#cb24-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-519"><a href="#cb24-519" aria-hidden="true" tabindex="-1"></a>frames <span class="op">=</span> []</span>
<span id="cb24-520"><a href="#cb24-520" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> cap.isOpened():</span>
<span id="cb24-521"><a href="#cb24-521" aria-hidden="true" tabindex="-1"></a>    ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb24-522"><a href="#cb24-522" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ret:</span>
<span id="cb24-523"><a href="#cb24-523" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb24-524"><a href="#cb24-524" aria-hidden="true" tabindex="-1"></a>    frames.append(frame)</span>
<span id="cb24-525"><a href="#cb24-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-526"><a href="#cb24-526" aria-hidden="true" tabindex="-1"></a>cap.release()</span>
<span id="cb24-527"><a href="#cb24-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-528"><a href="#cb24-528" aria-hidden="true" tabindex="-1"></a><span class="co"># 对每帧提取 CNN 特征</span></span>
<span id="cb24-529"><a href="#cb24-529" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> resnet50</span>
<span id="cb24-530"><a href="#cb24-530" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet50(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-531"><a href="#cb24-531" aria-hidden="true" tabindex="-1"></a>feature_extractor <span class="op">=</span> torch.nn.Sequential(<span class="op">*</span><span class="bu">list</span>(model.children())[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb24-532"><a href="#cb24-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-533"><a href="#cb24-533" aria-hidden="true" tabindex="-1"></a>frame_features <span class="op">=</span> []</span>
<span id="cb24-534"><a href="#cb24-534" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> frame <span class="kw">in</span> frames[::<span class="dv">30</span>]:  <span class="co"># 每秒1帧（假设30fps）</span></span>
<span id="cb24-535"><a href="#cb24-535" aria-hidden="true" tabindex="-1"></a>    tensor <span class="op">=</span> preprocess(frame)</span>
<span id="cb24-536"><a href="#cb24-536" aria-hidden="true" tabindex="-1"></a>    feature <span class="op">=</span> feature_extractor(tensor.unsqueeze(<span class="dv">0</span>)).squeeze()</span>
<span id="cb24-537"><a href="#cb24-537" aria-hidden="true" tabindex="-1"></a>    frame_features.append(feature.numpy())</span>
<span id="cb24-538"><a href="#cb24-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-539"><a href="#cb24-539" aria-hidden="true" tabindex="-1"></a><span class="co"># 得到 (T, 2048) 的特征矩阵，T = 帧数</span></span>
<span id="cb24-540"><a href="#cb24-540" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-541"><a href="#cb24-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-542"><a href="#cb24-542" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 时间聚合</span></span>
<span id="cb24-543"><a href="#cb24-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-544"><a href="#cb24-544" aria-hidden="true" tabindex="-1"></a>**简单方法**：</span>
<span id="cb24-545"><a href="#cb24-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-546"><a href="#cb24-546" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**平均池化**：$\mathbf{v}_{\text{video}} = \frac{1}{T}\sum_{t=1}^T \mathbf{v}_t$</span>
<span id="cb24-547"><a href="#cb24-547" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**最大池化**：$\mathbf{v}_{\text{video}} = \max_{t=1}^T \mathbf{v}_t$</span>
<span id="cb24-548"><a href="#cb24-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-549"><a href="#cb24-549" aria-hidden="true" tabindex="-1"></a>**高级方法**：</span>
<span id="cb24-550"><a href="#cb24-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-551"><a href="#cb24-551" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**时序卷积网络（TCN）**</span>
<span id="cb24-552"><a href="#cb24-552" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**LSTM/GRU**：捕捉长期依赖</span>
<span id="cb24-553"><a href="#cb24-553" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Transformer**：自注意力机制</span>
<span id="cb24-554"><a href="#cb24-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-555"><a href="#cb24-555" aria-hidden="true" tabindex="-1"></a><span class="fu">### 行为线索：非言语信号</span></span>
<span id="cb24-556"><a href="#cb24-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-557"><a href="#cb24-557" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 面部动作编码（Facial Action Units, AUs）</span></span>
<span id="cb24-558"><a href="#cb24-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-559"><a href="#cb24-559" aria-hidden="true" tabindex="-1"></a>**定义**：</span>
<span id="cb24-560"><a href="#cb24-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-561"><a href="#cb24-561" aria-hidden="true" tabindex="-1"></a>Paul Ekman 提出的面部肌肉运动编码系统，共 46 个 AU。</span>
<span id="cb24-562"><a href="#cb24-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-563"><a href="#cb24-563" aria-hidden="true" tabindex="-1"></a>**示例**：</span>
<span id="cb24-564"><a href="#cb24-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-565"><a href="#cb24-565" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>AU1: 内眉上扬（惊讶）</span>
<span id="cb24-566"><a href="#cb24-566" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>AU4: 皱眉（沉思、担忧）</span>
<span id="cb24-567"><a href="#cb24-567" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>AU12: 嘴角上扬（微笑）</span>
<span id="cb24-568"><a href="#cb24-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-569"><a href="#cb24-569" aria-hidden="true" tabindex="-1"></a>**提取工具**：</span>
<span id="cb24-570"><a href="#cb24-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-571"><a href="#cb24-571" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-572"><a href="#cb24-572" aria-hidden="true" tabindex="-1"></a><span class="co"># OpenFace（开源）</span></span>
<span id="cb24-573"><a href="#cb24-573" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> subprocess</span>
<span id="cb24-574"><a href="#cb24-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-575"><a href="#cb24-575" aria-hidden="true" tabindex="-1"></a>subprocess.run([</span>
<span id="cb24-576"><a href="#cb24-576" aria-hidden="true" tabindex="-1"></a>    <span class="st">"FeatureExtraction"</span>,</span>
<span id="cb24-577"><a href="#cb24-577" aria-hidden="true" tabindex="-1"></a>    <span class="st">"-f"</span>, <span class="st">"video.mp4"</span>,</span>
<span id="cb24-578"><a href="#cb24-578" aria-hidden="true" tabindex="-1"></a>    <span class="st">"-out_dir"</span>, <span class="st">"output/"</span></span>
<span id="cb24-579"><a href="#cb24-579" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb24-580"><a href="#cb24-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-581"><a href="#cb24-581" aria-hidden="true" tabindex="-1"></a><span class="co"># 输出 CSV 文件，包含每帧的 AU 强度</span></span>
<span id="cb24-582"><a href="#cb24-582" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-583"><a href="#cb24-583" aria-hidden="true" tabindex="-1"></a>aus <span class="op">=</span> pd.read_csv(<span class="st">"output/video.csv"</span>)</span>
<span id="cb24-584"><a href="#cb24-584" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(aus[[<span class="st">'AU01_r'</span>, <span class="st">'AU04_r'</span>, <span class="st">'AU12_r'</span>]].head())</span>
<span id="cb24-585"><a href="#cb24-585" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-586"><a href="#cb24-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-587"><a href="#cb24-587" aria-hidden="true" tabindex="-1"></a>**金融应用**：</span>
<span id="cb24-588"><a href="#cb24-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-589"><a href="#cb24-589" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>CEO 在路演中的微表情（紧张、自信）</span>
<span id="cb24-590"><a href="#cb24-590" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>与股价/融资成功率的关系</span>
<span id="cb24-591"><a href="#cb24-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-592"><a href="#cb24-592" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 头部姿态（Head Pose）</span></span>
<span id="cb24-593"><a href="#cb24-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-594"><a href="#cb24-594" aria-hidden="true" tabindex="-1"></a>**特征**：</span>
<span id="cb24-595"><a href="#cb24-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-596"><a href="#cb24-596" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Yaw（左右转）</span>
<span id="cb24-597"><a href="#cb24-597" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Pitch（上下点头）</span>
<span id="cb24-598"><a href="#cb24-598" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Roll（左右倾斜）</span>
<span id="cb24-599"><a href="#cb24-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-600"><a href="#cb24-600" aria-hidden="true" tabindex="-1"></a>**含义**：</span>
<span id="cb24-601"><a href="#cb24-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-602"><a href="#cb24-602" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>频繁回避目光 → 不诚实？</span>
<span id="cb24-603"><a href="#cb24-603" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>频繁点头 → 认同/强调</span>
<span id="cb24-604"><a href="#cb24-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-605"><a href="#cb24-605" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 注视（Gaze）</span></span>
<span id="cb24-606"><a href="#cb24-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-607"><a href="#cb24-607" aria-hidden="true" tabindex="-1"></a>**特征**：</span>
<span id="cb24-608"><a href="#cb24-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-609"><a href="#cb24-609" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>眼睛注视方向</span>
<span id="cb24-610"><a href="#cb24-610" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>眼神接触时长</span>
<span id="cb24-611"><a href="#cb24-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-612"><a href="#cb24-612" aria-hidden="true" tabindex="-1"></a>**金融应用**：</span>
<span id="cb24-613"><a href="#cb24-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-614"><a href="#cb24-614" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>管理层回答问题时的眼神变化</span>
<span id="cb24-615"><a href="#cb24-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-616"><a href="#cb24-616" aria-hidden="true" tabindex="-1"></a><span class="fu">### 时序建模示例：LSTM</span></span>
<span id="cb24-617"><a href="#cb24-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-618"><a href="#cb24-618" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-619"><a href="#cb24-619" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-620"><a href="#cb24-620" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb24-621"><a href="#cb24-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-622"><a href="#cb24-622" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> VideoClassifier(nn.Module):</span>
<span id="cb24-623"><a href="#cb24-623" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">2048</span>, hidden_dim<span class="op">=</span><span class="dv">512</span>, num_classes<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb24-624"><a href="#cb24-624" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-625"><a href="#cb24-625" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(input_dim, hidden_dim, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-626"><a href="#cb24-626" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_dim, num_classes)</span>
<span id="cb24-627"><a href="#cb24-627" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-628"><a href="#cb24-628" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-629"><a href="#cb24-629" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x: (batch, seq_len, input_dim)</span></span>
<span id="cb24-630"><a href="#cb24-630" aria-hidden="true" tabindex="-1"></a>        _, (h_n, _) <span class="op">=</span> <span class="va">self</span>.lstm(x)</span>
<span id="cb24-631"><a href="#cb24-631" aria-hidden="true" tabindex="-1"></a>        <span class="co"># h_n: (1, batch, hidden_dim)</span></span>
<span id="cb24-632"><a href="#cb24-632" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc(h_n.squeeze(<span class="dv">0</span>))</span>
<span id="cb24-633"><a href="#cb24-633" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb24-634"><a href="#cb24-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-635"><a href="#cb24-635" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练</span></span>
<span id="cb24-636"><a href="#cb24-636" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> VideoClassifier()</span>
<span id="cb24-637"><a href="#cb24-637" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters())</span>
<span id="cb24-638"><a href="#cb24-638" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb24-639"><a href="#cb24-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-640"><a href="#cb24-640" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb24-641"><a href="#cb24-641" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> video_features, labels <span class="kw">in</span> dataloader:</span>
<span id="cb24-642"><a href="#cb24-642" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb24-643"><a href="#cb24-643" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(video_features)</span>
<span id="cb24-644"><a href="#cb24-644" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb24-645"><a href="#cb24-645" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb24-646"><a href="#cb24-646" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb24-647"><a href="#cb24-647" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-648"><a href="#cb24-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-649"><a href="#cb24-649" aria-hidden="true" tabindex="-1"></a><span class="fu">### 风险点与合规边界</span></span>
<span id="cb24-650"><a href="#cb24-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-651"><a href="#cb24-651" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 测量误差来源</span></span>
<span id="cb24-652"><a href="#cb24-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-653"><a href="#cb24-653" aria-hidden="true" tabindex="-1"></a>**角度/光照/压缩**：</span>
<span id="cb24-654"><a href="#cb24-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-655"><a href="#cb24-655" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>侧脸检测 AU 不准</span>
<span id="cb24-656"><a href="#cb24-656" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>逆光导致面部不清晰</span>
<span id="cb24-657"><a href="#cb24-657" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>视频压缩丢失细节</span>
<span id="cb24-658"><a href="#cb24-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-659"><a href="#cb24-659" aria-hidden="true" tabindex="-1"></a>**遮挡**：</span>
<span id="cb24-660"><a href="#cb24-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-661"><a href="#cb24-661" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>手遮住脸</span>
<span id="cb24-662"><a href="#cb24-662" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>面具/口罩</span>
<span id="cb24-663"><a href="#cb24-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-664"><a href="#cb24-664" aria-hidden="true" tabindex="-1"></a>**缓解**：</span>
<span id="cb24-665"><a href="#cb24-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-666"><a href="#cb24-666" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>质量评分：剔除低质量帧</span>
<span id="cb24-667"><a href="#cb24-667" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>数据增强：训练时模拟各种条件</span>
<span id="cb24-668"><a href="#cb24-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-669"><a href="#cb24-669" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 算法偏差</span></span>
<span id="cb24-670"><a href="#cb24-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-671"><a href="#cb24-671" aria-hidden="true" tabindex="-1"></a>**问题**：</span>
<span id="cb24-672"><a href="#cb24-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-673"><a href="#cb24-673" aria-hidden="true" tabindex="-1"></a>面部识别算法在不同人种/性别上的准确率不同。</span>
<span id="cb24-674"><a href="#cb24-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-675"><a href="#cb24-675" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>对白人、男性的识别率更高</span>
<span id="cb24-676"><a href="#cb24-676" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>对深色皮肤、女性的识别率较低</span>
<span id="cb24-677"><a href="#cb24-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-678"><a href="#cb24-678" aria-hidden="true" tabindex="-1"></a>**后果**：</span>
<span id="cb24-679"><a href="#cb24-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-680"><a href="#cb24-680" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>模型对不同群体的预测存在系统性偏差</span>
<span id="cb24-681"><a href="#cb24-681" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>伦理与公平性问题</span>
<span id="cb24-682"><a href="#cb24-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-683"><a href="#cb24-683" aria-hidden="true" tabindex="-1"></a>**缓解**：</span>
<span id="cb24-684"><a href="#cb24-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-685"><a href="#cb24-685" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>使用**公平性优化**的模型</span>
<span id="cb24-686"><a href="#cb24-686" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>报告不同群体的性能差异</span>
<span id="cb24-687"><a href="#cb24-687" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>在敏感场景中避免使用</span>
<span id="cb24-688"><a href="#cb24-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-689"><a href="#cb24-689" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 涉及生物特征的合规边界</span></span>
<span id="cb24-690"><a href="#cb24-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-691"><a href="#cb24-691" aria-hidden="true" tabindex="-1"></a>:::{.callout-caution}</span>
<span id="cb24-692"><a href="#cb24-692" aria-hidden="true" tabindex="-1"></a>⚠️ 法律与伦理红线</span>
<span id="cb24-693"><a href="#cb24-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-694"><a href="#cb24-694" aria-hidden="true" tabindex="-1"></a>**生物特征数据**（面部、声纹、虹膜等）受严格监管：</span>
<span id="cb24-695"><a href="#cb24-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-696"><a href="#cb24-696" aria-hidden="true" tabindex="-1"></a>**法规**：</span>
<span id="cb24-697"><a href="#cb24-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-698"><a href="#cb24-698" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**欧盟 GDPR**：需明确同意，用途受限</span>
<span id="cb24-699"><a href="#cb24-699" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**中国《个人信息保护法》**：敏感个人信息，需单独同意</span>
<span id="cb24-700"><a href="#cb24-700" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**美国各州法律**：如加州 CCPA、伊利诺伊州 BIPA</span>
<span id="cb24-701"><a href="#cb24-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-702"><a href="#cb24-702" aria-hidden="true" tabindex="-1"></a>**禁止场景**：</span>
<span id="cb24-703"><a href="#cb24-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-704"><a href="#cb24-704" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>未经同意的秘密收集</span>
<span id="cb24-705"><a href="#cb24-705" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>用于歧视性决策（如贷款审批基于面相）</span>
<span id="cb24-706"><a href="#cb24-706" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>大规模公共监控</span>
<span id="cb24-707"><a href="#cb24-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-708"><a href="#cb24-708" aria-hidden="true" tabindex="-1"></a>**合规建议**：</span>
<span id="cb24-709"><a href="#cb24-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-710"><a href="#cb24-710" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**明确告知**：数据收集目的、用途</span>
<span id="cb24-711"><a href="#cb24-711" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**获取同意**：可撤回的明确授权</span>
<span id="cb24-712"><a href="#cb24-712" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**最小化原则**：只收集必要数据</span>
<span id="cb24-713"><a href="#cb24-713" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**去标识化**：尽可能匿名化</span>
<span id="cb24-714"><a href="#cb24-714" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**人工监督**：敏感决策需人类审核</span>
<span id="cb24-715"><a href="#cb24-715" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb24-716"><a href="#cb24-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-717"><a href="#cb24-717" aria-hidden="true" tabindex="-1"></a><span class="fu">## 融合与分类评估：多模态增量信息检验</span></span>
<span id="cb24-718"><a href="#cb24-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-719"><a href="#cb24-719" aria-hidden="true" tabindex="-1"></a><span class="fu">### 融合策略</span></span>
<span id="cb24-720"><a href="#cb24-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-721"><a href="#cb24-721" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 早融合（Early Fusion）</span></span>
<span id="cb24-722"><a href="#cb24-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-723"><a href="#cb24-723" aria-hidden="true" tabindex="-1"></a>**在特征层面拼接**：</span>
<span id="cb24-724"><a href="#cb24-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-725"><a href="#cb24-725" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-726"><a href="#cb24-726" aria-hidden="true" tabindex="-1"></a><span class="co"># 图像特征 (2048维) + 音频特征 (768维) + 文本特征 (768维)</span></span>
<span id="cb24-727"><a href="#cb24-727" aria-hidden="true" tabindex="-1"></a>multimodal_feature <span class="op">=</span> np.concatenate([</span>
<span id="cb24-728"><a href="#cb24-728" aria-hidden="true" tabindex="-1"></a>    image_embedding,</span>
<span id="cb24-729"><a href="#cb24-729" aria-hidden="true" tabindex="-1"></a>    audio_embedding,</span>
<span id="cb24-730"><a href="#cb24-730" aria-hidden="true" tabindex="-1"></a>    text_embedding</span>
<span id="cb24-731"><a href="#cb24-731" aria-hidden="true" tabindex="-1"></a>])  <span class="co"># (3584维)</span></span>
<span id="cb24-732"><a href="#cb24-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-733"><a href="#cb24-733" aria-hidden="true" tabindex="-1"></a><span class="co"># 输入到分类器</span></span>
<span id="cb24-734"><a href="#cb24-734" aria-hidden="true" tabindex="-1"></a>classifier.fit(multimodal_feature, label)</span>
<span id="cb24-735"><a href="#cb24-735" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-736"><a href="#cb24-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-737"><a href="#cb24-737" aria-hidden="true" tabindex="-1"></a>**优点**：简单</span>
<span id="cb24-738"><a href="#cb24-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-739"><a href="#cb24-739" aria-hidden="true" tabindex="-1"></a>**缺点**：</span>
<span id="cb24-740"><a href="#cb24-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-741"><a href="#cb24-741" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>不同模态维度差异大，可能主导性不均</span>
<span id="cb24-742"><a href="#cb24-742" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>缺失模态时难以处理</span>
<span id="cb24-743"><a href="#cb24-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-744"><a href="#cb24-744" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 中期融合（Mid Fusion）</span></span>
<span id="cb24-745"><a href="#cb24-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-746"><a href="#cb24-746" aria-hidden="true" tabindex="-1"></a>**各模态先单独编码，再融合**：</span>
<span id="cb24-747"><a href="#cb24-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-748"><a href="#cb24-748" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-749"><a href="#cb24-749" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MidFusionModel(nn.Module):</span>
<span id="cb24-750"><a href="#cb24-750" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb24-751"><a href="#cb24-751" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-752"><a href="#cb24-752" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_encoder <span class="op">=</span> nn.Linear(<span class="dv">2048</span>, <span class="dv">512</span>)</span>
<span id="cb24-753"><a href="#cb24-753" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.audio_encoder <span class="op">=</span> nn.Linear(<span class="dv">768</span>, <span class="dv">512</span>)</span>
<span id="cb24-754"><a href="#cb24-754" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_encoder <span class="op">=</span> nn.Linear(<span class="dv">768</span>, <span class="dv">512</span>)</span>
<span id="cb24-755"><a href="#cb24-755" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fusion <span class="op">=</span> nn.Linear(<span class="dv">512</span><span class="op">*</span><span class="dv">3</span>, <span class="dv">256</span>)</span>
<span id="cb24-756"><a href="#cb24-756" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Linear(<span class="dv">256</span>, <span class="dv">2</span>)</span>
<span id="cb24-757"><a href="#cb24-757" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-758"><a href="#cb24-758" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, image, audio, text):</span>
<span id="cb24-759"><a href="#cb24-759" aria-hidden="true" tabindex="-1"></a>        img_emb <span class="op">=</span> <span class="va">self</span>.image_encoder(image)</span>
<span id="cb24-760"><a href="#cb24-760" aria-hidden="true" tabindex="-1"></a>        aud_emb <span class="op">=</span> <span class="va">self</span>.audio_encoder(audio)</span>
<span id="cb24-761"><a href="#cb24-761" aria-hidden="true" tabindex="-1"></a>        txt_emb <span class="op">=</span> <span class="va">self</span>.text_encoder(text)</span>
<span id="cb24-762"><a href="#cb24-762" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-763"><a href="#cb24-763" aria-hidden="true" tabindex="-1"></a>        fused <span class="op">=</span> torch.cat([img_emb, aud_emb, txt_emb], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-764"><a href="#cb24-764" aria-hidden="true" tabindex="-1"></a>        fused <span class="op">=</span> F.relu(<span class="va">self</span>.fusion(fused))</span>
<span id="cb24-765"><a href="#cb24-765" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.classifier(fused)</span>
<span id="cb24-766"><a href="#cb24-766" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-767"><a href="#cb24-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-768"><a href="#cb24-768" aria-hidden="true" tabindex="-1"></a>**优点**：各模态地位平等</span>
<span id="cb24-769"><a href="#cb24-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-770"><a href="#cb24-770" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 后融合（Late Fusion）</span></span>
<span id="cb24-771"><a href="#cb24-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-772"><a href="#cb24-772" aria-hidden="true" tabindex="-1"></a>**各模态单独预测，再集成**：</span>
<span id="cb24-773"><a href="#cb24-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-774"><a href="#cb24-774" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-775"><a href="#cb24-775" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练三个独立分类器</span></span>
<span id="cb24-776"><a href="#cb24-776" aria-hidden="true" tabindex="-1"></a>image_pred <span class="op">=</span> image_classifier.predict_proba(image_features)</span>
<span id="cb24-777"><a href="#cb24-777" aria-hidden="true" tabindex="-1"></a>audio_pred <span class="op">=</span> audio_classifier.predict_proba(audio_features)</span>
<span id="cb24-778"><a href="#cb24-778" aria-hidden="true" tabindex="-1"></a>text_pred <span class="op">=</span> text_classifier.predict_proba(text_features)</span>
<span id="cb24-779"><a href="#cb24-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-780"><a href="#cb24-780" aria-hidden="true" tabindex="-1"></a><span class="co"># 加权平均</span></span>
<span id="cb24-781"><a href="#cb24-781" aria-hidden="true" tabindex="-1"></a>final_pred <span class="op">=</span> <span class="fl">0.4</span> <span class="op">*</span> image_pred <span class="op">+</span> <span class="fl">0.3</span> <span class="op">*</span> audio_pred <span class="op">+</span> <span class="fl">0.3</span> <span class="op">*</span> text_pred</span>
<span id="cb24-782"><a href="#cb24-782" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-783"><a href="#cb24-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-784"><a href="#cb24-784" aria-hidden="true" tabindex="-1"></a>**优点**：</span>
<span id="cb24-785"><a href="#cb24-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-786"><a href="#cb24-786" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>可解释性强（知道各模态贡献）</span>
<span id="cb24-787"><a href="#cb24-787" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>容易处理缺失模态</span>
<span id="cb24-788"><a href="#cb24-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-789"><a href="#cb24-789" aria-hidden="true" tabindex="-1"></a>**缺点**：</span>
<span id="cb24-790"><a href="#cb24-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-791"><a href="#cb24-791" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>未利用模态间交互</span>
<span id="cb24-792"><a href="#cb24-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-793"><a href="#cb24-793" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 注意力融合（Attention-based）</span></span>
<span id="cb24-794"><a href="#cb24-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-795"><a href="#cb24-795" aria-hidden="true" tabindex="-1"></a>**自动学习各模态的权重**：</span>
<span id="cb24-796"><a href="#cb24-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-797"><a href="#cb24-797" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-798"><a href="#cb24-798" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionFusion(nn.Module):</span>
<span id="cb24-799"><a href="#cb24-799" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">512</span>):</span>
<span id="cb24-800"><a href="#cb24-800" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-801"><a href="#cb24-801" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention <span class="op">=</span> nn.Linear(input_dim, <span class="dv">1</span>)</span>
<span id="cb24-802"><a href="#cb24-802" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-803"><a href="#cb24-803" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, modalities):</span>
<span id="cb24-804"><a href="#cb24-804" aria-hidden="true" tabindex="-1"></a>        <span class="co"># modalities: list of (batch, input_dim)</span></span>
<span id="cb24-805"><a href="#cb24-805" aria-hidden="true" tabindex="-1"></a>        stacked <span class="op">=</span> torch.stack(modalities, dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># (batch, n_modalities, input_dim)</span></span>
<span id="cb24-806"><a href="#cb24-806" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-807"><a href="#cb24-807" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 计算注意力权重</span></span>
<span id="cb24-808"><a href="#cb24-808" aria-hidden="true" tabindex="-1"></a>        attn_scores <span class="op">=</span> <span class="va">self</span>.attention(stacked).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (batch, n_modalities)</span></span>
<span id="cb24-809"><a href="#cb24-809" aria-hidden="true" tabindex="-1"></a>        attn_weights <span class="op">=</span> F.softmax(attn_scores, dim<span class="op">=</span><span class="dv">1</span>).unsqueeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (batch, n_modalities, 1)</span></span>
<span id="cb24-810"><a href="#cb24-810" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-811"><a href="#cb24-811" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 加权和</span></span>
<span id="cb24-812"><a href="#cb24-812" aria-hidden="true" tabindex="-1"></a>        fused <span class="op">=</span> (stacked <span class="op">*</span> attn_weights).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># (batch, input_dim)</span></span>
<span id="cb24-813"><a href="#cb24-813" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> fused</span>
<span id="cb24-814"><a href="#cb24-814" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-815"><a href="#cb24-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-816"><a href="#cb24-816" aria-hidden="true" tabindex="-1"></a>**优点**：自适应融合</span>
<span id="cb24-817"><a href="#cb24-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-818"><a href="#cb24-818" aria-hidden="true" tabindex="-1"></a><span class="fu">### 缺失模态处理</span></span>
<span id="cb24-819"><a href="#cb24-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-820"><a href="#cb24-820" aria-hidden="true" tabindex="-1"></a>**现实问题**：</span>
<span id="cb24-821"><a href="#cb24-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-822"><a href="#cb24-822" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>部分公司没有电话会录音（音频缺失）</span>
<span id="cb24-823"><a href="#cb24-823" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>部分时期卫星图像有云遮挡（图像缺失）</span>
<span id="cb24-824"><a href="#cb24-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-825"><a href="#cb24-825" aria-hidden="true" tabindex="-1"></a>**策略**：</span>
<span id="cb24-826"><a href="#cb24-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-827"><a href="#cb24-827" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**删除缺失样本**（简单但损失数据）</span>
<span id="cb24-828"><a href="#cb24-828" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**用零向量填充**</span>
<span id="cb24-829"><a href="#cb24-829" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**训练单模态 + 多模态模型**，缺失时用单模态</span>
<span id="cb24-830"><a href="#cb24-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-831"><a href="#cb24-831" aria-hidden="true" tabindex="-1"></a><span class="fu">### 增量贡献评估</span></span>
<span id="cb24-832"><a href="#cb24-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-833"><a href="#cb24-833" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 实验设计</span></span>
<span id="cb24-834"><a href="#cb24-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-835"><a href="#cb24-835" aria-hidden="true" tabindex="-1"></a>**基准模型**：仅用结构化变量（财务指标）</span>
<span id="cb24-836"><a href="#cb24-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-837"><a href="#cb24-837" aria-hidden="true" tabindex="-1"></a>**增强模型**：+ 文本变量</span>
<span id="cb24-838"><a href="#cb24-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-839"><a href="#cb24-839" aria-hidden="true" tabindex="-1"></a>**多模态模型**：+ 文本 + 图像/音频</span>
<span id="cb24-840"><a href="#cb24-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-841"><a href="#cb24-841" aria-hidden="true" tabindex="-1"></a>**比较**：</span>
<span id="cb24-842"><a href="#cb24-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-843"><a href="#cb24-843" aria-hidden="true" tabindex="-1"></a>| 模型 | AUC | F1 | 相对提升 |</span>
<span id="cb24-844"><a href="#cb24-844" aria-hidden="true" tabindex="-1"></a>|-----|-----|-----|---------|</span>
<span id="cb24-845"><a href="#cb24-845" aria-hidden="true" tabindex="-1"></a>| 基准（结构化） | 0.75 | 0.68 | - |</span>
<span id="cb24-846"><a href="#cb24-846" aria-hidden="true" tabindex="-1"></a>| + 文本 | 0.78 | 0.71 | +4% AUC |</span>
<span id="cb24-847"><a href="#cb24-847" aria-hidden="true" tabindex="-1"></a>| + 文本 + 音频 | 0.80 | 0.73 | +6.7% AUC |</span>
<span id="cb24-848"><a href="#cb24-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-849"><a href="#cb24-849" aria-hidden="true" tabindex="-1"></a>**统计检验**：</span>
<span id="cb24-850"><a href="#cb24-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-851"><a href="#cb24-851" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**DeLong 检验**：比较 AUC 是否显著不同</span>
<span id="cb24-852"><a href="#cb24-852" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**配对 t 检验**：比较预测误差</span>
<span id="cb24-853"><a href="#cb24-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-854"><a href="#cb24-854" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 互补性检验</span></span>
<span id="cb24-855"><a href="#cb24-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-856"><a href="#cb24-856" aria-hidden="true" tabindex="-1"></a>**问题**：多模态信号是否只是重复文本信息？</span>
<span id="cb24-857"><a href="#cb24-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-858"><a href="#cb24-858" aria-hidden="true" tabindex="-1"></a>**检验**：</span>
<span id="cb24-859"><a href="#cb24-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-860"><a href="#cb24-860" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**相关性分析**</span>
<span id="cb24-861"><a href="#cb24-861" aria-hidden="true" tabindex="-1"></a>   <span class="in">```python</span></span>
<span id="cb24-862"><a href="#cb24-862" aria-hidden="true" tabindex="-1"></a>   corr <span class="op">=</span> df[[<span class="st">'text_sentiment'</span>, <span class="st">'audio_uncertainty'</span>, <span class="st">'image_activity'</span>]].corr()</span>
<span id="cb24-863"><a href="#cb24-863" aria-hidden="true" tabindex="-1"></a>   <span class="in">```</span></span>
<span id="cb24-864"><a href="#cb24-864" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>相关系数 &lt; 0.6 为健康</span>
<span id="cb24-865"><a href="#cb24-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-866"><a href="#cb24-866" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**分组分析**</span>
<span id="cb24-867"><a href="#cb24-867" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>在文本信号弱的样本中，音频/图像是否作用更强？</span>
<span id="cb24-868"><a href="#cb24-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-869"><a href="#cb24-869" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**消融实验（Ablation Study）**</span>
<span id="cb24-870"><a href="#cb24-870" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>逐步移除各模态，观察性能下降</span>
<span id="cb24-871"><a href="#cb24-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-872"><a href="#cb24-872" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 误差分析</span></span>
<span id="cb24-873"><a href="#cb24-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-874"><a href="#cb24-874" aria-hidden="true" tabindex="-1"></a>**案例分析**：</span>
<span id="cb24-875"><a href="#cb24-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-876"><a href="#cb24-876" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>哪些样本预测错误？</span>
<span id="cb24-877"><a href="#cb24-877" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>是否某类样本（如小市值）更难预测？</span>
<span id="cb24-878"><a href="#cb24-878" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>多模态在哪些情况下帮助最大？</span>
<span id="cb24-879"><a href="#cb24-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-880"><a href="#cb24-880" aria-hidden="true" tabindex="-1"></a><span class="fu">### 切片评估与稳健性</span></span>
<span id="cb24-881"><a href="#cb24-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-882"><a href="#cb24-882" aria-hidden="true" tabindex="-1"></a>**时间切片**：</span>
<span id="cb24-883"><a href="#cb24-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-884"><a href="#cb24-884" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>训练期 vs 测试期性能差异</span>
<span id="cb24-885"><a href="#cb24-885" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>不同市场状态（牛市/熊市）</span>
<span id="cb24-886"><a href="#cb24-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-887"><a href="#cb24-887" aria-hidden="true" tabindex="-1"></a>**横截面切片**：</span>
<span id="cb24-888"><a href="#cb24-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-889"><a href="#cb24-889" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>不同行业（科技 vs 制造）</span>
<span id="cb24-890"><a href="#cb24-890" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>不同规模（大市值 vs 小市值）</span>
<span id="cb24-891"><a href="#cb24-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-892"><a href="#cb24-892" aria-hidden="true" tabindex="-1"></a>**目的**：确保模型泛化能力。</span>
<span id="cb24-893"><a href="#cb24-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-894"><a href="#cb24-894" aria-hidden="true" tabindex="-1"></a><span class="fu">## 本周小结</span></span>
<span id="cb24-895"><a href="#cb24-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-896"><a href="#cb24-896" aria-hidden="true" tabindex="-1"></a><span class="fu">### 核心要点</span></span>
<span id="cb24-897"><a href="#cb24-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-898"><a href="#cb24-898" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**多模态任务设计**：明确标签定义（何时、对谁、预测什么）</span>
<span id="cb24-899"><a href="#cb24-899" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**图像特征**：CNN/ViT/CLIP，注意空间对齐、质量控制、域漂移</span>
<span id="cb24-900"><a href="#cb24-900" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**音频特征**：ASR → 文本 vs 声学/韵律特征，注意 ASR 错误、说话人分离</span>
<span id="cb24-901"><a href="#cb24-901" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**视频特征**：帧级 + 时序建模，行为线索（AU/姿态/注视），注意测量误差</span>
<span id="cb24-902"><a href="#cb24-902" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**融合策略**：早/中/后融合、注意力机制，处理缺失模态</span>
<span id="cb24-903"><a href="#cb24-903" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**增量检验**：相对文本/结构化变量的增量贡献，互补性证据</span>
<span id="cb24-904"><a href="#cb24-904" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>**伦理边界**：生物特征合规、算法偏差、隐私保护</span>
<span id="cb24-905"><a href="#cb24-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-906"><a href="#cb24-906" aria-hidden="true" tabindex="-1"></a><span class="fu">### 本周思考题</span></span>
<span id="cb24-907"><a href="#cb24-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-908"><a href="#cb24-908" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 问题 1</span></span>
<span id="cb24-909"><a href="#cb24-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-910"><a href="#cb24-910" aria-hidden="true" tabindex="-1"></a>以"业绩电话会音频"构造一个分类任务（如识别管理层不确定性状态）时，标签通常如何定义？哪些环节最容易引入样本选择偏误？</span>
<span id="cb24-911"><a href="#cb24-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-912"><a href="#cb24-912" aria-hidden="true" tabindex="-1"></a>:::{.callout-note collapse="true"}</span>
<span id="cb24-913"><a href="#cb24-913" aria-hidden="true" tabindex="-1"></a>💡 参考答案</span>
<span id="cb24-914"><a href="#cb24-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-915"><a href="#cb24-915" aria-hidden="true" tabindex="-1"></a>**标签定义**：</span>
<span id="cb24-916"><a href="#cb24-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-917"><a href="#cb24-917" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**基于未来股价**：</span>
<span id="cb24-918"><a href="#cb24-918" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$y = \mathbb{I}(r_{t+1 \to t+k} &lt; \text{市场中位数})$</span>
<span id="cb24-919"><a href="#cb24-919" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>不确定性高 → 未来表现差</span>
<span id="cb24-920"><a href="#cb24-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-921"><a href="#cb24-921" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**基于财务意外**：</span>
<span id="cb24-922"><a href="#cb24-922" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$y = \mathbb{I}(|\text{实际EPS} - \text{预期EPS}| &gt; \text{阈值})$</span>
<span id="cb24-923"><a href="#cb24-923" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>不确定性高 → 预测误差大</span>
<span id="cb24-924"><a href="#cb24-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-925"><a href="#cb24-925" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**基于文本词典**（辅助标注）：</span>
<span id="cb24-926"><a href="#cb24-926" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>统计不确定性词汇（"uncertain", "might", "could"）</span>
<span id="cb24-927"><a href="#cb24-927" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>人工验证部分样本</span>
<span id="cb24-928"><a href="#cb24-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-929"><a href="#cb24-929" aria-hidden="true" tabindex="-1"></a>**样本选择偏误来源**：</span>
<span id="cb24-930"><a href="#cb24-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-931"><a href="#cb24-931" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**可得性偏误**</span>
<span id="cb24-932"><a href="#cb24-932" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>大公司、透明度高的公司更可能公开录音</span>
<span id="cb24-933"><a href="#cb24-933" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>小公司、有负面消息的可能隐藏</span>
<span id="cb24-934"><a href="#cb24-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-935"><a href="#cb24-935" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**存活偏误**</span>
<span id="cb24-936"><a href="#cb24-936" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>退市公司的电话会数据缺失</span>
<span id="cb24-937"><a href="#cb24-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-938"><a href="#cb24-938" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**时期选择**</span>
<span id="cb24-939"><a href="#cb24-939" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>危机期间电话会取消率更高</span>
<span id="cb24-940"><a href="#cb24-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-941"><a href="#cb24-941" aria-hidden="true" tabindex="-1"></a>**缓解**：</span>
<span id="cb24-942"><a href="#cb24-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-943"><a href="#cb24-943" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>报告样本特征分布</span>
<span id="cb24-944"><a href="#cb24-944" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>倾向评分加权</span>
<span id="cb24-945"><a href="#cb24-945" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>稳健性检验（仅用持续有数据的公司）</span>
<span id="cb24-946"><a href="#cb24-946" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb24-947"><a href="#cb24-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-948"><a href="#cb24-948" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 问题 2</span></span>
<span id="cb24-949"><a href="#cb24-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-950"><a href="#cb24-950" aria-hidden="true" tabindex="-1"></a>如何严谨地证明多模态信号对文本/结构化变量具有增量信息？请给出一个你认为必要的互补性检验设计。</span>
<span id="cb24-951"><a href="#cb24-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-952"><a href="#cb24-952" aria-hidden="true" tabindex="-1"></a>:::{.callout-note collapse="true"}</span>
<span id="cb24-953"><a href="#cb24-953" aria-hidden="true" tabindex="-1"></a>💡 参考答案</span>
<span id="cb24-954"><a href="#cb24-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-955"><a href="#cb24-955" aria-hidden="true" tabindex="-1"></a>**完整检验流程**：</span>
<span id="cb24-956"><a href="#cb24-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-957"><a href="#cb24-957" aria-hidden="true" tabindex="-1"></a>**1. 基准对比**</span>
<span id="cb24-958"><a href="#cb24-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-959"><a href="#cb24-959" aria-hidden="true" tabindex="-1"></a>| 模型 | 特征 | AUC | $\Delta$ AUC |</span>
<span id="cb24-960"><a href="#cb24-960" aria-hidden="true" tabindex="-1"></a>|-----|------|-----|-------------|</span>
<span id="cb24-961"><a href="#cb24-961" aria-hidden="true" tabindex="-1"></a>| M1 | 结构化（财务指标） | 0.72 | - |</span>
<span id="cb24-962"><a href="#cb24-962" aria-hidden="true" tabindex="-1"></a>| M2 | M1 + 文本 | 0.76 | +0.04 |</span>
<span id="cb24-963"><a href="#cb24-963" aria-hidden="true" tabindex="-1"></a>| M3 | M2 + 音频 | 0.79 | +0.03 |</span>
<span id="cb24-964"><a href="#cb24-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-965"><a href="#cb24-965" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**条件**：$\Delta$ AUC 统计显著（DeLong 检验 $p &lt; 0.05$）</span>
<span id="cb24-966"><a href="#cb24-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-967"><a href="#cb24-967" aria-hidden="true" tabindex="-1"></a>**2. 相关性分析**</span>
<span id="cb24-968"><a href="#cb24-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-969"><a href="#cb24-969" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb24-970"><a href="#cb24-970" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> df[[<span class="st">'structured'</span>, <span class="st">'text'</span>, <span class="st">'audio'</span>]].corr()</span>
<span id="cb24-971"><a href="#cb24-971" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> corr_matrix.loc[<span class="st">'audio'</span>, <span class="st">'text'</span>] <span class="op">&lt;</span> <span class="fl">0.6</span>  <span class="co"># 避免高度冗余</span></span>
<span id="cb24-972"><a href="#cb24-972" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-973"><a href="#cb24-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-974"><a href="#cb24-974" aria-hidden="true" tabindex="-1"></a>**3. 条件独立性检验**</span>
<span id="cb24-975"><a href="#cb24-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-976"><a href="#cb24-976" aria-hidden="true" tabindex="-1"></a>在控制文本后，音频是否仍有预测力？</span>
<span id="cb24-977"><a href="#cb24-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-978"><a href="#cb24-978" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb24-979"><a href="#cb24-979" aria-hidden="true" tabindex="-1"></a>\text{Logit}(y) = \beta_0 + \beta_1 \text{Text} + \beta_2 \text{Audio} + \varepsilon</span>
<span id="cb24-980"><a href="#cb24-980" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb24-981"><a href="#cb24-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-982"><a href="#cb24-982" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>检验：$\beta_2$ 是否显著？</span>
<span id="cb24-983"><a href="#cb24-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-984"><a href="#cb24-984" aria-hidden="true" tabindex="-1"></a>**4. 分组异质性**</span>
<span id="cb24-985"><a href="#cb24-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-986"><a href="#cb24-986" aria-hidden="true" tabindex="-1"></a>在文本信号弱的子样本中，音频贡献更大：</span>
<span id="cb24-987"><a href="#cb24-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-988"><a href="#cb24-988" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-989"><a href="#cb24-989" aria-hidden="true" tabindex="-1"></a><span class="in">分组：文本情感 = 中性（信息量少）</span></span>
<span id="cb24-990"><a href="#cb24-990" aria-hidden="true" tabindex="-1"></a><span class="in">  → 音频 AUC 提升更显著</span></span>
<span id="cb24-991"><a href="#cb24-991" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb24-992"><a href="#cb24-992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-993"><a href="#cb24-993" aria-hidden="true" tabindex="-1"></a>**5. 消融实验**</span>
<span id="cb24-994"><a href="#cb24-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-995"><a href="#cb24-995" aria-hidden="true" tabindex="-1"></a>| 移除模态 | AUC 下降 | 解释 |</span>
<span id="cb24-996"><a href="#cb24-996" aria-hidden="true" tabindex="-1"></a>|---------|---------|-----|</span>
<span id="cb24-997"><a href="#cb24-997" aria-hidden="true" tabindex="-1"></a>| 去除音频 | -0.03 | 音频有独特贡献 |</span>
<span id="cb24-998"><a href="#cb24-998" aria-hidden="true" tabindex="-1"></a>| 去除文本 | -0.04 | 文本仍重要 |</span>
<span id="cb24-999"><a href="#cb24-999" aria-hidden="true" tabindex="-1"></a>| 去除结构化 | -0.05 | 基础变量最重要 |</span>
<span id="cb24-1000"><a href="#cb24-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1001"><a href="#cb24-1001" aria-hidden="true" tabindex="-1"></a>**结论模板**：</span>
<span id="cb24-1002"><a href="#cb24-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1003"><a href="#cb24-1003" aria-hidden="true" tabindex="-1"></a>"音频特征在控制文本与结构化变量后，仍能带来统计显著的 AUC 提升（+0.03, p=0.01）。相关性分析显示音频与文本相关系数为 0.45，表明二者捕捉了部分重叠但非完全冗余的信息。在文本情感中性的子样本中，音频的增量贡献更大（AUC +0.05），证实了互补性。"</span>
<span id="cb24-1004"><a href="#cb24-1004" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb24-1005"><a href="#cb24-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1006"><a href="#cb24-1006" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb24-1007"><a href="#cb24-1007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1008"><a href="#cb24-1008" aria-hidden="true" tabindex="-1"></a><span class="fu">### 课程前半段回顾</span></span>
<span id="cb24-1009"><a href="#cb24-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1010"><a href="#cb24-1010" aria-hidden="true" tabindex="-1"></a>前四周我们建立了**AI 赋能金融研究的完整框架**：</span>
<span id="cb24-1011"><a href="#cb24-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1012"><a href="#cb24-1012" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**第1周**：机器学习基础（i.i.d. 场景）</span>
<span id="cb24-1013"><a href="#cb24-1013" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**第2周**：金融时序评估与回测规范</span>
<span id="cb24-1014"><a href="#cb24-1014" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**第3周**：文本分析的可审计流程</span>
<span id="cb24-1015"><a href="#cb24-1015" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**第4周**：多模态信号的增量检验</span>
<span id="cb24-1016"><a href="#cb24-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1017"><a href="#cb24-1017" aria-hidden="true" tabindex="-1"></a>**共同主线**：</span>
<span id="cb24-1018"><a href="#cb24-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1019"><a href="#cb24-1019" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**泛化能力**：样本外表现是唯一标准</span>
<span id="cb24-1020"><a href="#cb24-1020" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**可审计性**：从原始数据到变量的每一步可追溯</span>
<span id="cb24-1021"><a href="#cb24-1021" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**增量价值**：新方法必须相对已知方法展示增量信息</span>
<span id="cb24-1022"><a href="#cb24-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1023"><a href="#cb24-1023" aria-hidden="true" tabindex="-1"></a><span class="fu">### 后半段课程预告</span></span>
<span id="cb24-1024"><a href="#cb24-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1025"><a href="#cb24-1025" aria-hidden="true" tabindex="-1"></a>**第5-8周**：学生研究计划汇报与研讨</span>
<span id="cb24-1026"><a href="#cb24-1026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1027"><a href="#cb24-1027" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>每组展示研究问题、数据、方法、评估协议</span>
<span id="cb24-1028"><a href="#cb24-1028" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>课堂讨论与反馈</span>
<span id="cb24-1029"><a href="#cb24-1029" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>强化**最小证据链**意识</span>
<span id="cb24-1030"><a href="#cb24-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1031"><a href="#cb24-1031" aria-hidden="true" tabindex="-1"></a>**第5周前**将有**课前测验**，覆盖第1-4周核心概念，请提前复习！</span>
<span id="cb24-1032"><a href="#cb24-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1033"><a href="#cb24-1033" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb24-1034"><a href="#cb24-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-1035"><a href="#cb24-1035" aria-hidden="true" tabindex="-1"></a>**祝学习顺利！期待看到你们的精彩研究！**</span></code><button title="复制到剪贴板" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>